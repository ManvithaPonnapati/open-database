# deprecated retrive functions from the old database
# retieve function should generalize to any comlumn name



# FROM CREATE
# Not acceptable because of complexity of creation
 parser.add_argument('--create',dest='db_create', action='store_true')
    parser.add_argument('--continue',dest='db_continue', action='store_true')
    parser.add_argument('--delete',dest='db_delete', action='store_true')
    parser.add_argument('--progress', dest='db_progress', action='store_true')
    parser.add_argument('--list_param', dest='db_param',action='store_true')
    parser.add_argument('--action', type=str)
    parser.add_argument('--param', type=str)
    parser.add_argument('--retry_failed', action='store_true')
    parser.add_argument('--folder_name', type=str)
    parser.add_argument('--table_idx', type=int)
    parser.add_argument('--receptor_idx', type=int)
    parser.add_argument('--ligand_idx', type=int)
    parser.add_argument('--crystal_idx', type=int)
    parser.add_argument('--docked_idx', type=int)
    parser.add_argument('--column_name', type=str)
    parser.add_argument('--column_dtype', type=str)
    parser.add_argument('--download_idx', type=int)



import os
import sys 
import re 
import numbers 
from collections import namedtuple
import pandas as pd 
from database_action import db 
import six 
import time
import numpy as np
import sys
import os
import re
import prody
import config
import pandas as pd 
import cPickle
import tensorflow as tf 
sys.path.append('..')


class table(pd.DataFrame):
    def apply_rest(self, key, val):
        new = self
        if isinstance(val, numbers.Number) or isinstance(val, six.string_types):
            new = new[new[key] == val]
        elif isinstance(val, list):
            if len(val) == 2:
                minimum, maximum = val
                if minimum is not None:
                    new = new[new[key] >= minimum]
                if maximum is not None:
                    new = new[new[key] <= maximum]
            else:
                raise Exception("require restriction size 2, get %d" % len(val))
        elif isinstance(val, tuple):
            if len(val) == 2:
                minimum, maximum = val
                if minimum is not None:
                    new = new[new[key] > minimum]
                if maximum is not None:
                    
                    new = new[new[key] < maximum]
            else:
                raise Exception("require restriction size 2, get %d" % len(val))
        elif val is None:
            pass
        else:
            raise Exception("Restrictions type {} doesn't support.".format(type(val).__name__))
        
        return self.wrap(new)

    @classmethod
    def wrap(cls, dataframe):
        return cls(dataframe)

    def __and__(self, other):
        if len(self) == 0:
            return self
        elif len(other) == 0:
            return other
        else:
            new = self
            new = new.merge(other).drop_duplicates().dropna()
            return self.wrap(new)

    def __or__(self, other):
        if len(self) == 0:
            return other
        elif len(other) == 0:
            return self
        else:
            new = self
            new = new.merge(other, how='outer').drop_duplicates().dropna()
            return self.wrap(new)

    def __sub__(self, other):

        new = self
        intersec = new & other
        #union = new | other

        i = set(map(tuple, list(intersec.values)))
        u = set(map(tuple, list(new.values)))

        diff = u - i
        columns = self.columns

        if len(diff):
            new = self.wrap(pd.DataFrame(list(diff), columns=columns))
        else:
            new = self.wrap(pd.DataFrame())

        return new

class retrieve_data(object):
    export_fmt = ['pdb','pkl','av4','tfr', 'tfr_one']

    def __init__(self):
        
        # table for available ligand
        # columns : ['receptor','chain','resnum', 'resname'] + other
        # path of receptor : [receptor_folder]/[receptor]/[receptor]_[chain]_[resnum]_[resname]_receptor.pdb
        # path of ligand   : [ligand_folder]/[receptor]/[receptor]_[chain]_[resnnum]_[resname]_ligand.pdb
        # path of docked ligand : [docked_folder]/[receptor]/[receptor]_[chain]_[resnum]_[resname]_ligand.pdb
        self.ligand = None
        
        # table for available position 
        # columns : ['receptor','chain','resnum','resname','position'] + other
        self.position = None
        
        # where can get splited receptor
        # e.g. 2_splited_receptor
        self.receptor_folder = None 
        
        # where can get splited ligand
        # e.g. 3_splited_ligand
        self.ligand_folder = None 
        
        # where can get the docked ligand
        # e.g. 4_docked
        self.docked_folder = None 
        
        # log_affinity or norm_affinity
        # it will be the label for the ligand
        self.affinity_key = None

        # table for ligand that is invalid
        # columns = ['resname']
        self.exclude = table(pd.DataFrame())

    def __and__(self, other):
        '''
        and operation between two retive_data obj
        new = self & other
        
        Args:
            other: retrive_data obj

        Returns: retrive_data 

        '''
        assert self.receptor_folder == other.receptor_folder
        assert self.ligand_folder == other.ligand_folder 
        assert self.docked_folder == other.docked_folder \
                or self.docked_folder == None \
                or other.docked_folder == None

        assert self.affinity_key == other.affinity_key

        new = self.same()

        if new.ligand is None:
            new.ligand = other.ligand 
        elif other.ligand is not None:
            new.ligand = new.ligand & other.ligand 
        
        if new.position is None:
            new.position = other.position
        elif other.position is not None:
            new.position = new.position & other.position 

        if new.exclude is None:
            new.exclude = other.exclude
        elif other.exclude is not None:
            new.exclude = new.exclude | other.exclude

        if new.docked_folder is None:
            new.docked_folder = other.docked_folder

        return new 

    def __or__(self, other):
        '''
        or operation between data_retrive obj
        new = self | other
        
        Args:
            other: data_retrive obj

        Returns: data_retrive obj

        '''
        assert self.receptor_folder == other.receptor_folder
        assert self.ligand_folder == other.ligand_folder
        assert self.docked_folder == other.docked_folder \
                or self.docked_folder == None \
                or other.docked_folder == None

        assert self.affinity_key == other.affinity_key

        new = self.same()

        if new.ligand is None:
            new.ligand = other.ligand 
        elif other.ligand is not None:
            new.ligand = new.ligand | other.ligand 

        if new.position is None:
            new.position = other.position
        elif other.position is not None:
            new.position = new.position | other.position

        if new.exclude is None:
            new.exclude = other.exclude
        elif other.exclude is not None:
            new.exclude = new.exclude | other.exclude
        
        if new.docked_folder is None:
            new.docked_folder = other.docked_folder

        return new
      

    def same(self):
        '''
        Greate and return a new object with same attribute
        
        Returns: retrive_data object

        '''
        new = retrive_data()
        new.receptor_folder = self.receptor_folder
        new.ligand_folder = self.ligand_folder
        new.docked_folder = self.docked_folder
        new.ligand = self.ligand
        new.position = self.position
        new.affinity_key = self.affinity_key
        new.exclude = self.exclude

        return new

    def print_all(self, idx):
        db.get_success_data(idx, dataframe=True)
        table_name, _, df  = db.get_success_data(idx, dataframe=True)
        print(df['receptor'])

    def retrieve_pdb_files(self, idx1, idx2):
        """
        Returns a list of pdb names to download
        """
        db.get_receptors_with_affinity(idx1, idx2)
        # self.retrive_all(idx)
        # pdb_names = [x.encode('ascii')+'.pdb' for x in self.ligand['receptor'].tolist()]        
        # binding_affinities = self.ligand['log_affinity'].tolist()
        # print pdb_names, binding_affinities

    def receptor(self, receptor_idx, rest):
        '''
        load available receptor from table with idx: receptor_idx
        set receptor_folder
        
        Args:
            receptor_idx: int
            rest: typle: (a,b) , restriction a < value < b 
                  list: [a,b] , restriction a <= value <= b
                  None: no restriction

        Returns:

        '''

        _, _, df = db.get_success_data(receptor_idx, dataframe=True)
        primary_key = db.primary_key_for(receptor_idx)
        df = df[primary_key+['resolution']]
        df = table(df).apply_rest('resolution',rest)

        if self.ligand is None:
            self.ligand  = df 
        else:
            self.ligand = self.ligand & df

        folder_name = db.get_folder(receptor_idx)
        self.receptor_folder = '{}_{}'.format(receptor_idx, folder_name)
        
        return self

    def crystal(self, crystal_idx):
        '''
        load available ligand from table with idx: crystal_idx
        set ligand_folder
        
        Args:
            crystal_idx: int 

        Returns: self

        '''
        #print('here')
        db.get_success_data(crystal_idx, dataframe=True)
        table_name, _, df  = db.get_success_data(crystal_idx, dataframe=True)
        primary_key = db.primary_key_for(crystal_idx)
        df = df[primary_key]
        df = table(df) 
        print df
        #print df
        if self.ligand is None:
            self.ligand = df 
        else:
            self.ligand = self.ligand & df  
        try:            
            folder_name  = db.get_folder(crystal_idx)
            self.ligand_folder = '{}_{}'.format(crystal_idx, folder_name)
        except:
            pass
        return self




    def ligand_size(self, ligand_idx, rest):
        '''
        select the ligand for the size in restriciton : rest
        e.g. rest=(None,20) for the ligand could be fit into the box with size 20 A

        Args:
            ligand_idx: int 
            rest: typle: (a,b) , restriction a < value < b 
                  list: [a,b] , restriction a <= value <= b
                  None: no restriction
        '''

        _, _, df = db.get_success_data(ligand_idx, dataframe=True)
        primary_key = db.primary_key_for(ligand_idx)
        df = df[primary_key + ['max_size_on_axis']]
        df = table(df).apply_rest('max_size_on_axis', rest)
        if self.ligand is None:
            self.ligand = df
        else:
            self.ligand = self.ligand & df 
        try:            
            folder_name  = db.get_folder(ligand_idx)
            self.ligand_folder = '{}_{}'.format(ligand_idx, folder_name)
        except:
            pass
        return self

    def docked(self, docked_idx):
        '''
        load available docked ligand from table with idx: docked_idx
        set docked_folder
    
        Args:
            docked_idx: int

        Returns: self

        '''

        _, _, df = db.get_success_data(docked_idx, dataframe=True)
        primary_key = db.primary_key_for(docked_idx)
        df = df[primary_key]
        df = table(df)

        if self.ligand is None:
            self.ligand = df 
        else:
            self.ligand = self.ligand & df 
        
        folder_name = db.get_folder(docked_idx)
        self.docked_folder = '{}_{}'.format(docked_idx, folder_name )

        return self

    def overlap(self, overlap_idx, rest):
        '''
        # select position with overlap value in restriction: rest
        # e.g. rest=[0.1,0.5] overlap ratio : 0.1 <= value <= 0.5
        Args:
            overlap_idx: int index for overlap table
            rest: typle: (a,b) , restriction a < value < b 
                  list: [a,b] , restriction a <= value <= b
                  None: no restriction

        Returns: self

        '''

        _, _, df = db.get_success_data(overlap_idx, dataframe=True)
        primary_key = db.primary_key_for(overlap_idx)
        df = df[primary_key+['overlap_ratio']]
        df = table(df).apply_rest('overlap_ratio',rest)

        if self.position is None:
            self.position = df 
        else:
            self.position = self.docked & df 

        return self

    def rmsd(self, rmsd_idx, rest):
        '''
        select position with rmsd value in restriction: rest
        e.g. rest=[None, 2] rmsd ration : minimum <= value <= 2
        
        Args:
            rmsd_idx: 
            rest: typle: (a,b) , restriction a < value < b 
                  list: [a,b] , restriction a <= value <= b
                  None: no restriction

        Returns: self

        '''
        
        _, _, df = db.get_success_data(rmsd_idx, dataframe=True)
        primary_key = db.primary_key_for(rmsd_idx)
        df= df[primary_key + ['rmsd']]
        df = table(df).apply_rest('rmsd',rest)
        
        if self.position is None:
            self.position = df
        else:
            self.position = self.position & df

        return self

    def native_contact(self, native_contact_idx, rest):
        '''
        select position with native contact ration in restriction: rest
        e.g. rest=None  no restriction on native contact
        Args:
            native_contact_idx:  int
            rest: typle: (a,b) , restriction a < value < b 
                  list: [a,b] , restriction a <= value <= b
                  None: no restriction


        Returns:

        '''


        _, _, df = db.get_success_data(native_contact_idx, dataframe=True)
        primary_key = db.primary_key_for(native_contact_idx)
        df = df[primary_key + ['native_contact']]
        df = table(df).apply_rest('native_contact',rest)

        if self.position is None:
            self.position = df 
        else: 
            self.position = self.position & df 

        return self

    def norm_affinity(self, affinity_idx, rest):
        '''
        select available ligand with norm affinity value in restriction: rest
        Args:
            affinity_idx: int
            rest: tuple: (a,b) , restriction a < value < b 
                  list: [a,b] , restriction a <= value <= b
                  None: no restriction

        Returns:

        '''
        
        self.affinity_key = 'norm_affinity'
        _, _, df = db.get_success_data(affinity_idx, dataframe=True)
        primary_key = db.primary_key_for(affinity_idx)
        df = df[primary_key+[self.affinity_key]]
        df = table(df).apply_rest(self.affinity_key,rest)
        
        if self.ligand is None:
            self.ligand = df
        else:
            self.ligand = self.ligand & df 

        return self





    def export_table(self):
        '''
        export the retrive result as a dataframe table
        Returns: table

        '''
        if self.position is None:
            return self.ligand - self.exclude
        else:
            return self.ligand & self.position - self.exclude

    def export_data_to(self, folder_name, d_format):
        '''
        retrive data to the folder named by [folder_name] and convert them to [d_format]
           
        Args:
            folder_name: the data to export the folder
            d_format: str
                'pkl': python pikle
                'av4': affinity build-in binary format
                'tfr': tensorflow record format
                'pdb': save format as input
                'tfr_one': save ligand and receptor in one TFRecord

        Returns: None

        '''
        
        if not d_format in self.export_fmt:
            raise Exception("Unexpected format {}, available format: {}".\
                                format(d_format, self.export_fmt))
        
        export_dir = os.path.join(config.export_dir, folder_name)
        
        if self.position is None:
            valid = self.ligand - self.exclude
        
            collection = []
            for i in range(len(valid)):
                item = valid.ix[i]
                receptor = item['receptor']
                file = '_'.join(item[['receptor', 'chain', 'resnum', 'resname']])
                receptor_path = os.path.join(config.data_dir, 
                                        self.receptor_folder, 
                                        receptor,
                                        file+'_receptor.pdb')

                ligand_path = os.path.join(config.data_dir,
                                        self.ligand_folder,
                                        receptor,
                                        file+'_ligand.pdb')

                docked_path = ''
                positions = []

                affinity = item[self.affinity_key]

                collection.append([receptor_path, 
                                ligand_path, 
                                docked_path, 
                                positions, 
                                affinity])
            
        
        else:
            valid = self.ligand & self.position - self.exclude
            collection =[]
            
            for keys, group in valid.groupby(['receptor','chain','resnum','resname', self.affinity_key]):
                receptor = keys[0]
                file = '_'.join(keys[:4])

                receptor_path = os.path.join(config.data_dir, 
                                        self.receptor_folder, 
                                        receptor,
                                        file+'_receptor.pdb')

                ligand_path = os.path.join(config.data_dir,
                                        self.ligand_folder,
                                        receptor,
                                        file+'_ligand.pdb')

                docked_path = os.path.join(config.data_dir,
                                        self.docked_folder,
                                        receptor,
                                        file+'_ligand.pdb')

                positions = sorted(group['position'])

                affinity = list(set(group[self.affinity_key]))
                assert len(affinity) == 1
                affinity = affinity[0]

                collection.append([receptor_path, 
                                   ligand_path, 
                                   docked_path, 
                                   positions, 
                                   affinity])

        #print(set(map(lambda x:len(x),collection)))
        export_table_dir = os.path.join(export_dir,'index')
        if not os.path.exists(export_table_dir):
            os.makedirs(export_table_dir)

        df = pd.DataFrame(collection,columns=['receptor','ligand','docked','position','affinity'])
        df.to_csv(os.path.join(export_table_dir,'raw.csv'), index=False, sep='\t')

        data_export_dir = os.path.join(export_dir,'data')

        index = []
        for receptor, ligand, docked, position, aff in collection:
            rec_path, lig_path = convert_and_save_data(data_export_dir,
                                                     receptor,
                                                     ligand,
                                                     docked,
                                                     position,
                                                     aff,
                                                     d_format)
            if rec_path is None:
                continue
            index.append([rec_path, lig_path, aff])

        df = pd.DataFrame(index, columns=['receptor','ligand','affinity'])
        df.to_csv(os.path.join(export_table_dir,'index.csv'), index=False)


