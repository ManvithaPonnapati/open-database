import tensorflow as tf123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport numpy as np123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef _matmul_point_pairs_by_kernel(pix_size,point_pairs,rel_coords,kernel,d_features,s_features=None):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    d_features will be concatenated to s_features when given123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    :param pixel_size:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    :param point_pairs:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    :param rel_coords:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    :param kernel:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    :param s_features:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    :param d_features:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    :return:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # todo assert shapes123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    k_dims = tf.shape(kernel)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    conv_dims = tf.shape(kernel)[0:3]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    k_size = tf.cast(tf.shape(kernel)[0:3], tf.float32)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # if kernel is given in 5D, flatten kernel from 5D into 3D123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    if np.asarray(kernel.get_shape()).size == 3:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        k_flat = kernel123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    elif np.asarray(kernel.get_shape()).size == 5:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        k_flatshape = tf.concat([[tf.reduce_prod(k_dims[0:3])],k_dims[3:5]],0)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        k_flat = tf.reshape(kernel,k_flatshape)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    else:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        raise ValueError("only 5D or 3D kernels are supported for sparse multiplication. Got size:",123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                         np.asarray(kernel.get_shape()).size)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    if s_features is None:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        feature_pairs = tf.gather(d_features, point_pairs[:, 1], validate_indices=True)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    else:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        s_features = tf.gather(s_features,point_pairs[:,0], validate_indices=True)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        d_features = tf.gather(d_features,point_pairs[:,1], validate_indices=True)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        feature_pairs = tf.concat([s_features,d_features], axis=1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # find indices on the flattened kernel to gather/slice123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    k_gatheridx = tf.cast((rel_coords / pix_size) + (k_size/2) + 0.5,tf.int32)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    k_gatheridx = tf.reduce_sum(k_gatheridx * tf.stack([conv_dims[0] * conv_dims[1], conv_dims[1], 1]),1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # gather slices of the kernels123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    k_shards = tf.gather(k_flat,k_gatheridx)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    convout = tf.matmul(tf.expand_dims(feature_pairs,1),k_shards)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    convout = convout[:, 0, :] # squeezing the empty central dimension123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return convout123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef _compute_feature_distance_matrix(atom_features, nbr_idx, batch_size, neighbors):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #atom_features: [B, N, d]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #nbr_idx: [B, N, M]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #gather the corresponding features of the neighbors for each atom123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    num_atoms = tf.shape(nbr_idx)[1]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    batch_pad = tf.convert_to_tensor(range(batch_size), dtype=tf.int32)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    batch_pad = tf.reshape(batch_pad, shape=[batch_size, 1, 1, 1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    batch_pad = tf.tile(batch_pad, [1, num_atoms, neighbors, 1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    nbr_idx_for_gather = tf.concat([batch_pad, tf.expand_dims(nbr_idx, 3)], axis=3)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    nbr_features = tf.gather_nd(atom_features, nbr_idx_for_gather)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #compute the distance matrix between each atom and neighbor features123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    feature_dist = tf.expand_dims(atom_features, axis=2) - nbr_features123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    feature_dist = tf.sqrt(tf.reduce_sum(tf.square(feature_dist), axis=3))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return feature_dist123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef _radial_filter(filter_means, filter_stds, distance_matrix, source_atoms, nbr_atoms, atom_mask, atom_types, radial_cutoff, radial_scaling, radial_bias):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #distance matrix: [B, N, M]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #TODO: embed the correct filters for each interaction type123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #embed the correct filters - one per source/dest atom type pair123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    param_selector = tf.expand_dims(source_atoms,-1) * (atom_types+1) + nbr_atoms123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    embed_means = tf.nn.embedding_lookup(params=filter_means, ids=param_selector)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    embed_stds = tf.nn.embedding_lookup(params=filter_stds, ids=param_selector)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #apply the Gaussian filters to create the corresponding output123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    distance_matrix = tf.expand_dims(distance_matrix, axis=-1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    distances_filtered = tf.exp(-((distance_matrix-embed_means)/embed_stds) ** 2)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #apply radial cutoff function and zeros activations for "nonexistent padded atoms"123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    distances_filtered *= tf.cos(np.pi * distance_matrix / radial_cutoff)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    distances_filtered *= tf.expand_dims(tf.cast(atom_mask, tf.float32), -1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    distances_filtered *= tf.cast(tf.logical_and(distance_matrix > 0, distance_matrix < radial_cutoff), tf.float32)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    distances_filtered = distances_filtered * tf.constant(radial_scaling) + tf.constant(radial_bias)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return distances_filtered123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef _atom_type_one_hot_expansion(distances_filtered, corr_atoms, atom_types):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #distances_filtered: [B, N, M, Nr]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #corr_atoms: [B, N, M]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    atoms_one_hot = tf.expand_dims(tf.one_hot(corr_atoms, atom_types+1)[:, :, :, 1:], 3)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    distances_expanded = tf.multiply(tf.expand_dims(distances_filtered, -1), atoms_one_hot)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return distances_expanded