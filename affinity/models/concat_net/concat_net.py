import tensorflow as tf123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport numpy as np123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport time,sys,os123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#sys.path.append("../")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFsys.path.append(os.path.join(os.path.dirname(__file__), "../../../"))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport affinity as af123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#import av4_networks123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#import av4_input123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFfrom config import FLAGS123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFtest_srcpnt_coords = tf.Variable(tf.random_uniform([15000,3],minval=1,maxval=40,dtype=tf.float32))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFtest_destpnt_coords = tf.Variable(tf.random_uniform([50,3],minval=1,maxval=40,dtype=tf.float32))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFtest_srcpnt_features = tf.Variable(tf.random_uniform([15000],minval=1,maxval=100,dtype=tf.float32))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFtest_destpnt_features = tf.Variable(tf.random_uniform([50],minval=1,maxval=100,dtype=tfpkill -9 python123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFfilename_queue, examples_in_database = af.input.index_pdbbind_database_into_q(FLAGS.database_path, shuffle=True)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFwith tf.variable_scope("epoch_counter"):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    batch_counter = tf.Variable(0)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    batch_counter_increment = tf.assign(batch_counter, tf.Variable(0).count_up_to(123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        np.round((examples_in_database * FLAGS.train_epochs) / FLAGS.batch_size)))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    epoch_counter = tf.div(batch_counter * FLAGS.batch_size, examples_in_database)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFligand_file,epoch_counter,label,lig_elem,lig_coord,rec_elem,rec_coord = af.input.read_rec_and_lig(123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    filename_queue,epoch_counter,lig_frame='OVERSAMPLING')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFwith tf.variable_scope("network"):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    net = af.networks.ConcatNet()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#logit = net.compute_output(lig_elem=test_srcpnt_features,lig_coord=test_srcpnt_coords,rec_elem=test_destpnt_features,rec_coord=test_destpnt_coords)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#logits = tf.expand_dims(logit,0)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#labels = tf.expand_dims(label,0)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#label_batch,logit_batch = tf.train.batch([label,logit],batch_size=100,capacity=1000,num_threads=20)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#cost = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=label,logits=logit)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#cost_mean = tf.reduce_mean(cost)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#train_step = tf.train.AdamOptimizer().minimize(cost)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFsess.run(tf.global_variables_initializer())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFcoord = tf.train.Coordinator()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFthreads = tf.train.start_queue_runners(sess=sess, coord=coord)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFtf.get_default_graph().finalize()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# print lig_coord.get_shape()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# print rec_coord.get_shape()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# print lig_elem.get_shape()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# print rec_elem.get_shape()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# print sess.run(tf.shape(s_feat))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# print sess.run(tf.shape(d_feat))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFwhile True:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    start = time.time()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # print sess.run(tf.shape(answer[1]))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print sess.run([logit])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print "exps:", "%.3f" % (1 / (time.time() - start))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF