"""123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFgenerate report for the database123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF"""123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport os123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport sys123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport numpy as np 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport pandas as pd 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport config123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFfrom db import database123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdb = database()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdataframe_dict = {}123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef load_dataframe():123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    db.export()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    for table in db.tables.keys():123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        try:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            csv_path = os.path.join(config.table_dir, table+'.csv')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        except IOError as e:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            print e123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            continue123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        dataframe_dict[table] = pd.read_csv(csv_path)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef gather_state():123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    gather report for state123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    state_tables = [tab for tab in dataframe_dict.keys() if tab.endswith('state')]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    state_tables = sorted(state_tables)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    records = []123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    for table in state_tables:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        csv_path = os.path.join(config.table_dir,table+'.csv')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        df = pd.read_csv(csv_path)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        success_entrys = df[df['state'] == 1]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        success_num = len(success_entrys)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        failed_entrys = df[df['state'] == 0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        failed_group = failed_entrys.groupby('comment')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        failed_count = []123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        for name, group in failed_group:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            failed_count.append(name, len(group))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        print table123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        print 'success : ', success_num123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        if len(failed_count):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            print 'failed : ' 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            for reason, num in failed_count:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                print "\t%d\t%s" % (num, reason)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        print '\n\n'123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef reporter_gen():123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ligands_atom = len(dataframe_dict['ligand_atom_num'])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    dock_df = dataframe_dict['dock_state']123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    dock_success = dock_df[dock_df['state']==1]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    dock_failed = dock_df[dock_df['state']==0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    failed_group = dock_failed.groupby('comment')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    failed_count = []123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    for name, group in failed_group:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        failed_count.append([name, len(group)])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print "=========\ndocking\n=========\n\n"123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ligands_num = len(ligands_atom)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print "total ligands : %d" % ligands_num123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    success = len(dock_success)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print "finished: %d\tpercents: %f" % (success, 100.0 * success/ligands_num)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    rest = ligands_num - success123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print "rest: %d\tpercent: %f " % ( rest, 10* rest/ ligands_num)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    for reason, failed_num in failed_count:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        print "%d ligands failed docking due to %s" % (failed_num, reason)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    receptor_info = dataframe_dict['receptor_info']123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    pair_cumsum = lambda x: (x-1)*x/2 if x>1 else 0123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ligands_pair_num = sum(receptor_info['residue_num'].apply(pair_cumsum))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    similarity123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    similar_df = dataframe_dict['similarity']123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    similar_group = similar_df.groupby('finger_print')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    similar_count = []123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    for name, group in similar_group:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        similar_count.append([name, len(group)])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print "=========\nsimilarity\n============\n\ns"123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    for finger_print, finish in similar_count:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        print "calculate similarity use finger print %s" % finger_print123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        print "finished: %d\tpercent: %f" % (finish, 100.0 * finish / ligands_pair_num)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        rest = ligands_pair_num - finish123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        print "rest: %d\tpercent: %f" % (rest, 100.0 * rest / ligands_pair_num)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    overlap123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #overlap_count_pairs = similar_df[similar_df['similarity']>config.tanimoto_cutoff]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    overlap_state = dataframe_dict['overlap_state']123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    overlap_group = overlap_state.groupby('finger_print')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    overlap_count = []123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    for name, group in overlap_group:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        overlap_count.append([name, len(group)])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print "overlap"123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    for finger_print, finish in overlap_count:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        print "overlap between ligands"123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    rmsd123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    rmsd_count_pairs = similar_df[similar_df['similarity']>config.tanimoto_cutoff]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    rmsd_state = dataframe_dict['rmsd_state']123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    rmsd_success = rmsd_state[rmsd_state['state']== 1]['docked_ligand','crystal_ligand']123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    rmsd_success = set(rmsd_success)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    rmsd_failed = rmsd_state[rmsd_state['state'] == 0]['docked_lgiand','crystal_ligand']123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    rmsd_failed = set(rmsd_failed)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    failed_group = rmsd_failed.groupby('comment')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    failed_count = []123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    for name, group in failed_group:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        failed_count.append([name, len(group)])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    rmsd_count_num = len(rmsd_count_pairs)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    success = len(rmsd_success)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print "rmsd"123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print "finished: %d\t percent: %f" % (success, 100.0 * success/rmsd_count_num)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    rest = rmsd_count_num - success123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print "rest: %d\t percent: %f" % (rest, 100.0 * rest/rmsd_count_num)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    for reason, failed_num in failed_count:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        print "%d pairs failed due to %s" % (failed_num, reason)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    overlap123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef _reporter_gen():123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    total_ligands_num = len(dataframe_dict['ligand_atom_num'])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    dock_group = dataframe_dict['dock_state'].groupby('identifier')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef rmsd_report():123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    pass123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFload_dataframe()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFreporter_gen()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF