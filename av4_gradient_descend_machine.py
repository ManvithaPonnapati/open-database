import time,re,threading,logging123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport tensorflow as tf123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport numpy as np123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport av4_input123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport av4_networks123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFfrom av4_config import FLAGS123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport av4_conformation_sampler123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport av4_cost_functions123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# create folders for logs and sumaries before any other part of the script has a chance to run123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFif tf.gfile.Exists(FLAGS.summaries_dir + "/" + str(FLAGS.run_name) +'_netstate' ) or \123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        tf.gfile.Exists(FLAGS.summaries_dir + "/" + str(FLAGS.run_name) + '_logs'):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    raise Exception('Summaries folder already exists. Please, change the run name, or delete it manually.')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFelse:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    tf.gfile.MakeDirs(FLAGS.summaries_dir + "/" + str(FLAGS.run_name) +'_netstate')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    tf.gfile.MakeDirs(FLAGS.summaries_dir + "/" + str(FLAGS.run_name) + '_logs')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFclass SamplingAgentonGPU:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    def __init__(self, agent_name, gpu_name, filename_queue, sampling_coord, training_queue, sess ):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.sampling_coord = sampling_coord123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.sess = sess123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.filename_queue = filename_queue123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.logger = logging.getLogger(agent_name)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        log_file = (FLAGS.summaries_dir + "/" + FLAGS.run_name + "_logs/" + agent_name + ".log")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.logger.addHandler(logging.FileHandler(log_file, mode='a'))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.ag = av4_conformation_sampler.SamplingAgent(agent_name,gpu_name,training_queue,self.logger)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.lig_file, _, _, self.lig_elem, self.lig_coord, self.rec_elem, self.rec_coord = \123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            av4_input.read_receptor_and_ligand(filename_queue=self.filename_queue, epoch_counter=tf.constant(0))  # FIXME: change epoch counter123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.logger.info("SamplingAgentonGPU:" + agent_name + "successfully initialized on device:" + gpu_name)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    def _count_example(self):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        if (self.sampling_coord.run_samples is not None) and (self.sampling_coord.run_samples > 0):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            with self.sampling_coord.lock:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                self.sampling_coord.run_samples = self.sampling_coord.run_samples - 1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            return None123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        elif (self.sampling_coord.run_samples is not None) and (self.sampling_coord.run_samples <= 0):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            self.sampling_coord.request_stop()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            return None123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        else:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            return None123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    def _do_sampling(self):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # with TF. device GPU1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # create an instance of a search agent that will run on this GPU123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        while not self.sampling_coord.should_stop():123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            try:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                # read receptor and ligand from the queue123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                # evaluate all positions for this ligand and receptor123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                my_lig_file, my_lig_elem, my_lig_coord, my_rec_elem, my_rec_coord = self.sess.run(123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                    [self.lig_file, self.lig_elem, self.lig_coord, self.rec_elem, self.rec_coord])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                self.ag.grid_evaluate_positions(my_lig_elem,my_lig_coord,my_rec_elem,my_rec_coord)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                self.logger.info("evaluated positions for:" + my_lig_file)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                self._count_example()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            except Exception as ex:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                self.sampling_coord.request_stop(ex=ex)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        return None123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    def start(self):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # start a thread for this agent123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        tr = threading.Thread(target=self._do_sampling)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.sampling_coord.threads.append(tr)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        tr.start()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFclass GradientDescendMachine:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """ Does sompling and training123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Controls sampling, infinite, or timely. Potentially, with many GPUs.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Dependencies: FLAGS.examples_in_database should be already calculated123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    def __init__(self,side_pixels=FLAGS.side_pixels, batch_size=FLAGS.batch_size):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # try to capture all of the events that happen in many background threads with tf.logging.DEBUG123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        tf.logging.set_verbosity(tf.logging.DEBUG)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        logging.basicConfig(level=logging.INFO)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # create a logger object only for the main threadf of the gradient descend machine123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.logger = logging.getLogger("machine")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        log_file = (FLAGS.summaries_dir + "/" + FLAGS.run_name + "_logs/machine.log")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.logger.addHandler(logging.FileHandler(log_file, mode='a'))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # create session to compute evaluation123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.sess = FLAGS.main_session123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # global_step is the total number steps of gradient descent (number of batches)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.global_step = 0123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # create a filename queue first123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        filename_queue,self.ex_in_database = av4_input.index_the_database_into_queue(FLAGS.database_path, shuffle=True)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # create a very large queue of images for central parameter server123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # TODO: make capacity adjustable123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.training_queue = tf.RandomShuffleQueue(capacity=1000000, min_after_dequeue=10,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                                    dtypes=[tf.float32,tf.float32],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                                    shapes=[[side_pixels,side_pixels,side_pixels],[]])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.training_queue_size = self.training_queue.size()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        tf.summary.scalar("training_queue_size",self.training_queue_size)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # create a way to train a network123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        image_batch,lig_RMSD_batch = self.training_queue.dequeue_many(batch_size)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.keep_prob = tf.placeholder(tf.float32)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        with tf.name_scope("network"):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            logits = av4_networks.max_net.compute_output(image_batch, self.keep_prob, FLAGS.batch_size)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.cost = av4_cost_functions.cross_entropy_with_RMSD(logits=logits,lig_RMSDs=lig_RMSD_batch)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        tf.summary.scalar('cost',tf.reduce_mean(self.cost))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        with tf.name_scope("Adam_optimizer"):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            self.train_step_run = tf.train.AdamOptimizer(1e-4).minimize(self.cost)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # configure sampling123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.sampling_coord = tf.train.Coordinator()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.sampling_coord.lock = threading.Lock()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.ag0 = SamplingAgentonGPU("AG0", "/gpu:0", filename_queue, self.sampling_coord, self.training_queue, self.sess)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#        self.ag1 = SamplingAgentonGPU("AG1", "/gpu:1", filename_queue, self.sampling_coord, self.training_queue, self.sess)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#        self.ag2 = SamplingAgentonGPU("AG2", "/gpu:2", filename_queue, self.sampling_coord, self.training_queue, self.sess)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#        self.ag3 = SamplingAgentonGPU("AG3", "/gpu:3", filename_queue, self.sampling_coord, self.training_queue, self.sess)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#        self.ag4 = SamplingAgentonGPU("AG4", "/gpu:4", filename_queue, self.sampling_coord, self.training_queue, self.sess)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#        self.ag5 = SamplingAgentonGPU("AG5", "/gpu:5", filename_queue, self.sampling_coord, self.training_queue, self.sess)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#        self.ag6 = SamplingAgentonGPU("AG6", "/gpu:6", filename_queue, self.sampling_coord, self.training_queue, self.sess)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#        self.ag7 = SamplingAgentonGPU("AG7", "/gpu:7", filename_queue, self.sampling_coord, self.training_queue, self.sess)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # merge all summaries and create a file writer object123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.merged_summaries = tf.summary.merge_all()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.summary_writer = tf.summary.FileWriter((FLAGS.summaries_dir + '/' + str(FLAGS.run_name) + "_logs"), self.sess.graph)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # create saver to save and load the network state123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.saver = tf.train.Saver(var_list=(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope="Adam_optimizer")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                         + tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope="network")))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                         #+ tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope="epoch_counter")))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        if FLAGS.saved_session is None:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            self.sess.run(tf.global_variables_initializer())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        else:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            self.sess.run(tf.global_variables_initializer())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            self.logger.info("Restoring variables from sleep. This may take a while...")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            self.saver.restore(self.sess,FLAGS.saved_session)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            self.logger.info("unitialized vars:", self.sess.run(tf.report_uninitialized_variables()))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # do not allow to add any nodes to the graph after this point123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        tf.get_default_graph().finalize()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    def do_sampling(self, sample_epochs=None):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        """ Controls all of the sampling by multiple agents123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.sampling_coord.threads = []123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        if sample_epochs is None:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            self.sampling_coord.run_samples = None123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        else:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            self.sampling_coord.run_samples = self.ex_in_database * sample_epochs123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        threads = tf.train.start_queue_runners(sess=self.sess, coord=self.sampling_coord)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.ag0.start()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#        self.ag1.start()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#        self.ag2.start()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#        self.ag3.start()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#        self.ag4.start()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#        self.ag5.start()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#        self.ag6.start()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#       self.ag7.start()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # in continuous regime return immediately leaving the threads to run on the background123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # in epoch regime wait for the task to complete, for the threads to stop, then return123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        if sample_epochs is not None:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            self.sampling_coord.join(self.sampling_coord.threads)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            self.sampling_coord.clear_stop()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        return None123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    def do_training(self, train_epochs=None):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        while True:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            if (self.global_step % 100 == 99):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                self.saver.save(self.sess, FLAGS.summaries_dir + '/' + str(FLAGS.run_name) + "_netstate/saved_state",123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                global_step=self.global_step)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                _, my_summaries, my_cost, my_training_queue_size = self.sess.run([self.train_step_run,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                                                                  self.merged_summaries,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                                                                  self.cost,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                                                                  self.training_queue_size],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                                                                 feed_dict={self.keep_prob:0.5})123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                self.summary_writer.add_summary(my_summaries, self.global_step)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            else:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                _, my_cost = self.sess.run([self.train_step_run, self.cost], feed_dict={self.keep_prob: 0.5})123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            self.logger.info("global step:" + str(self.global_step) + "softmax RMSD cost:" + str(my_cost))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            # increment the batch counter123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            self.global_step +=1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # should be cleaning the queue from the trash -- I think no123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        #123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # I will need memory in the future123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # is there a rule for fastest convergence ??123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # maybe, there is a rule Gradient/Second123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # simplest rule is cost update step123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # good networks will , probably, need a lot of sampling at the end if this thing ever converges123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # most of the cost is sampling (almost all) at moment X123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # let's go simplest and do distributed training123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # on all GPUs at the same time123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # ideally, it's infinite sampling per step of training123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # for best results sampling is absolute; any not absolute sampling is an exchange of efficacy for the speed123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # training is always a single step in the future123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # be not afraid of physics -- it brings good first-layer convolutions123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFa = GradientDescendMachine()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFa.do_sampling(sample_epochs=None)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFa.do_training(train_epochs=500)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFprint "All Done"