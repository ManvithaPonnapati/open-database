###Quick Introduction to Affinity  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF_The aim of the resources on this page is to allow anyone, even without specific machine learning background, to quickly get up to speeed with Affinity Core virtual screening engine. The estimated time for completions is under two weeks._123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF![alt_tag](https://github.com/mitaffinity/core/blob/master/misc/affinity_how2.png)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF####Background Readings123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF_If you are familiar with all of the concepts the list: weights, biases, activation function, ReLU, softmax, convolution, pooling, layers of depth, batch, gradient descent, backpropagation (and chain rule), AdamOptimizer, please feel free to skip to the next section._  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFCS231n "Convolutional Neural Networks for Visual Recognition"  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFhttp://cs231n.github.io/  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFPlease, read through  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFModule 1, Neural Networks      123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFModule 2, Convolutional Neural Networks   123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF####TensorFlow tutorials to complete123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF_If you are familiar with all of the concepts in this list: tensor graph, session, tf.global_variable_initializer, tf.train.coordinator, tf.train.start_queue_runners, tf.nn.sparse_softmax_cross_entropy_with_logits, tf.saver, tf.summary, tf.summary.FileWriter, tf.name_scope, please, feel free to skip to the next section._123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF[MNIST](https://www.tensorflow.org/tutorials/mnist/beginners/)  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF[Deep MNIST](https://www.tensorflow.org/tutorials/mnist/pros/)  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF[Understandig TensorFlow's workflow](https://www.tensorflow.org/tutorials/mnist/tf/)  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF[CIFAR10](https://www.tensorflow.org/tutorials/deep_cnn/)  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF[Deep Generative Adversarial Models](https://github.com/carpedm20/DCGAN-tensorflow)  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF####Introduction to Affinity Core123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF_Structure based virtual screening is an approach that allows to retrieve a very small percent, usually few dozens of molecules, from the large database, of millioons of chemical structures. The process can be imagined as a google search for a flexible key (ligand) with a 3D image of a rigid lock (receptor,protein). Search can be broken into two parts. Since the most optimal relative position of the drug and protein is not known, it has to be estimated (docking). Afterwards, many static protein-ligand complexes have to be ranked by their predicted relative binding affinity (sorting). Usually, 25,000-200,000 pose evaluations are done during docking, and a single pose evaluation is done during ranking. Because Tesla K80 GPU can only evaluate 100-200 images/second, position search for a single ligand may take anywhere between 3 and 35 minutes, docking the average-size database of 1,000,000 of molecules may take 1.2 GPU years. In this example we only apply the network to the previously docked with AutoDock Smina positions, IE: ranking._123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF[![network_search](https://github.com/mitaffinity/core/blob/master/misc/search.png)](https://youtu.be/qHxrW6NUjkU)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF####Step 1: teaching the network123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFYou will need four scripts, and the database123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFav4_networks.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFav4_main.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFav4_input.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFav4_utils.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFlabeled_av4123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFwhere `labeled_av4` is an already prepared database of the ligands and proteins in av4 binary format.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFav4_networks.py 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# is a library of many different network architectures123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# each of the networks accepts batch of images, and outputs batch of unscaled probabilities (logits)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# crucial part 1: the network itself123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# convolutional layers IE: tf.nn.conv3d123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# pooling layers IE: tf.nn.max_pool3d or tf.nn.avg_pool3d123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# Rectifier Linear Regression Units, or ReLUs IE: tf.nn.relu123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# crucial part 2: rules for variable initialization123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# IE: bias_variable 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# tf.constant(0.01, shape=shape)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# or weight variable123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# tf.truncated_normal(shape, stddev=0.005)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# initial weights and biases for trainable variables are usually initialized with small random positive 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# values. Deep networks can easily run out of control and owerflow the floats in higher layers 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# if not initialized properly.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# That's why it's important to initialize variables very accurately123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# especially deep networks can be hierarchically constructed 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# when the new layer(s) is added to the top of existing trained network123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# crucial part 3: variable summaries123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# IE: tf.summary.histogram, tf.summary.scalar, 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# and tf.name_scope (groups variables together under a common name)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# variable summaries are written in a separate file and help to monitor the state and evolution 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# of the network during training or testing123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFav4_input.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# is script that reads and indexes the database in av4 format, and creates batches of images123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# in 3D that can be fed to the network123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# av4 database consists of thousands of folders - one for each protein123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# each protein can have many ligands123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# each ligand av4 file can have many positions (frames), and every frame has it's label123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# the name of each folder IE 1QGT, 4G93 each correspond to a particular PDB id  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# original PDB file with coordinates can be found at http://www.rcsb.org/123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# crucial part 1: index_the_database_into_queue123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# crawls of all the folders in the database and creates tensor of filenames123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# crucial part 2: read_receptor_and_ligand123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# reads a single example of receptor and ligand from the database123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# returns coordinates and name (label) of every atom (only one frame depending on epoch counter)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# crucial part 3: convert_protein_and_ligand_to_image123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# creates an image (sparse or dense) from input atom coordinates123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# sparse image roughly can be described as array like123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# [[atom_tag1,x1,y1,z1]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#  [atom_tag2,x2,y2,z2]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#  [atom_tag3,x3,y3,z3]]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# dense image is a 3D cube filled with zeros and float numbers123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# both PDB and av4 store data in sparse representations123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# network, however, needs a 3D variant to do convolutions123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# crucial part 4: tf.train.batch (for three reasons)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# reason 1:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# it runs multiple independent threads of image creation123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# reason 2:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# it batches images together123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# single images are small and tensor operations in them (such as convolution or pooling)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# are not efficient. 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# reason 3:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# gradient descent optimizer gets much better gradient from multiple images. 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# Ideally, every single gradient descent step would be applied to a representative sample 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# of a whole database; this is better achievable with larger batches123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# av4_main.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# is a main script that assembles all of the parts together 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# crucial part 1: FLAGS123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# class that stores many global parameters of the script123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# such as FLAGS.pixels_size - determines the size of the pixel generated by av4_input123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# crucial part 2: train123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# assembles all of the parts together:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 1. input image creation pipeline              IE: ....something = image_and_label_queue 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 2. network that makes predictions             IE: intuit_net or nilai_net123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 3. cost function to minimize                  IE: tf.nn.sparse_softmax_cross_entropy_with_logits123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 4. optimizer(applies gradient descent steps)  IE: tf.train.AdamOptimizer123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 5. run while loop pipe the tensor graph       IE: sess.run(train_step_run)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# graph initialization commands:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 6. initializer of variables from placeholders IE: tf.global_variable_initializer 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 7. fill the graph skeleton with data inputs   IE: tf.train.start_queue_runners123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 8. also has saver of variable states          IE: tf.train.saver123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 9. variable summaries to visualize            IE: tf.summaries.writer123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 10. an epoch counter that counts every read through all proteins in database as one epoch123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFav4_utils.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# stores various utilities to support functions that are not natively present in TensorFlow123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF``` 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFhere is how a typical session on our Amazon graphical instance with K80 GPU would look like:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```bash123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# log into our remote machine 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# email maksym to get the key123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ ssh -i P2_key.pem ubuntu@awsinstance.com123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# every member of the group should have his or her folder123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ cd maksym123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# clone affinity core into your working directory 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFubuntu@ip-172-31-4-5:~/maksym$ git clone https://github.com/mitaffinity/core.git  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ cd core 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ python av4_main.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# does not work; the database is empty123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# point the script to the location of the database123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ vi (or any other command line text file editor; some people like nano) 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# the database has already been downloaded to the instance123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# change the database path under flags to   123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# /home/ubuntu/common/data/labeled_av4  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ python av4_main.py  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# does not work; needs latest tensorflow  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# tensorflow12 is hidden in an envoronmental variable 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ source $TF12  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# if you are interested what $TF12 it is:  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ echo $TF12 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF/home/ubuntu/common/venv/tf12/bin/activate  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# start training123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ python av4_main.py 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# seems to work, now it's time to launch this process for a while123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# the key is to launch it on the background, so it does not die when you log off123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# from your remote host. Use the '&' sign123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ python av4_main.py &  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# now background process will persist when you exit the session  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# now the nasty problem: TensorFlow tends not to die and hog on the GPU even after it's been terminated123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# also, there are many of us using GPU instance at the same time, but with TF's default settings123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# only one process will capture all VRAM on the GPU 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# see if anything is running on the GPU  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ nvidia-smi  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# should show the running processes, and how much VRAM each of them takes123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# you can also use top to monitor RAM and CPU123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ top123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# since it's a development instance, it is ok to kill all python processes with pkill -9 python123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# be carefull as it kills all the python processes that other people are running 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# it's ok to do it on our instance since it's consired to be only development zone for debugging123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ pkill -9 python123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ python av4_main.py &123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ exit123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFThe network training may take hours, or days depending on your dataset and architecture of the network. It's important to note that in our code the epoch is counted by protein-ligand pairs, not by images. Every protein-ligand pair may have multiple incorrect positions of the ligand 50-400, and a single correct, crystal position. In this case, it takes 100 epochs to only show all of the negatives to the network once. That is different from classical understanding of epochs in image recognition when images can't have multiple frames.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFRunning the code should have resulted in four folders with outputs:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF1_logs   123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF1_netstate   123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF1_test   123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF1_train  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF`1_logs` might be empty, and will be used to write outputs during evaluation.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF`1_netstate` will store the saved weights and biases for every trainable variable of the network 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF(and also all other variables, such as epoch counter)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF`1_train` and `1_test` should store summaries for variable states during training and testing that can123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFbe visualized. Let's expect the outputs of in the foders123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# log into our instance123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ ssh -i P2_key.pem ubuntu@awsinstance.com123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# now I am123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# ubuntu@ip-172-31-4-5:~$123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# cd maksym123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ cd /core/summaries123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ cd 1_netstate123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ ls -l123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# should show all of the files together with their size123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# IE: 96789276 Jan 29 16:55 saved_state-60999.data-00000-of-00001123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ cd ../1_train123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ ls123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# should show 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# events.out.tfevents.1485708632.ip-172-31-4-5123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# which is a tensorflow summaries file123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# let's try to visualize it:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# load tensorflow 0.12 (default version in the environment is 0.10)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ source $TF12123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# it's important to launch the tensorboard on port 80. By default internet browsers, such as chrome,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# will connect to port 80. You can read more here: 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# https://en.wikipedia.org/wiki/Port_(computer_networking)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# by default port 80 is not available to the user (the error is port is busy) that's why we use sudo123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ sudo python -m tensorflow.tensorboard --logdir=. --port=80123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# now you can navigate your browser to awsinstance.com123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF you should be able to see the following:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF![alt_tag](https://github.com/mitaffinity/core/blob/master/misc/cross_entropy.png)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFCross entropy (our cost function) goes down as we are training the network. 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF![alt_tag](https://github.com/mitaffinity/core/blob/master/misc/sparsity.png)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFSparsity of Rectifier Linear Unit is a percentage of zero-valued outputs of the layer. 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFIn chain rule for backpropagation, the derivative on sparse neuron is 0, and the derivative on downstream 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFneurons is also 0. If the sparsity for the layer is exactly 1, backpropagation does not work, and weights 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFcan't be updated. That is what frequently happens when the network "explodes" because of the incorrect weight initialization.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF![alt_tag](https://github.com/mitaffinity/core/blob/master/misc/histogram.png)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFBiases that all vere all initialized at 0.001 diverge as we are training our network. 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF####Step 2: evaluating the network123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFIn addition to four folders resulting from our previous step, you will need these three scripts:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF1_logs   123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF1_netstate   123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF1_test   123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF1_train  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFav4_eval.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFav4_input.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFav4_utils.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFthe only new script is `av4_eval`  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFav4_eval.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# av4_eval script is very similar to av4_main123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# crucial part 1:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# assembles all of the parts together:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 1. input image creation pipeline              IE: ....something = image_and_label_queue 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 2. network that makes predictions             IE: intuit_net or nilai_net123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 3. softmax instead of cost function in main   IE: tf.nn.softmax123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 4. no optimizer, variables are loaded         IE: saver.restore123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 5. run while loop pipe the tensor graph       IE: sess.run(train_step_run)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# crucial part 2: class store_predictions123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# stores, sorts, and saves predictions123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# estimates different evaluation parameters for straightforward binary classification such as 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# Area Under Curve https://en.wikipedia.org/wiki/Receiver_operating_characteristic123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# Confusion Matrix https://en.wikipedia.org/wiki/Confusion_matrix123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# crucial part 3: av4_eval can be used for two different tasks123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 1. distinguishing the correct position within many positions as in docking123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 2. sorting ligands each of which has many positions as in sorting123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 1 is very straightforward since our training consits of correct and incorrect positions, 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# we only need to score all of the available positions123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# our performance on task 1 is very high (AUC > 0.94)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 2 is not straighforward. Since many of the docked positions given to the network are not correct123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# (sometimes all of them)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFNow let's evaluate our script on distinguishing a single correct position from a single incorrect position, the same task it has been trained on. In this case testing set would be the part of the same dataset that was not used for training.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# Let's download the dataset from Kaggle to our local machine123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# navigate your browser to: https://inclass.kaggle.com/c/affinity4/data123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# and download holdout_av4.zip123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ scp -i P2_key.pem holdout_av4.zip ubuntu@awsinstance.com:/home/ubuntu/common/data123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ ssh -i P2_key.pem ubuntu@awsinstance.com123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ cd common123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# unzip the database 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ unzip holdout_av4.zip123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# get the path to current directory123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ pwd 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# /home/ubuntu/common/data/labeled_av4123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ cd ~/maksym/core/summaries/1_netstate123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ ls123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# note the latest step of the saved network123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# it's saved_state-60999.data-00000-of-00001 in my case123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ cd ../..123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# edit 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# FLAGS.saved_session = ./summaries/1_netstate/saved_state-60999123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# FLAGS.database_path = /home/ubuntu/common/data/labeled_av4123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ vi av4_eval.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# now source tensorflow 0.12 and launch the evaluation script123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ source $TF12123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ python av4_eval.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# ....123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# current_epoch: 6 batch_num: [82]  prediction averages: 0.538309   examples per second: 273.89123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# ......123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# all_done123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# the evaluation script should have written five files into the corresponding logs folder123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# in our case it's 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# saved_state-60999_average_submission.csv123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# saved_state-60999_max_submission.csv123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# saved_state-60999_multiframe_submission.csv123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# saved_state-60999_predictions.txt123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# saved_state-60999_scores.txt123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# for this kind of evaluation only two files are meaningful:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ vi saved_state-60999_predictions.txt123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# saved_state-60999_predictions.txt123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# has four columns:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# average_prediction   label   filename   predictions123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 1.0       1.0       1swd_465_ligand.av4_frame19                       1.0           123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 1.0       1.0       2pno_1757_ligand.av4_frame11                      1.0        123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 1.0       1.0       4d1j_4337_ligand.av4_frame13                      1.0             123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 1.0       1.0       4nul_138_ligand.av4_frame11                       1.0         123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 1.0       1.0       2pno_1757_ligand.av4_frame3                       1.0           123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 1.0       1.0       4nul_138_ligand.av4_frame15                       1.0,1.0            123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 1.0       1.0       4nul_138_ligand.av4_frame17                       1.0,1.0   123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# .....123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# ...123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 0.953     1.0       3n66_819_ligand.av4_frame9                        0.953    123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 0.953     1.0       3elz_401_ligand.av4_frame5                        0.953      123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 0.953     1.0       4rrw_2217_ligand.av4_frame8                       0.953 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 0.953     1.0       1gt6_538_ligand.av4_frame6                        0.953  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 0.953     1.0       1an5_533_ligand.av4_frame18                       0.953 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 0.953     1.0       4ki0_1898_ligand.av4_frame2                       0.953 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 0.953     1.0       1ivf_807_ligand.av4_frame18                       0.953  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# ....123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 0.002     0.0       3ekw_199_ligand.av4_frame3                        0.002   123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 0.002     0.0       2b0m_362_ligand.av4_frame0                        0.003,0.001   123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 0.002     0.0       1oya_399_ligand.av4_frame14                       0.002 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 0.002     0.0       2nxi_3110_ligand.av4_frame3                       0.002   123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 0.002     0.0       1yrh_1605_ligand.av4_frame5                       0.002   123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 0.001     0.0       3thq_430_ligand.av4_frame18                       0.001 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 0.001     0.0       1jvu_248_ligand.av4_frame2                        0.001123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 0.001     0.0       1yrh_1605_ligand.av4_frame17                      0.001123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# the reson that the last column has multiple entries is because same protein-ligand complex can be123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# evaluated several times. Because random affine transform (in av4_input) rotates and shifts the box 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# around protein-ligand complex randomly, every time an image in different orientation is evaluated123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# ideally, the network should be rotationally and translationally invariant. In that case all of the123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# values in the last column should be same. That is almost the case.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# another file to look at is saved_state-60999_scores.txt123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# some of the importat parameters such as AUC123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# AUC: 0.947862873006123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# and the confusion matrix: [[7835 1141] [1019 7764]]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# should be here.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# you can read more about AUC and the confusion matrix here: 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# https://en.wikipedia.org/wiki/Receiver_operating_characteristic123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFWe have applied our network to distinguish correct position of ligand from incorrect (docking), and it performed very well. Now let's try to apply our network to another stage of virtual screening - ranking. In this case we have multiple ligands (flexible keys), and a series of proteins (rigid locks). In this case we will not do the docking itself, but will use several proposed positions (400) by [smina](https://github.com/mwojcikowski/smina) for each of the ligands. 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF`unlabeleled_av4` contains 10 receptors and, on average, 200 ligands per receptor (100 actives and 100 inactives). There are top 400 positions predicted by smina positions in each ligand av4 file.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# edit the name of the database to be used for evaluations123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# to the location of the database at: /home/ubuntu/common/data/labeled_av4123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ vi av4_eval.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# run the eval script123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ python av4_eval.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# the number of epochs in the script FLAGS.num_epochs 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# will determine the number of frames per each ligand to be evaluated123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# this time we will re-rank only top 20 positions and not consider other 380123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# inspect the outputs of the script at 1_logs123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# cd ./summaries/1_logs123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# again you may find five files in the same folder:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ ls123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# saved_state-60999_average_submission.csv123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# saved_state-60999_max_submission.csv123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# saved_state-60999_multiframe_submission.csv123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# saved_state-60999_predictions.txt123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# saved_state-60999_scores.txt123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# this time another three files will carry meaning:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ less saved_state-60999_average_submission.csv123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# ID,Predicted123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 3zw2_270_ligand,0.944675922394123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 1rmg_432_ligand,0.979166805744123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 1b30_303_ligand,0.954633176327123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 3mw7_516_ligand,0.999969124794123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 3pby_439_ligand,0.999946951866123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 4mm5_499_ligand,0.999761760235123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 1ppf_286_ligand,0.954079449177123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# ...123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# ..123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# saved_state-60999_average_submission.csv123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# will store frame averages123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# saved_state-60999_max_submission.csv123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# will store maximum of the frames123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# and can be submitted to Kaggle directly123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# saved_state-60999_multiframe_submission.csv123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# will store all of the predictions separated by comma an can be used for future analysis123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# move all of the predictions to local machine123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ cd ..123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ tar zcvf 1_logs.tar.gz 1_logs123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ pwd123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# /home/ubuntu/maksym/core/summaries123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ exit123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ scp -i P2_key.pem ubuntu@awsinstance.com:/home/ubuntu/maksym/core/summaries/1_logs.tar.gz .123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ tar -xzvf 1_logs.tar.gz123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ cd 1_logs123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# now you are ready to submit your solution:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# please, navigate your browser to inclass/kaggle.com/c/affinity4123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# how much did you score123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# you can also use post-process 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# saved_state-60999_multiframe_submission.csv123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# for example, auc_script.py under /misc/ can calculate AUC for any given protein123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# receptor: aa2ar123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 0.575214145789123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# num predictions: 365123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# receptor: cp2c9123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 0.540473188014123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# num predictions: 627123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# ...123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# ..123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF####Step 3: database preparation (demo)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF_We are working hard to make our database construction scripts human-readable. We hope to finish in the near future_  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFDatabase construction is a very complex multistage process, perhaps much more complex than Affinity itself. There are few important things to notice.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFDatabase is constructed from X-ray crystallographic images from the [Protein Data Bank](http://www.rcsb.org/).123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFAnd binding affinity data is taken from databases like [PubChem](https://pubchem.ncbi.nlm.nih.gov/).123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFIn the process of preparation ligand is split from it's protein. In addition, fake positions can be generated with standard virtual screening algorithms like [Vina](http://vina.scripps.edu/manual.html).  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFOn the final stage `av4_database_master` joins pdb recods into a single database of binary files that can be read very fast during training of the network.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFData and .av4 format is, generally, stored in the following way123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# [label_for_frame_1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#  [[x11,y11,z11]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#   [x12,y12,z12]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#   [x13,y13,z13]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#   [x14,y14,z14]]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#   [atom_tag11,atom_tag12,atom_tag13,atom_tag14]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# [label_for_frame_2123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#  [[x21,y21,z21]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#   [x22,y22,z22]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#   [x23,y23,z23]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#   [x24,y24,z24]]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#   [atom_tag21,atom_tag22,atom_tag23,atom_tag24]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# ..........123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFFinally, the naming convention of the database is the following: 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```1a28123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF     1a28.av4123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF     1a28_500_ligand.av4123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF     1a28_501_ligand.av4123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF ```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF [1a28](http://www.rcsb.org/pdb/explore.do?structureId=1a28) is the structure ID in the PDB. `1a28.av4` is the protein itself, and `1a28_500_ligand.av4` and `1a28_501_ligand.av4` are two of it's ligands.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF####Step 4: running affinity on Bridges, XSEDE national supercomputer123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFIn steps 2 and 3 we have used Amazon instance that only has a single GPU to run the scripts. It make take up to a few days to train a deep CNN on protein images, and in industrial and scientific applications it's very reasonable to train networks with several different architectures at the same time. XSEDE (Extream Science and Engineering Discovery Environment) is a broad effort that controls access to most of the largest clusters in the US. In this tutorial we will use [Bridges](https://portal.xsede.org/psc-bridges) that has over a 100 GPUs. The current version of Affinity is written for a single GPU. But usually every user submits a few separate, unrelated jobs at the same time. 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# register for XSEDE here: https://portal.xsede.org/#/guest123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# and ask maksym to add you to our computer time grant 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# login to Bridges through XSEDE Single Sign-On (SSO) Hub. 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFbash123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ ssh [xsede_username]@login.xsede.org123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ gsissh bridges123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# each user is prowided with a high performance work directory would be different from your $HOME 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# (IE: /home/korablyo) for me. Work directory allows to read and write data much faster 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# you will need to find your work directory and put the database there123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# it is: /pylon1/[groupname]/[username]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# get groupname123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFbash123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ id -gn123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# clone Affinity source code to your work directory123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFbash123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ cd /pylon1/[groupname]/[username]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ git clone https://github.com/mitaffinity/core.git123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# now you will need to log in into our AWS instance to download the database to Bridges123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# you will need a .pem access key 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# just create a new text file , and copy-paste your key there123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFvi P2_key.pem123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# paste123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF:wq123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# change permissions of the key so that only you can read it 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# you can read more here: http://stackoverflow.com/questions/9270734/ssh-permissions-are-too-open-error123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ cd $HOME123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ chmod 400 key.pem123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# transfer data from aws instance to bridges123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFbash123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ cd  /pylon1/[groupname]/[username]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ scp -i $HOME/key.pem ubuntu@awsinstance.com:/home/ubuntu/common/data/labeled_av4.zip ./123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ unzip labeled_av4.zip123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# change FLAGS.database_path in av4_main.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# to database_path = "/pylon1/[groupname]/[username]/labeled_av4"123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFcreate batch script to submit your job. You can read more about submission queue [here](https://www.psc.edu/index.php/bridges/user-guide/running-jobs).123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFIn this case it is just a test file that will be executed by bash. You can use `vi` or any other command line text editor to create it.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#!/bin/bash123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#SBATCH -N 1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#SBATCH -p GPU123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#SBATCH --ntasks-per-node 28123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#SBATCH -t 48:00:00123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#SBATCH --gres=gpu:k80:4123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#echo commands to stdout123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFset -x123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#load module123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFmodule load cuda/8.0123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFmodule load tensorflow/0.12.1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#set python environment123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFsource $TENSORFLOW_ENV/bin/activate123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#move to working directory123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFcd /pylon1/[groupname]/[username]/core123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#run GPU program123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFpython av4_main.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF run your job123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ sbatch job.sh123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# monitor the status of your job with 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ squeue -u korablyo123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFJOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            893569       GPU   gpu.sh korablyo PD       0:00      1 (Priority)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            893570       GPU   gpu.sh korablyo PD       0:00      1 (Priority)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            893576       GPU   gpu.sh korablyo PD       0:00      1 (Priority)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            893890       GPU   gpu.sh korablyo PD       0:00      1 (Priority)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            893566       GPU   gpu.sh korablyo  R      26:15      1 gpu021123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            893557       GPU   gpu.sh korablyo  R      34:41      1 gpu038123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            893548       GPU   gpu.sh korablyo  R    1:21:00      1 gpu031123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            893554       GPU   gpu.sh korablyo  R    1:12:31      1 gpu040123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            893546       GPU   gpu.sh korablyo  R    2:32:33      1 gpu043123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            893540       GPU   gpu.sh korablyo  R    4:30:44      1 gpu039123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            893613       GPU   gpu.sh korablyo  R    4:09:42      1 gpu013123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# shows that I have seven pending jobs and four running jobs123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF