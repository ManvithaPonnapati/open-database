import tensorflow as tf123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport time123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# telling tensorflow how we want to randomly initialize weights123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef weight_variable(shape):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    initial = tf.truncated_normal(shape, stddev=0.005)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return tf.Variable(initial)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef bias_variable(shape):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    initial = tf.constant(0.01, shape=shape)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return tf.Variable(initial)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef variable_summaries(var, name):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """attaches a lot of summaries to a tensor."""123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.name_scope('summaries'):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        mean = tf.reduce_mean(var)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        tf.summary.scalar('mean/' + name, mean)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.name_scope('stddev'):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        tf.summary.scalar('stddev/' + name, stddev)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        tf.summary.scalar('max/' + name, tf.reduce_max(var))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        tf.summary.scalar('min/' + name, tf.reduce_min(var))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        tf.summary.histogram(name, var)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef conv_layer(layer_name, input_tensor, filter_size, strides=[1, 1, 1, 1, 1], padding='SAME'):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """makes a simple convolutional layer"""123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    input_depth = filter_size[3]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    output_depth = filter_size[4]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.name_scope(layer_name):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        with tf.name_scope('weights'):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            W_conv = weight_variable(filter_size)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            variable_summaries(W_conv, layer_name + '/weights')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        with tf.name_scope('biases'):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            b_conv = bias_variable([output_depth])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            variable_summaries(b_conv, layer_name + '/biases')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            h_conv = tf.nn.conv3d(input_tensor, W_conv, strides=strides, padding=padding) + b_conv123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            tf.summary.histogram(layer_name + '/pooling_output', h_conv)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print layer_name,"output dimensions:", h_conv.get_shape()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return h_conv123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef relu_layer(layer_name,input_tensor,act=tf.nn.relu):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """makes a simple relu layer"""123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.name_scope(layer_name):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        h_relu = act(input_tensor, name='activation')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        tf.summary.histogram(layer_name + '/relu_output', h_relu)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        tf.summary.scalar(layer_name + '/sparsity', tf.nn.zero_fraction(h_relu))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print layer_name, "output dimensions:", h_relu.get_shape()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return h_relu123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef pool_layer(layer_name,input_tensor,ksize,strides=[1, 1, 1, 1, 1],padding='SAME'):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """makes a simple max pooling layer"""123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.name_scope(layer_name):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        h_pool = tf.nn.max_pool3d(input_tensor,ksize=ksize,strides=strides,padding=padding)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        tf.summary.histogram(layer_name + '/max_pooling_output', h_pool)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print layer_name, "output dimensions:", h_pool.get_shape()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return h_pool123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef avg_pool_layer(layer_name,input_tensor,ksize,strides=[1, 1, 1, 1, 1],padding='SAME'):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """makes a average pooling layer"""123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.name_scope(layer_name):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        h_pool = tf.nn.avg_pool3d(input_tensor,ksize=ksize,strides=strides,padding=padding)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        tf.summary.histogram(layer_name + '/average_pooling_output', h_pool)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print layer_name, "output dimensions:", h_pool.get_shape()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return h_pool123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef fc_layer(layer_name,input_tensor,output_dim):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """makes a simple fully connected layer"""123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    input_dim = int((input_tensor.get_shape())[1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.name_scope(layer_name):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        weights = weight_variable([input_dim, output_dim])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        variable_summaries(weights, layer_name + '/weights')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.name_scope('biases'):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        biases = bias_variable([output_dim])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        variable_summaries(biases, layer_name + '/biases')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.name_scope('Wx_plus_b'):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        h_fc = tf.matmul(input_tensor, weights) + biases123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        tf.summary.histogram(layer_name + '/fc_output', h_fc)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print layer_name, "output dimensions:", h_fc.get_shape()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return h_fc123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef old_max_net(x_image_batch,keep_prob,batch_size):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    "makes a simple network that can receive 20x20x20 input images. And output 2 classes"123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.name_scope('input'):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        pass123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.name_scope("input_reshape"):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        print "image batch dimensions", x_image_batch.get_shape()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # formally adding one depth dimension to the input123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        x_image_batch = tf.reshape(x_image_batch, [batch_size, 20, 20, 20, 1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        print "input to the first layer dimensions", x_image_batch.get_shape()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    h_conv1 = conv_layer(layer_name='conv1_5x5x5', input_tensor=x_image_batch, filter_size=[5, 5, 5, 1, 20])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    h_relu1 = relu_layer(layer_name='relu1', input_tensor=h_conv1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    h_pool1 = pool_layer(layer_name='pool1_2x2x2', input_tensor=h_relu1, ksize=[1, 2, 2, 2, 1], strides=[1, 2, 2, 2, 1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    h_conv2 = conv_layer(layer_name="conv2_3x3x3", input_tensor=h_pool1, filter_size=[3, 3, 3, 20, 30])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    h_relu2 = relu_layer(layer_name="relu2", input_tensor=h_conv2)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    h_pool2 = pool_layer(layer_name="pool2_2x2x2", input_tensor=h_relu2, ksize=[1, 2, 2, 2, 1], strides=[1, 2, 2, 2, 1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    h_conv3 = conv_layer(layer_name="conv3_2x2x2", input_tensor=h_pool2, filter_size=[2, 2, 2, 30, 40])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    h_relu3 = relu_layer(layer_name="relu3", input_tensor=h_conv3)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    h_pool3 = pool_layer(layer_name="pool3_2x2x2", input_tensor=h_relu3, ksize=[1, 2, 2, 2, 1], strides=[1, 1, 1, 1, 1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    h_conv4 = conv_layer(layer_name="conv4_2x2x2", input_tensor=h_pool3, filter_size=[2, 2, 2, 40, 50])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    h_relu4 = relu_layer(layer_name="relu4", input_tensor=h_conv4)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    h_pool4 = pool_layer(layer_name="pool4_2x2x2", input_tensor=h_relu4, ksize=[1, 2, 2, 2, 1], strides=[1, 1, 1, 1, 1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    h_conv5 = conv_layer(layer_name="conv5_2x2x2", input_tensor=h_pool4, filter_size=[2, 2, 2, 50, 60])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    h_relu5 = relu_layer(layer_name="relu5", input_tensor=h_conv5)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    h_pool5 = pool_layer(layer_name="pool5_2x2x2", input_tensor=h_relu5, ksize=[1, 2, 2, 2, 1], strides=[1, 1, 1, 1, 1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.name_scope("flatten_layer"):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        h_pool2_flat = tf.reshape(h_pool5, [-1, 5 * 5 * 5 * 60])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    h_fc1 = fc_layer(layer_name="fc1", input_tensor=h_pool2_flat, output_dim=1024)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    h_fc1_relu = relu_layer(layer_name="fc1_relu", input_tensor=h_fc1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.name_scope("dropout"):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        tf.summary.scalar('dropout_keep_probability', keep_prob)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        h_fc1_drop = tf.nn.dropout(h_fc1_relu, keep_prob)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    h_fc2 = fc_layer(layer_name="fc2", input_tensor=h_fc1_drop, output_dim=256)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    h_fc2_relu = relu_layer(layer_name="fc2_relu", input_tensor=h_fc2)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    y_conv = fc_layer(layer_name="out_neuron", input_tensor=h_fc2_relu, output_dim=2)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return y_conv123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFclass MaxNet:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    def __init__(self):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.w1 = weight_variable([5, 5, 5, 1, 20])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.w2 = weight_variable([3, 3, 3, 20, 30])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.w3 = weight_variable([2, 2, 2, 30, 40])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.w4 = weight_variable([2, 2, 2, 40, 50])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.w5 = weight_variable([2, 2, 2, 50, 60])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.b1 = bias_variable([20])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.b2 = bias_variable([30])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.b3 = bias_variable([40])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.b4 = bias_variable([50])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.b5 = bias_variable([60])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.fc1w = weight_variable([7500,1024])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.fc1b = bias_variable([1024])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.fc2w = weight_variable([1024,256])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.fc2b = bias_variable([256])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.fc3w = weight_variable([256,2])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.fc3b = bias_variable([2])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    def compute_output(self,image_batch,keep_prob,batch_size):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        x_image_batch = tf.reshape(image_batch, [batch_size, 20, 20, 20, 1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        h_conv1 = tf.nn.conv3d(x_image_batch,self.w1, strides=[1,1,1,1,1], padding='SAME') + self.b1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        h_relu1 = tf.nn.relu(h_conv1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        h_pool1 = tf.nn.max_pool3d(h_relu1,ksize=[1, 2, 2, 2, 1],strides=[1, 2, 2, 2, 1],padding='SAME')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        h_conv2 = tf.nn.conv3d(h_pool1,self.w2, strides=[1,1,1,1,1], padding='SAME') + self.b2123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        h_relu2 = tf.nn.relu(h_conv2)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        h_pool2 = tf.nn.max_pool3d(h_relu2, ksize=[1, 2, 2, 2, 1], strides=[1, 2, 2, 2, 1], padding='SAME')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        h_conv3 = tf.nn.conv3d(h_pool2, self.w3, strides=[1, 1, 1, 1, 1], padding='SAME') + self.b3123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        h_relu3 = tf.nn.relu(h_conv3)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        h_pool3 = tf.nn.max_pool3d(h_relu3, ksize=[1, 1, 1, 1, 1], strides=[1, 1, 1, 1, 1], padding='SAME')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        h_conv4 = tf.nn.conv3d(h_pool3, self.w4, strides=[1, 1, 1, 1, 1], padding='SAME') + self.b4123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        h_relu4 = tf.nn.relu(h_conv4)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        h_pool4 = tf.nn.max_pool3d(h_relu4, ksize=[1, 1, 1, 1, 1], strides=[1, 1, 1, 1, 1], padding='SAME')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        h_conv5 = tf.nn.conv3d(h_pool4, self.w5, strides=[1, 1, 1, 1, 1], padding='SAME') + self.b5123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        h_relu5 = tf.nn.relu(h_conv5)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        h_pool5 = tf.nn.max_pool3d(h_relu5, ksize=[1, 1, 1, 1, 1], strides=[1, 1, 1, 1, 1], padding='SAME')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        h_pool2_flat = tf.reshape(h_pool5, [-1, 5 * 5 * 5 * 60])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,self.fc1w) + self.fc1b)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        h_fc2 = tf.nn.relu(tf.matmul(h_fc1_drop, self.fc2w) + self.fc2b)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        y_conv = tf.matmul(h_fc2, self.fc3w) + self.fc3b123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        return y_conv123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFmax_net = MaxNet()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# New stuff ahead of time__________________________________________________________________________________________________________________________________:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFpixel_size = tf.constant(0.5,tf.float32)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFfilter_size = tf.constant([5,5,5],tf.int32)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFtest_srcpnt_coords = tf.Variable(tf.random_uniform([1100,3],minval=1,maxval=40,dtype=tf.float32))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFtest_destpnt_coords = tf.Variable(tf.random_uniform([900,3],minval=1,maxval=40,dtype=tf.float32))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFsess.run(tf.global_variables_initializer())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef pointcloud_pairlist(source_points,dest_points,cutoffs_xyz):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Find pairs of points between source and destination clouds within the cutoff distance123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Args:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        source_cloud:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        dest_cloud:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        cutoff:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Returns:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    int32 tensor indexes of pairs of points within the cuttoff123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # todo assert fits;123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # convert to canonical float 32123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcpnt_coords = tf.to_float(source_points)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destpnt_coords = tf.to_float(dest_points)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    cutoffs_xyz = tf.to_float(cutoffs_xyz)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    point_mean = tf.reduce_mean(tf.concat([srcpnt_coords,destpnt_coords],0),reduction_indices=0)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcpnt_coords = srcpnt_coords - point_mean123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destpnt_coords = destpnt_coords - point_mean123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # index source and destination points123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    num_srcpnt = tf.shape(srcpnt_coords)[0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcpnt_idx = tf.to_int64(tf.range(num_srcpnt))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    num_destpnt = tf.shape(destpnt_coords)[0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destpnt_idx = tf.to_int64(tf.range(num_destpnt))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # define a grid of the size cutoff around both of the point clouds123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcgrid_coords = tf.to_int64((source_points / cutoffs_xyz)+0.5)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destgrid_coords = tf.to_int64((dest_points / cutoffs_xyz)+0.5)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # sort both source and destination clouds123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcgrid_stensor = tf.SparseTensor(indices=srcgrid_coords,values=srcpnt_idx,dense_shape=[1,1,1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcgrid_stensor = tf.sparse_reorder(srcgrid_stensor)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destgrid_stensor = tf.SparseTensor(indices=destgrid_coords,values=destpnt_idx,dense_shape=[1,1,1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destgrid_stensor = tf.sparse_reorder(destgrid_stensor)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcgrid_coords = tf.cast(srcgrid_stensor.indices,tf.int16)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcgrid_order = srcgrid_stensor.values123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destgrid_coords = tf.cast(destgrid_stensor.indices,tf.int16)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destgrid_order = destgrid_stensor.values123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # find the number of points in every grid (start + end)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # commented out waiting for custom C op to make multiple slices123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #srcgrid_names = tf.bitcast(tf.concat([srcgrid_coords,tf.zeros([num_srcpnt,1],tf.int16)],1),tf.int64)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #unq_srcgrid_names,srcgrid_ids,srcgrid_counts = tf.unique_with_counts(srcgrid_names)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #srcgrid_starts = tf.segment_min(srcpnt_idx,srcgrid_ids)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destgrid_names = tf.bitcast(tf.concat([destgrid_coords,tf.zeros([num_destpnt,1],tf.int16)],1),tf.int64)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    unq_destgrid_names,destgrid_ids,destgrid_counts = tf.unique_with_counts(destgrid_names)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destgrid_starts = tf.segment_min(destpnt_idx,destgrid_ids)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # use source grid points to search for the destination grid cells123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    starts_counts = tf.stack([tf.to_int32(destgrid_starts),tf.to_int32(destgrid_counts)],axis=1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    starts_counts_zip = tf.bitcast(starts_counts,tf.int64)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    empty_key = tf.bitcast(tf.constant([0,0,0,1],tf.int16),tf.int64)    # some impossible key (all our keys end with 0)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destgrid_hash = tf.contrib.lookup.MutableDenseHashTable(key_dtype=tf.int64, value_dtype=tf.int64, default_value=0, empty_key=empty_key, checkpoint=False)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destgrid_hash_init = destgrid_hash.insert(unq_destgrid_names, starts_counts_zip)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # itself            (1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # face neighbors    (6)  : +/-1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # edge neighbors    (12) : +/-1 +/-1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # vertex neighbors  (8)  : +/-1 +/-1 +/-1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    neighbor_shift = tf.constant([[0,0,0],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                  [0,0,1],[0,1,0],[1,0,0],[0,0,-1],[0,-1,0],[-1,0,0],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                  [0,1,1],[1,0,1],[1,1,0],[0,-1,-1],[-1,0,-1],[-1,-1,0],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                  [0,1,-1],[1,0,-1],[1,-1,0],[0,-1,1],[-1,0,1],[-1,1,0],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                  [1,1,1],[1,1,-1],[1,-1,1],[-1,1,1],[1,-1,-1],[-1,1,-1],[-1,-1,1],[-1,-1,-1]],tf.int16)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    neighbor_shifts = tf.tile(neighbor_shift,[num_srcpnt,1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcgrid_nhb_coords = tf.reshape(tf.tile(srcgrid_coords,[1,27]),[-1,3]) + neighbor_shifts123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcgrid_nhb_names = tf.bitcast(tf.concat([srcgrid_nhb_coords,tf.zeros([num_srcpnt*27,1],tf.int16)],1),tf.int64)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcgrid_src_idx = tf.reshape(tf.tile(tf.expand_dims(srcpnt_idx, 1), [1, 27]), [-1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.get_default_graph().control_dependencies([destgrid_hash_init]):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        destpnt_slices = destgrid_hash.lookup(srcgrid_nhb_names)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # only retain source and destination points for the filters that are not empty123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    filter_notempty = tf.not_equal(destpnt_slices, [0])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcgrid_src_idx = tf.boolean_mask(srcgrid_src_idx, filter_notempty)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destpnt_slices = tf.boolean_mask(destpnt_slices, filter_notempty)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # convert slices into indexes of source/destination points; map indices back the initial order (before sorting)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destpnt_slices = tf.bitcast(destpnt_slices, tf.int32)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcpnt_src_idx = int_repeat(srcgrid_src_idx, destpnt_slices[:, 1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destpnt_dest_idx = int_sequence(destpnt_slices[:,0],destpnt_slices[:,1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcpnt_src_idx = tf.gather(srcgrid_order,srcpnt_src_idx)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destpnt_dest_idx = tf.gather(destgrid_order,destpnt_dest_idx)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # one more round of cropping to fit discard the points which fall outside of the centered on the point filter123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcpnt_src_coords = tf.gather(srcpnt_coords, srcpnt_src_idx)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destpnt_dest_coords = tf.gather(destpnt_coords, destpnt_dest_idx)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destpnt_rel_coords = destpnt_dest_coords - srcpnt_src_coords123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    in_radii_of_src = tf.reduce_all(tf.abs(destpnt_rel_coords) < cutoffs_xyz,1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destpnt_rel_coords = tf.boolean_mask(destpnt_rel_coords,in_radii_of_src)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcpnt_src_idx = tf.boolean_mask(srcpnt_src_idx,in_radii_of_src)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destpnt_dest_idx = tf.boolean_mask(destpnt_dest_idx,in_radii_of_src)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return srcpnt_src_idx,destpnt_dest_idx,destpnt_rel_coords123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef int_sequence(starts,lengths,abs_upper_limit=10000000):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Creates a range(s) of integer numbers starting at start, and with a length length.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Args:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        starts: int32/int64 array of shape [1]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        lengths: int32/int64 array of shape [1]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        abs_upper_limit: highest integer that can exist in sequence123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Returns:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Returns a concatenated string of ranges of type int32123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Example:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        int_sequence([3,5,7],[2,4,6])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Returns123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        [3,4,5,6,7,8,7,8,9,10,11,12]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # TODO: is Variable faster compared to constant ?123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    rangestring = tf.constant(np.arange(abs_upper_limit,dtype=np.int32).tobytes())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    byte_sequence = tf.reduce_join(tf.substr(rangestring,4*starts,4*lengths))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    int_sequence = tf.decode_raw(byte_sequence,tf.int32)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return int_sequence123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef int_repeat(integers, repeats, abs_repeat_limit = 100000):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Given 1D array of integers, and 1D of array of repeats of the same length as an array of integers repeats every123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    integer number of repeats time.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Args:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        integers: 1D tensor of int32/int64 numbers123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        repeats: 1D tensor of int32/int64123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        abs_repeat_limit: int32/int64 highest number of repeats used in the run of the program123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Returns:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        1D tensor of int32 of the length tf.reduce_sum(repeats)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # TODO assert repeat limit does not break int32123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    integers = tf.to_int32(integers)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    repeats = tf.to_int32(repeats)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # every int32 string can be represented as 4 uint8 strings123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # a long string with abs_repeat_limit of every possible 1-255 uint8 numbers is created123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    uint8_string = tf.constant(np.tile(np.expand_dims(123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        np.arange(256,dtype=np.uint8), axis=1), reps=[1,abs_repeat_limit]).reshape([-1]).tobytes())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # determine the location of the slices from a long uint8 string123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    substr_starts = tf.reshape(tf.to_int32(tf.bitcast(integers,tf.uint8)) * abs_repeat_limit,[-1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    substr_lengths = tf.reshape(tf.tile(tf.expand_dims(repeats,1),[1,4]),[-1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    sliced_bytes = tf.substr(uint8_string,substr_starts,substr_lengths)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # convert slices into uint 8, and 4 uint8 numbers into int32123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    uint8_repeat = tf.decode_raw(tf.reduce_join(tf.reshape(sliced_bytes, [-1, 4]), reduction_indices=0), tf.uint8)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    int32_repeat = tf.bitcast(tf.transpose(uint8_repeat,[1,0]),tf.int32)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return int32_repeat123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# TOP_K stuff _______________________________________________________________________________________________123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef pointcloud_pairlist(source_points,dest_points,cutoffs_xyz):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Find pairs of points between source and destination clouds within the cutoff distance123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Args:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        source_cloud:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        dest_cloud:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        cutoff:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Returns:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    int32 tensor indexes of pairs of points within the cuttoff123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # todo assert fits;123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # convert to canonical float 32123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcpnt_coords = tf.to_float(source_points)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destpnt_coords = tf.to_float(dest_points)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    cutoffs_xyz = tf.to_float(cutoffs_xyz)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    point_mean = tf.reduce_mean(tf.concat([srcpnt_coords,destpnt_coords],0),reduction_indices=0)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcpnt_coords = srcpnt_coords - point_mean123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destpnt_coords = destpnt_coords - point_mean123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # index source and destination points123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    num_srcpnt = tf.shape(srcpnt_coords)[0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcpnt_idx = tf.to_int64(tf.range(num_srcpnt))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    num_destpnt = tf.shape(destpnt_coords)[0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destpnt_idx = tf.to_int64(tf.range(num_destpnt))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # define a grid of the size cutoff around both of the point clouds123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcgrid_coords = tf.to_int64((source_points / cutoffs_xyz)+0.5)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destgrid_coords = tf.to_int64((dest_points / cutoffs_xyz)+0.5)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # sort both source and destination clouds123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcgrid_stensor = tf.SparseTensor(indices=srcgrid_coords,values=srcpnt_idx,dense_shape=[1,1,1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcgrid_stensor = tf.sparse_reorder(srcgrid_stensor)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destgrid_stensor = tf.SparseTensor(indices=destgrid_coords,values=destpnt_idx,dense_shape=[1,1,1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destgrid_stensor = tf.sparse_reorder(destgrid_stensor)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcgrid_coords = tf.cast(srcgrid_stensor.indices,tf.int16)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcgrid_order = srcgrid_stensor.values123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destgrid_coords = tf.cast(destgrid_stensor.indices,tf.int16)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destgrid_order = destgrid_stensor.values123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # find the number of points in every grid (start + end)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # commented out waiting for custom C op to make multiple slices123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #srcgrid_names = tf.bitcast(tf.concat([srcgrid_coords,tf.zeros([num_srcpnt,1],tf.int16)],1),tf.int64)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #unq_srcgrid_names,srcgrid_ids,srcgrid_counts = tf.unique_with_counts(srcgrid_names)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #srcgrid_starts = tf.segment_min(srcpnt_idx,srcgrid_ids)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destgrid_names = tf.bitcast(tf.concat([destgrid_coords,tf.zeros([num_destpnt,1],tf.int16)],1),tf.int64)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    unq_destgrid_names,destgrid_ids,destgrid_counts = tf.unique_with_counts(destgrid_names)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destgrid_starts = tf.segment_min(destpnt_idx,destgrid_ids)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # use source grid points to search for the destination grid cells123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    starts_counts = tf.stack([tf.to_int32(destgrid_starts),tf.to_int32(destgrid_counts)],axis=1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    starts_counts_zip = tf.bitcast(starts_counts,tf.int64)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    empty_key = tf.bitcast(tf.constant([0,0,0,1],tf.int16),tf.int64)    # some impossible key (all our keys end with 0)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destgrid_hash = tf.contrib.lookup.MutableDenseHashTable(key_dtype=tf.int64, value_dtype=tf.int64, default_value=0, empty_key=empty_key, checkpoint=False)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destgrid_hash_init = destgrid_hash.insert(unq_destgrid_names, starts_counts_zip)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # itself            (1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # face neighbors    (6)  : +/-1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # edge neighbors    (12) : +/-1 +/-1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # vertex neighbors  (8)  : +/-1 +/-1 +/-1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    neighbor_shift = tf.constant([[0,0,0],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                  [0,0,1],[0,1,0],[1,0,0],[0,0,-1],[0,-1,0],[-1,0,0],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                  [0,1,1],[1,0,1],[1,1,0],[0,-1,-1],[-1,0,-1],[-1,-1,0],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                  [0,1,-1],[1,0,-1],[1,-1,0],[0,-1,1],[-1,0,1],[-1,1,0],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                  [1,1,1],[1,1,-1],[1,-1,1],[-1,1,1],[1,-1,-1],[-1,1,-1],[-1,-1,1],[-1,-1,-1]],tf.int16)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    neighbor_shifts = tf.tile(neighbor_shift,[num_srcpnt,1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcgrid_nhb_coords = tf.reshape(tf.tile(srcgrid_coords,[1,27]),[-1,3]) + neighbor_shifts123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcgrid_nhb_names = tf.bitcast(tf.concat([srcgrid_nhb_coords,tf.zeros([num_srcpnt*27,1],tf.int16)],1),tf.int64)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcgrid_src_idx = tf.reshape(tf.tile(tf.expand_dims(srcpnt_idx, 1), [1, 27]), [-1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.get_default_graph().control_dependencies([destgrid_hash_init]):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        destpnt_slices_zip = destgrid_hash.lookup(srcgrid_nhb_names)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # pad number of neighbors to the same size123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destpnt_slices = tf.bitcast(destpnt_slices_zip, tf.int32)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcpnt_num_nhb = tf.segment_sum(destpnt_slices[:,1], srcgrid_src_idx)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    max_nhb = tf.reduce_max(srcpnt_num_nhb)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    pad_slices = tf.concat([tf.ones([num_srcpnt,1],tf.int32)*num_destpnt,tf.expand_dims(max_nhb - srcpnt_num_nhb,1)],1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    pad_slices_zip = tf.bitcast(pad_slices,tf.int64)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destpnt_slices_zip = tf.reshape(tf.concat([tf.reshape(destpnt_slices_zip,[num_srcpnt,27]),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                               tf.expand_dims(pad_slices_zip,1)],1),[-1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destpnt_slices = tf.bitcast(destpnt_slices_zip,tf.int32)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # todo pad123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #srcgrid_src_idx = tf.reshape(tf.tile(tf.expand_dims(srcpnt_idx, 1), [1, 28]), [-1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destgrid_order_pad = tf.concat([destgrid_order,tf.to_int64(tf.range(num_destpnt,num_destpnt+max_nhb))],0)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #destpnt_coords_pad = tf.concat([destpnt_coords,tf.zeros([max_nhb,3])],0)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # crop123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    nonzero_slice = tf.not_equal(destpnt_slices[:,1],0)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destpnt_slices = tf.boolean_mask(destpnt_slices,nonzero_slice)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #srcgrid_src_idx = tf.boolean_mask(srcgrid_src_idx,nonzero_slice)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # generate ranges with numbergatan123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcpnt_src_idx = tf.reshape(tf.tile(tf.expand_dims(srcpnt_idx,1),[1,max_nhb]),[-1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destpnt_dest_idx = numbergatan.int_sequence(destpnt_slices[:, 0], destpnt_slices[:, 1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # get relative point coords -> distance123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcpnt_src_idx = tf.gather(srcgrid_order,srcpnt_src_idx)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destpnt_dest_idx = tf.gather(destgrid_order_pad,destpnt_dest_idx)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcpnt_src_coords = tf.gather(srcpnt_coords, srcpnt_src_idx)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destpnt_dest_coords = tf.gather(destpnt_coords, destpnt_dest_idx)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destpnt_srcpnt_dist = tf.reduce_sum((destpnt_dest_coords - srcpnt_src_coords)**2,reduction_indices=1)**0.5123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # substitute distance for the biggest integer, and idx to the -1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    if_pad = destpnt_dest_idx > tf.to_int64(num_destpnt - 1) # todo123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    biggest_float = tf.ones([num_srcpnt*max_nhb]) * 2147483647123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    empty_key = tf.ones([num_srcpnt*max_nhb],tf.int64)*-1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destpnt_dest_idx = tf.where(if_pad,empty_key,destpnt_dest_idx)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destpnt_srcpnt_dist = tf.where(if_pad,biggest_float,destpnt_srcpnt_dist)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # order by the distance from the source123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destpnt_srcpnt_dist = tf.reshape(destpnt_srcpnt_dist,[num_srcpnt,max_nhb])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destpnt_srcpnt_dist,order_by_dist = tf.nn.top_k(destpnt_srcpnt_dist,k=max_nhb)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destpnt_dest_idx = tf.reshape(destpnt_dest_idx,[num_srcpnt,max_nhb])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destpnt_dest_idx = tf.gather(destpnt_dest_idx,order_by_dist)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # crop empty (and bad) filters123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # generate ranges with numbergatan123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # have a gigantic repeat (len max_nhbr) x num_pnts123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # get relative point coordinates -> distance123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # get an index mask of existing points123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # update distances to biggest integer with ex mask123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # reshape and sort relative distances123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # use existence mask to rename destpoint idx into -1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # reorder the existence mask by the order from topK123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # only retain source and destination points for the filters that are not empty123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #filter_notempty = tf.not_equal(destpnt_slices, [0]) # todo also remove bad slices of123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #srcgrid_src_idx = tf.boolean_mask(srcgrid_src_idx, filter_notempty)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #destpnt_slices = tf.boolean_mask(destpnt_slices, filter_notempty)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # # convert slices into indexes of source/destination points; map indices back the initial order (before sorting)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # destpnt_slices = tf.bitcast(destpnt_slices, tf.int32)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # srcpnt_src_idx = numbergatan.int_repeat(srcgrid_src_idx, destpnt_slices[:, 1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # destpnt_dest_idx = numbergatan.int_sequence(destpnt_slices[:,0],destpnt_slices[:,1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # srcpnt_src_idx = tf.gather(srcgrid_order,srcpnt_src_idx)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # destpnt_dest_idx = tf.gather(destgrid_order,destpnt_dest_idx)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # # one more round of cropping to fit discard the points which fall outside of the centered on the point filter123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # srcpnt_src_coords = tf.gather(srcpnt_coords, srcpnt_src_idx)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # destpnt_dest_coords = tf.gather(destpnt_coords, destpnt_dest_idx)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # destpnt_rel_coords = destpnt_dest_coords - srcpnt_src_coords123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # in_radii_of_src = tf.reduce_all(tf.abs(destpnt_rel_coords) < cutoffs_xyz,1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # destpnt_rel_coords = tf.boolean_mask(destpnt_rel_coords,in_radii_of_src)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # srcpnt_src_idx = tf.boolean_mask(srcpnt_src_idx,in_radii_of_src)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # destpnt_dest_idx = tf.boolean_mask(destpnt_dest_idx,in_radii_of_src)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return destpnt_dest_idx,destpnt_srcpnt_dist123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF### Revision 4 convenient for Brian (at this moment we have fast number range generators).123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport tensorflow as tf123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport numbergatan123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport time123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFint_repeat_module = tf.load_op_library('/home/maksym/PyCharmProjects/tensorMe25_C/int_repeat.so')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFint_sequence_module = tf.load_op_library('/home/maksym/PyCharmProjects/tensorMe25_C/int_sequence.so')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFsess = tf.Session()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFpixel_size = tf.constant(0.5,tf.float32)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFfilter_size = tf.constant([5,5,5],tf.int32)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFtest_srcpnt_coords = tf.Variable(tf.random_uniform([1100,3],minval=1,maxval=40,dtype=tf.float32))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFtest_destpnt_coords = tf.Variable(tf.random_uniform([900,3],minval=1,maxval=40,dtype=tf.float32))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFtest_srcpnt_features = tf.Variable(tf.random_uniform([1100,7],minval=1,maxval=100,dtype=tf.float32))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFtest_destpnt_features = tf.Variable(tf.random_uniform([900,7],minval=1,maxval=100,dtype=tf.float32))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef pointcloud_pairlist(source_points,dest_points,cutoffs_xyz,ordered=True):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Find pairs of points between source and destination clouds within the cutoff distance123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Args:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        source_cloud:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        dest_cloud:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        cutoff:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Returns:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    int32 tensor indexes of pairs of points within the cuttoff123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # todo assert fits;123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # convert to canonical float 32 (assert fits float32 for points)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcpnt_coords = tf.to_float(source_points)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destpnt_coords = tf.to_float(dest_points)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    cutoffs_xyz = tf.to_float(cutoffs_xyz)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    point_mean = tf.reduce_mean(tf.concat([srcpnt_coords,destpnt_coords],0),reduction_indices=0)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcpnt_coords = srcpnt_coords - point_mean123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destpnt_coords = destpnt_coords - point_mean123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # index source and destination points123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    num_srcpnt = tf.shape(srcpnt_coords)[0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcpnt_idx = tf.to_int64(tf.range(num_srcpnt))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    num_destpnt = tf.shape(destpnt_coords)[0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destpnt_idx = tf.to_int64(tf.range(num_destpnt))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # define a grid of the size cutoff around both of the point clouds123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcgrid_coords = tf.to_int64((source_points / cutoffs_xyz)+0.5)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destgrid_coords = tf.to_int64((dest_points / cutoffs_xyz)+0.5)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # sort both source and destination clouds123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcgrid_stensor = tf.SparseTensor(indices=srcgrid_coords,values=srcpnt_idx,dense_shape=[1,1,1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcgrid_stensor = tf.sparse_reorder(srcgrid_stensor)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destgrid_stensor = tf.SparseTensor(indices=destgrid_coords,values=destpnt_idx,dense_shape=[1,1,1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destgrid_stensor = tf.sparse_reorder(destgrid_stensor)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcgrid_coords = tf.cast(srcgrid_stensor.indices,tf.int16)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcgrid_order = srcgrid_stensor.values123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destgrid_coords = tf.cast(destgrid_stensor.indices,tf.int16)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destgrid_order = destgrid_stensor.values123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # find the number of points in every grid (start + end)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcgrid_names = tf.bitcast(tf.concat([srcgrid_coords,tf.zeros([num_srcpnt,1],tf.int16)],1),tf.int64)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    unq_srcgrid_names,srcgrid_ids,srcgrid_counts = tf.unique_with_counts(srcgrid_names)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcgrid_starts = tf.segment_min(srcpnt_idx,srcgrid_ids)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destgrid_names = tf.bitcast(tf.concat([destgrid_coords,tf.zeros([num_destpnt,1],tf.int16)],1),tf.int64)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    unq_destgrid_names,destgrid_ids,destgrid_counts = tf.unique_with_counts(destgrid_names)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destgrid_starts = tf.segment_min(destpnt_idx,destgrid_ids)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # generate all possible 27 grid neighbors of each of the source grids123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    num_srcgrids = tf.shape(unq_srcgrid_names)[0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcgrid_idx = tf.to_int64(tf.range(num_srcgrids))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    unq_srcgrid_coords = tf.bitcast(unq_srcgrid_names,tf.int16)[:,0:3]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    num_destgrids = tf.shape(unq_destgrid_names)[0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # itself            (1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # face neighbors    (6)  : +/-1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # edge neighbors    (12) : +/-1 +/-1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # vertex neighbors  (8)  : +/-1 +/-1 +/-1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    neighbor_shift = tf.constant([[0,0,0],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                  [0,0,1],[0,1,0],[1,0,0],[0,0,-1],[0,-1,0],[-1,0,0],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                  [0,1,1],[1,0,1],[1,1,0],[0,-1,-1],[-1,0,-1],[-1,-1,0],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                  [0,1,-1],[1,0,-1],[1,-1,0],[0,-1,1],[-1,0,1],[-1,1,0],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                  [1,1,1],[1,1,-1],[1,-1,1],[-1,1,1],[1,-1,-1],[-1,1,-1],[-1,-1,1],[-1,-1,-1]],tf.int16)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    neighbor_shifts = tf.tile(neighbor_shift,[num_srcgrids,1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcgrid_nhb_coords = tf.reshape(tf.tile(unq_srcgrid_coords,[1,27]),[-1,3]) + neighbor_shifts123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcgrid_nhb_names = tf.bitcast(tf.concat([srcgrid_nhb_coords,tf.zeros([num_srcgrids*27,1],tf.int16)],1),tf.int64)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcgrid_of_srcgrid = tf.reshape(tf.tile(tf.expand_dims(srcgrid_idx, 1), [1, 27]), [-1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # find grid if grid neighbors of the source grids exist in destination grids123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    all_grid_names = tf.concat([unq_destgrid_names,srcgrid_nhb_names],0)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    _,all_grid_ids,_ = tf.unique_with_counts(all_grid_names)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destgrid_of_srcgrid = tf.slice(all_grid_ids,[num_destgrids],[num_srcgrids*27])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    filter_notempty = destgrid_of_srcgrid < num_destgrids123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcgrid_of_srcgrid = tf.boolean_mask(srcgrid_of_srcgrid, filter_notempty)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destgrid_of_srcgrid = tf.boolean_mask(destgrid_of_srcgrid, filter_notempty)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcgrid_slices = tf.stack([tf.to_int32(tf.gather(srcgrid_starts,srcgrid_of_srcgrid)),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                               tf.gather(srcgrid_counts,srcgrid_of_srcgrid)],axis=1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destgrid_slices = tf.stack([tf.to_int32(tf.gather(destgrid_starts,destgrid_of_srcgrid)),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                tf.gather(destgrid_counts,destgrid_of_srcgrid)],axis=1)                                 # 1100/sec123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # convert the slices of the gerid cells into back into the points123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    src_pairs_1 = numbergatan.int_sequence(srcgrid_slices[:,0], srcgrid_slices[:, 1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    src_pairs_2 = numbergatan.int_repeat(destgrid_slices[:,1], srcgrid_slices[:,1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    src_pairs = numbergatan.int_repeat(src_pairs_1, src_pairs_2)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    dest_pairs_1 = numbergatan.int_repeat(destgrid_slices[:,0],srcgrid_slices[:,1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    dest_pairs_2 = numbergatan.int_repeat(destgrid_slices[:,1],srcgrid_slices[:,1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    dest_pairs = numbergatan.int_sequence(dest_pairs_1,dest_pairs_2)                                            # 110/sec123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # # todo assert src and dest pairs are of the same size123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    src_pairs = tf.gather(srcgrid_order,src_pairs) # map to the initial order of coords123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    dest_pairs = tf.gather(destgrid_order,dest_pairs) # map to the initial order of coords123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # calculate the exact distance between every pair of points, and crop points that do not fit123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    src_pairs_coords = tf.gather(srcpnt_coords, src_pairs)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    dest_pairs_coords = tf.gather(destpnt_coords, dest_pairs)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destpnt_rel_coords = dest_pairs_coords - src_pairs_coords123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    in_radii_of_src = tf.reduce_all(tf.abs(destpnt_rel_coords) < cutoffs_xyz,1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destpnt_rel_coords = tf.boolean_mask(destpnt_rel_coords,in_radii_of_src)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    src_pairs = tf.boolean_mask(src_pairs,in_radii_of_src)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    dest_pairs = tf.boolean_mask(dest_pairs,in_radii_of_src)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    if ordered:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # todo if ordered # todo (bigger multiplier)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # (optional) order by the source point (first) and by the distance (second)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        num_pairs = tf.shape(src_pairs)[0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        pairs_idx = tf.range(0, num_pairs)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        pairs_rel_dist = tf.reduce_sum(destpnt_rel_coords **2,reduction_indices=1)**0.5123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        pairs_int_dist = tf.to_int64((pairs_rel_dist / tf.reduce_mean(cutoffs_xyz)) * 1000000)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        pairs_stensor_idx = tf.concat([tf.expand_dims(src_pairs,1),tf.expand_dims(pairs_int_dist,1)],1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        pairs_stensor = tf.SparseTensor(pairs_stensor_idx,pairs_idx,dense_shape=[1,1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        pairs_stensor = tf.sparse_reorder(pairs_stensor)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        src_pairs = pairs_stensor.indices[:,0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        dest_pairs = tf.gather(dest_pairs,pairs_stensor.values)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        destpnt_rel_coords = tf.gather(destpnt_rel_coords,pairs_stensor.values)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return src_pairs,dest_pairs,destpnt_rel_coords123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef veawe_module(srcpnt_coords,destpnt_coords,srcpnt_features,destpnt_features,src_pairs,dest_pairs,destpnt_rel_coords,num_neighbors):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Args:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        srcpnt_coords:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        destpnt_coords:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        srcpnt_features:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        destpnt_features:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        src_pairs:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        dest_pairs:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        destpnt_rel_coords:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        num_neighbors:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Returns:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # todo assert shape reason123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # todo different variations of cropping the table to num neighbors123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    num_srcpnt = tf.shape(srcpnt_coords)[0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    num_pairs = tf.shape(src_pairs)[0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    table_shape = tf.to_int64(tf.stack([num_neighbors, num_srcpnt]))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # if any of the source points has more neighbors than requested, crop them123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    nhbr_per_srcpnt = tf.segment_sum(tf.ones([num_pairs],tf.int32),src_pairs)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    nhbr_idx = numbergatan.int_sequence(tf.zeros([num_srcpnt], tf.int32), nhbr_per_srcpnt)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    nhbr_fits_table = nhbr_idx < num_neighbors123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    nhbr_idx = tf.boolean_mask(nhbr_idx,nhbr_fits_table)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    src_pairs = tf.boolean_mask(src_pairs,nhbr_fits_table)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    dest_pairs = tf.boolean_mask(dest_pairs,nhbr_fits_table)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destpnt_rel_coords = tf.boolean_mask(destpnt_rel_coords,nhbr_fits_table)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # convert lists of neighboring points; if some of the points do not have enogh neighbors, pad with 0s123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    table_indices = tf.concat([tf.to_int64(tf.expand_dims(nhbr_idx,1)),tf.expand_dims(src_pairs,1)],1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    table_values = tf.to_int64(dest_pairs + 1) # shifting coordinates by 1 to allow padding123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    nhbr_table = tf.SparseTensor(table_indices,table_values, dense_shape=table_shape)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    nhbr_table = tf.sparse_reorder(nhbr_table)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    nhbr_table = tf.sparse_tensor_to_dense(nhbr_table)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # create a 3D table with features from 3D table of neighbors123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    empty_feature = tf.zeros([1,tf.shape(destpnt_features)[1]])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destpnt_features = tf.concat([empty_feature,destpnt_features],0)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    feature_table = tf.gather(destpnt_features,nhbr_table)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # .... more things to do .......123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return feature_table123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef veawe_input():123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Prepares a first layer for the veawe intput123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Returns:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # feature of distance123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # feature of atom123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # feature of atom (one_hot)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFsrc_pairs, dest_pairs, destpnt_rel_coords = pointcloud_pairlist(test_srcpnt_coords,test_destpnt_coords,cutoffs_xyz=filter_size,ordered=True)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFanswer = veawe_module(test_srcpnt_coords,test_destpnt_coords,test_srcpnt_features,test_destpnt_features,src_pairs,dest_pairs,destpnt_rel_coords,9)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#test_answer = tf.reduce_min(answer)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#test_batch = tf.train.batch([test_answer],batch_size=100,num_threads=50,capacity=500,shapes=[])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFcoord = tf.train.Coordinator()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFinit_op = tf.global_variables_initializer()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFtf.get_default_graph().finalize()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFsess.run(init_op)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFa = sess.run(answer)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFprint a123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#for line in a:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#    print line123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#threads = tf.train.start_queue_runners(sess,coord)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#while True:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#    start = time.time()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#    #print sess.run(tf.shape(fits_centered_filter))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#    sess.run([test_batch])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#    print "exps:", "%.3f" % (100/ (time.time() - start))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF########### -------------------------- revision 3123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef pointcloud_pairlist(source_points,dest_points,cutoffs_xyz):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Find pairs of points between source and destination clouds within the cutoff distance123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Args:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        source_cloud:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        dest_cloud:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        cutoff:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Returns:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    int32 tensor indexes of pairs of points within the cuttoff123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # todo assert fits;123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # convert to canonical float 32123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcpnt_coords = tf.to_float(source_points)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destpnt_coords = tf.to_float(dest_points)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    cutoffs_xyz = tf.to_float(cutoffs_xyz)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    point_mean = tf.reduce_mean(tf.concat([srcpnt_coords,destpnt_coords],0),reduction_indices=0)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcpnt_coords = srcpnt_coords - point_mean123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destpnt_coords = destpnt_coords - point_mean123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # index source and destination points123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    num_srcpnt = tf.shape(srcpnt_coords)[0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcpnt_idx = tf.to_int64(tf.range(num_srcpnt))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    num_destpnt = tf.shape(destpnt_coords)[0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destpnt_idx = tf.to_int64(tf.range(num_destpnt))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # define a grid of the size cutoff around both of the point clouds123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcgrid_coords = tf.to_int64((source_points / cutoffs_xyz)+0.5)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destgrid_coords = tf.to_int64((dest_points / cutoffs_xyz)+0.5)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # sort both source and destination clouds123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcgrid_stensor = tf.SparseTensor(indices=srcgrid_coords,values=srcpnt_idx,dense_shape=[1,1,1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcgrid_stensor = tf.sparse_reorder(srcgrid_stensor)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destgrid_stensor = tf.SparseTensor(indices=destgrid_coords,values=destpnt_idx,dense_shape=[1,1,1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destgrid_stensor = tf.sparse_reorder(destgrid_stensor)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcgrid_coords = tf.cast(srcgrid_stensor.indices,tf.int16)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcgrid_order = srcgrid_stensor.values123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destgrid_coords = tf.cast(destgrid_stensor.indices,tf.int16)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destgrid_order = destgrid_stensor.values123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # find the number of points in every grid (start + end)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # commented out waiting for custom C op to make multiple slices123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #srcgrid_names = tf.bitcast(tf.concat([srcgrid_coords,tf.zeros([num_srcpnt,1],tf.int16)],1),tf.int64)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #unq_srcgrid_names,srcgrid_ids,srcgrid_counts = tf.unique_with_counts(srcgrid_names)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #srcgrid_starts = tf.segment_min(srcpnt_idx,srcgrid_ids)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destgrid_names = tf.bitcast(tf.concat([destgrid_coords,tf.zeros([num_destpnt,1],tf.int16)],1),tf.int64)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    unq_destgrid_names,destgrid_ids,destgrid_counts = tf.unique_with_counts(destgrid_names)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destgrid_starts = tf.segment_min(destpnt_idx,destgrid_ids)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # generate all possible 27 grid neighbors of each of the source grids123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # itself            (1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # face neighbors    (6)  : +/-1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # edge neighbors    (12) : +/-1 +/-1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # vertex neighbors  (8)  : +/-1 +/-1 +/-1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    neighbor_shift = tf.constant([[0,0,0],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                  [0,0,1],[0,1,0],[1,0,0],[0,0,-1],[0,-1,0],[-1,0,0],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                  [0,1,1],[1,0,1],[1,1,0],[0,-1,-1],[-1,0,-1],[-1,-1,0],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                  [0,1,-1],[1,0,-1],[1,-1,0],[0,-1,1],[-1,0,1],[-1,1,0],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                  [1,1,1],[1,1,-1],[1,-1,1],[-1,1,1],[1,-1,-1],[-1,1,-1],[-1,-1,1],[-1,-1,-1]],tf.int16)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    neighbor_shifts = tf.tile(neighbor_shift,[num_srcpnt,1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcgrid_nhb_coords = tf.reshape(tf.tile(srcgrid_coords,[1,27]),[-1,3]) + neighbor_shifts123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcgrid_nhb_names = tf.bitcast(tf.concat([srcgrid_nhb_coords,tf.zeros([num_srcpnt*27,1],tf.int16)],1),tf.int64)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcgrid_src_idx = tf.reshape(tf.tile(tf.expand_dims(srcpnt_idx, 1), [1, 27]), [-1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # find grid if grid neighbors of the source grids exist in destination grids123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    all_grid_names = tf.concat([unq_destgrid_names,srcgrid_nhb_names],0)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    _,all_grid_ids,_ = tf.unique_with_counts(all_grid_names)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    num_unq_destgrids = tf.shape(unq_destgrid_names)[0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcgrid_destgrid_ids = tf.slice(all_grid_ids,[num_unq_destgrids],[num_srcpnt*27])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    filter_notempty = srcgrid_destgrid_ids < num_unq_destgrids123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcgrid_destgrid_ids = tf.boolean_mask(srcgrid_destgrid_ids, filter_notempty)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcgrid_src_idx = tf.boolean_mask(srcgrid_src_idx, filter_notempty)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destgrid_slices = tf.stack([tf.to_int32(tf.gather(destgrid_starts,srcgrid_destgrid_ids)),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                tf.gather(destgrid_counts,srcgrid_destgrid_ids)],axis=1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # convert slices into indexes of source/destination points; map indices back the initial order (before sorting)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcpnt_src_idx = numbergatan.int_repeat(srcgrid_src_idx, destgrid_slices[:, 1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destpnt_dest_idx = numbergatan.int_sequence(destgrid_slices[:,0],destgrid_slices[:,1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcpnt_src_idx = tf.gather(srcgrid_order,srcpnt_src_idx)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destpnt_dest_idx = tf.gather(destgrid_order,destpnt_dest_idx)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # one more round of cropping to fit discard the points which fall outside of the centered on the point filter123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcpnt_src_coords = tf.gather(srcpnt_coords, srcpnt_src_idx)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destpnt_dest_coords = tf.gather(destpnt_coords, destpnt_dest_idx)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destpnt_rel_coords = destpnt_dest_coords - srcpnt_src_coords123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    in_radii_of_src = tf.reduce_all(tf.abs(destpnt_rel_coords) < cutoffs_xyz,1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destpnt_rel_coords = tf.boolean_mask(destpnt_rel_coords,in_radii_of_src)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    srcpnt_src_idx = tf.boolean_mask(srcpnt_src_idx,in_radii_of_src)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    destpnt_dest_idx = tf.boolean_mask(destpnt_dest_idx,in_radii_of_src)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return srcpnt_src_idx,destpnt_dest_idx,destpnt_rel_coords 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF