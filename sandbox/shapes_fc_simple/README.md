# shapes123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF## Shape matching123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFHere, we are trying to solve the problem of shape-matching.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFWe are given two pieces of a shape; for instance, two halves123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFof a cut triangle. However, we do not know whether these two123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFpieces join together or not. We use a convolutional neural123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFnetwork together with incremental weight-loading in order to123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFaccurately predict whether to halves of a shape match each123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFother, regardless of initial position and rotation.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF### Input123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFThe input to our program is a dataset of 50K 100x100 image pairs123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFof two matching pieces of a shape. Here are a couple (enlarged)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFexample image pairs from our dataset:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFA cut triangle.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF<img src="shape_generation/images/1_L.png?raw=true" alt="Lock image 1" style="width: 120px;"/>123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF<img src="shape_generation/images/1_K.png?raw=true" alt="Key image 1" style="width: 120px;"/>123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFA cut square.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF<img src="shape_generation/images/3_L.png?raw=true" alt="Lock image 3" style="width: 120px;"/>123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF<img src="shape_generation/images/3_K.png?raw=true" alt="Key image 3" style="width: 120px;"/>123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#### Datasets123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFCurrently, we have [several datasets](https://electronneutrino.com/affinity/shapes/datasets/)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFfor training. Here are what the naming conventions mean:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF* `MSHAPES` - the name of the dataset (always MSHAPES in our case)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF* `[x]DEG` - (`0<=x<=180`) - the maximum rotation of each shape, in degrees,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFfrom its original position. Note that since both the lock image123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFand the key image can be rotated in either direction by `x` degrees,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFall datasets where `DEG>180` are equivalent (this is also partially123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFtrue for all datasets with `DEG>90`).123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF* `COLOR` - (can be `ONE` or `RANDOM`) - `ONE` means that all of the shapes123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFin the database are the same color; `RANDOM` means that each pair is its123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFown (random) color. Thus, when training a network on a `RANDOMCOLOR`123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdataset, there is a very high change that it will simply learn colors123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFrather than learning to match shapes.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF* cut type - (currently only `SIMPLE`) - the way the shapes are cut.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF`SIMPLE` means that they are cut by a straight line. In the future,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFwe are looking to implement more complex cuts, and having incorrect123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimage pairs that are less obvious (like not fitting in some notches.)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFIncorrect examples are dynamically generated by incorrectly matching123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFlock images and key images (uniformity of selection is observed.)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF### Training123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFWe train our model using a relatively standard convolutional123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFneural network (for details, see `inference()` in 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF`simpletrain5/st5.py`).123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#### Weight loading123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFIf we try to train this network on randomly rotated images, the123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFcross-entropy loss gets stuck at 0.69--this means that, most of123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFthe time, the network is randomly guessing, and is not learning123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFanything. Thus, we use the idea of *weight loading*. First, we123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFtrain the network on matching shapes rotated at most ten degrees123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFfor, say, 1000 iterations. Then, we retain the weights, but123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFswitch the dataset to one of images rotated at most *thirty*123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdegrees. We continue in a similar pattern through datasets123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFwith images rotated 60, 135, and, finally 180 degrees, and, on123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFthe final dataset with random rotation, we get a cross-entropy123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFloss comparable to the one we get on the 10-degree dataset.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFThis has several immediate implications for neural architercutes123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFin drug design--if, at first, we train a network on protein-ligand123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFcrystallographic data with the ligands randomly rotated by a small123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFangle, and then load those weights into another net, we can expect123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFthat the second net will get comparable accuracy *without at all123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFconsidering the orientation of either the protein or the ligand*.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFThis seems like a promising step in the development of more123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFpowerful drug design networks.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF## Shape generation123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFRun `shape_generation/main.py`.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFEdit flags in `shape_generation/nshapegenflags.py`:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF* `IMAGE_NUM` - the number of images to be generated123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF* `DIM` - dimension of images123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF* `COLOR` - what color to use for the shapes123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF* `RANDOM_COLOR` - boolean; whether to use random colors for the shapes instead. Overrides `COLOR`. (This is nice for quickly being able to tell whether two shapes match or not)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF* `ROTATE` - Whether to rotate the generated shape pieces123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF* `SIMPLE` - **(experimental!)** boolean; whether to use simple geometric shapes or more complex geometric shapes123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF* `CUT` - **(not fully implemented)** which cut style to use when cutting the shapes