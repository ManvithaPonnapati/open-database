import tensorflow as tf123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef graph_conv_layer(adj_matrix, feature_matrix, weights, biases):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF	"""Performs a graph convolution layer. 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF	Args:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF		adj_matrix [B, N, N]: adjacency matrix123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF		feature_matrix [B, N, input_dim]: features for each atom123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF		weights [input_dim, output_dim]: weights for transformation123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF		biases [output_dim]: biases for transformation123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF	Returns:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF		new_feature_matrix: Tensor of shape [B, N, output_dim]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF	"""123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF	batch_size = tf.shape(feature_matrix)[0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF	num_atoms = tf.shape(feature_matrix)[1]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF	input_dim = tf.shape(feature_matrix)[2]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF	output_dim = tf.shape(weights)[1]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF	adj_matrix = _normalize_adjacency_matrix(adj_matrix)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF	#for each atom, sum the features from adjacent atoms123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF	summed_features = tf.matmul(adj_matrix, feature_matrix)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF	#apply an atomwise convolution to transform the old features into new features123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF	summed_features = tf.reshape(summed_features, shape=[-1, input_dim])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF	new_feature_matrix = tf.matmul(summed_features, weights) + biases123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF	new_feature_matrix = tf.reshape(new_feature_matrix, shape=[batch_size, num_atoms, output_dim])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF	#apply nonlinearity (ReLU)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF	new_feature_matrix = tf.nn.relu(new_feature_matrix)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF	#apply batch normalization123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF	mean, var = tf.nn.moments(new_feature_matrix, axes=[0])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF	normalized_feature_matrix = tf.nn.batch_normalization(new_feature_matrix, mean, var, None, None, 1e-5)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF	return new_feature_matrix123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef graph_max_pool(adj_matrix, feature_matrix):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF	"""Performs max pooling over an atom's neighbors and itself123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF	Args:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF		adj_matrix [B, N, N]: adjacency matrix (DO NOT NORMALIZE)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF		feature_matrix [B, N, input_dim]: features for each atom123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF	Returns:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF		pool_feature_matrix [B, N, input_dim]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF	"""123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF	adj_matrix = tf.expand_dims(adj_matrix, -1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF	feature_matrix = tf.expand_dims(feature_matrix, 2)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF	return tf.reduce_max(adj_matrix * feature_matrix, axis=2)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef fc_layer(input_tensor, weights, biases, keep_prob):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF	"""Creates a simple fully-connected layer with ReLU activation and dropout"""123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF	output_tensor = tf.matmul(input_tensor, weights) + biases123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF	output_tensor = tf.nn.relu(output_tensor)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF	output_tensor = tf.nn.dropout(output_tensor, keep_prob)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF	return output_tensor123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef _normalize_adjacency_matrix(adj_matrix):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF	"""Normalizes the adjacency matrix using the method in Thomas N. Kipf's paper"""123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF	diag_degrees = tf.matrix_diag(1.0 / tf.sqrt(tf.reduce_sum(adj_matrix, axis=2)))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF	return tf.matmul(tf.matmul(diag_degrees, adj_matrix), diag_degrees)