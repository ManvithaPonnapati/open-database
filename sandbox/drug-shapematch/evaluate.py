#!/usr/bin/env python123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# -*- coding: utf-8 -*-123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFfrom __future__ import print_function123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFfrom __future__ import print_function123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFfrom __future__ import print_function123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFfrom __future__ import print_function123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport argparse123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport sys123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport time123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport numpy as np123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport dsminput123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFfrom utils import *123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFfrom constants import EVAL_CONSTANTS123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport tensorflow as tf123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFsys.path.append('../../')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport affinity as af123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef inputs(data_dir, batch_size, side_pixels=20, num_threads=200):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Constructs the input for drug-shapematch from the av4 data.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    :param data_dir: Path to the MSHAPES data directory123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    :param batch_size: Number of images per batch123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    :param side_pixels: (Optional) The size of the bounding box for the receptor/ligand. Defaults to 20, although123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                        this parameter should be set nevertheless.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    :param num_threads: (Optional) The number of threads to be used. Defaults to 200, although this parameter should123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                        be set nevertheless.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    :return:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 6] size123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        labels: Labels. 1D tensor of [batch_size] size.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # Initialize lists for receptor files, matching ligand files, and non-matching ligand files123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    info("Initializing lists", source="dsminput")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    receptor_files = []123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ligand_files_good = []123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ligand_files_bad = []123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # All examples are in the form .../*.av4123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    num_examples = len(glob(os.path.join(data_dir + '/**/', "*[_]*.av4")))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    info("Loading files into queue", source="dsminput")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    af.utils.print_progress_bar(0, num_examples, prefix='Progress:', suffix='complete',123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                length=50, fill='█')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    counter = 0123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    for ligand_file in glob(os.path.join(data_dir + '/**/', "*[_]*.av4")):  # Cycle through each example in the database123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # receptor_file = "/".join(ligand_file.split("/")[:-1]) + "/" + ligand_file.split("/")[-1][:4] + '.av4'123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        receptor_file = "/".join(ligand_file.split("/")[:-1]) + "/" + ligand_file.split("/")[-1][123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                                                      :ligand_file.split("/")[-1].split("_")[123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                                                          0].__len__()] + '.av4'123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # info("Looking at " + str(ligand_file) + " and " + str(receptor_file))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        af.utils.print_progress_bar(counter + 1, num_examples,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                    prefix='Progress:', suffix='complete',123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                    length=50, fill='█')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # On odd times, append the receptor and the matching ligand.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # On even times, append a non-matching ligand.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        if counter % 2 == 0:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            receptor_files.append(receptor_file)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            ligand_files_good.append(ligand_file)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        else:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            ligand_files_bad.append(ligand_file)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        counter = counter + 1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    info("Finished loading files.", source="dsminput")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    info("Number of examples: " + str(counter), source="dsminput")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # print("Lock files: ")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # print(lock_files)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # print("Good key files: ")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # print(key_files_good)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # print("Bad key files: ")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # print(key_files_bad)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # Generate queues of matching and non-matching pairs123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    info("Generating queues of matching and non-matching data", source="dsminput")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    good_pairs_queue = tf.train.slice_input_producer([receptor_files, ligand_files_good],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                                     num_epochs=None, shuffle=False)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    bad_pairs_queue = tf.train.slice_input_producer([receptor_files, ligand_files_bad],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                                    num_epochs=None, shuffle=False)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    info("Finished queueing", source="dsminput")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # Get the correct and incorrect examples from files in the filename queue.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # receptor, ligand = read_av4_correct(good_pairs_queue)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # wrong_ligand = read_av4_wrong(bad_pairs_queue)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # Generate correct and incorrect examples from the image pair queues123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    info("Setting up correct and incorrect example generation", source="dsminput")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    correct_example = dsminput.read_av4(good_pairs_queue)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    wrong_example = dsminput.read_av4(bad_pairs_queue)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # print("c Example shape:--------------------------------------------------------->"),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # print(correct_example.get_shape())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # print("w Example shape:--------------------------------------------------------->"),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # print(wrong_example.get_shape())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    info("Finished setting up example generation", source="dsminput")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # Regroup the enqueues123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # grouped_enqueues = tf.group(enqueues[0], enqueues[1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # for i in xrange(2, len(enqueues) - 1):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #     grouped_enqueues = tf.group(grouped_enqueues, enqueues[i])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # Now, return a batch with randomly added correct and incorrect examples.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    info("Setting up correct/incorrect example chooser", source="dsminput")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    correct_or_incorrect = tf.random_uniform(shape=[], minval=0, maxval=1, dtype=tf.float32)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # The case code is basically tensorflow language for this:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # if (correct_or_incorrect < 0.5):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #     _generate_image_and_label_batch(correct_example, [1],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #                                     min_queue_examples, batch_size,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #                                     shuffle=False)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # else:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #     _generate_image_and_label_batch(wrong_example, [0],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #                                     min_queue_examples, batch_size,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #                                     shuffle=False)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    def f1():123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        return correct_example123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    def f2():123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        return wrong_example123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    def g1():123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        return tf.constant(0)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    def g2():123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        return tf.constant(1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    image = tf.case(123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        {tf.less(correct_or_incorrect, tf.constant(0.5)): f1, tf.greater(correct_or_incorrect, tf.constant(0.5)): f2},123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        default=f1, exclusive=True)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    label = tf.case(123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        {tf.less(correct_or_incorrect, tf.constant(0.5)): g1, tf.greater(correct_or_incorrect, tf.constant(0.5)): g2},123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        default=g1, exclusive=True)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # return (good_pairs_queue, (_generate_image_and_label_batch(image, label,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #                                                            min_queue_examples, batch_size,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #                                                            shuffle=True)))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    info("Returning queue and batches", source="dsminput")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return (num_examples, (tf.train.batch([image, label], batch_size,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                          num_threads=num_threads, capacity=batch_size * 3, dynamic_pad=True,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                          shapes=[[side_pixels, side_pixels, side_pixels], []])))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # def f1(): return (good_pairs_queue, (_generate_image_and_label_batch(correct_example, [1],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #                                     min_queue_examples, batch_size,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #                                     shuffle=False)))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # def f2(): return (good_pairs_queue, (_generate_image_and_label_batch(wrong_example, [0],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #                                     min_queue_examples, batch_size,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #                                     shuffle=False)))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # r = tf.case([(tf.less(correct_or_incorrect, tf.constant(0.5)), f1)], default=f2)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # return r123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef evaluate_on_train_set():123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    header("Running train() function.")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # Make logging very verbose123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    info("Setting verbosity to maximum value")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    tf.logging.set_verbosity(tf.logging.DEBUG)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # Create the image and label batches for the data123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    info("Creating image and label batches")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    (num_examples, (image_batch, label_batch)) = inputs(data_dir=EVAL_CONSTANTS.database_path,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                                        batch_size=EVAL_CONSTANTS.batch_size,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                                        side_pixels=EVAL_CONSTANTS.side_pixels,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                                        num_threads=EVAL_CONSTANTS.num_threads)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # Launch a tensorflow session123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    info("Launching tensorflow session")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    sess = tf.Session()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    if not EVAL_CONSTANTS.saved_session is None:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        sess.run(tf.global_variables_initializer())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    info("Image batch shape")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    info(str(image_batch.get_shape()))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    info("Making keep probability placeholder")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    keep_prob = tf.placeholder(tf.float32)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.variable_scope("network"):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # Predict the labels using a MaxNet123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        info("Setting up MaxNet")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        predicted_labels = af.networks.MaxNet().compute_output(image_batch, keep_prob, EVAL_CONSTANTS.batch_size)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # Randomly shuffle along the batch dimension and calculate the shuffled error123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    info("Setting up shuffled losses")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    shuffled_labels = tf.random_shuffle(label_batch)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    shuffled_cross_entropy_mean = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=predicted_labels,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                                                                                labels=shuffled_labels))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    tf.summary.scalar('shuffled cross entropy mean', shuffled_cross_entropy_mean)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # Create saver to save and load the network state123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    info("Creating saver")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    saver = tf.train.Saver(var_list=(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope="Adam_optimizer") +123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                     tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope="network") +123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                     tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope="epoch_counter")))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # FIXME: -- not sure if it is the best way to initialize the network123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # restore variables from sleep123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    info("Restoring variables from saved session")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    sess.run(tf.global_variables_initializer())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    saver.restore(sess, EVAL_CONSTANTS.saved_session)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    info("Restored variables. Beginning training")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # Launch all threads123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # (Note: only do this after the graph is complete and all the variables initialized!)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    info("Launching threads and queue runners")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    coord = tf.train.Coordinator()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    threads = tf.train.start_queue_runners(sess=sess, coord=coord)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    predicted_labels = tf.nn.softmax(predicted_labels)[:, -1]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    info("Entering evaluation loop")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    auc, update_op = tf.contrib.metrics.streaming_auc(predicted_labels, label_batch)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    sess.run(tf.local_variables_initializer())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ne = num_examples123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    printi("Number of examples: " + str(ne))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    try:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        for i in xrange(1, ne):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            start = time.time()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            my_predictions, my_labels, my_auc = sess.run([predicted_labels, label_batch, update_op],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                                         feed_dict={keep_prob: EVAL_CONSTANTS.keep_probability})123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            sys.stdout.write("\033[93mlocal step: " + str(i)),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            # sys.stdout.write("      current auc: " + str(my_auc)),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            sys.stdout.write("      prediction averages: " + rightzpad(str(np.mean(my_predictions)), 8)),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            sys.stdout.write(123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                "      examples per second: " + (str(123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                    round((EVAL_CONSTANTS.batch_size / (time.time() - start)), 2)) + "")[123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                                ::-1].zfill(6)[::-1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            print("")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    except tf.errors.OutOfRangeError:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        printi("Exiting the evaluation loop!")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # printi("Predictions shape " + str(predicted_labels.get_shape()))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # printi("Labels shape " + str(label_batch.get_shape()))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # c_entropy_mean, _, my_labels, my_predicted_labels = sess.run([cross_entropy_mean, train_step_run, label_batch, predicted_labels], feed_dict={keep_prob: EVAL_CONSTANTS.keep_probability})123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # print(my_labels)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # my_predicted_labels = np.around(my_predicted_labels, decimals=2)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # print(my_predicted_labels)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    auc, _ = sess.run([auc, update_op],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                      feed_dict={keep_prob: EVAL_CONSTANTS.keep_probability})123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    printi("")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    printi("")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    printi("")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    printi("_______________________________________________")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    printi("|              AUC: " + str(auc) + "                  |")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    printi("-----------------------------------------------")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef main(_):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    evaluate_on_train_set()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFif __name__ == '__main__':123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    tf.app.run()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF