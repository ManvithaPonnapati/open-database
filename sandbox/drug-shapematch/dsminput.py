#!/usr/bin/env python123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# -*- coding: utf-8 -*-123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport sys123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport numpy as np123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport tensorflow as tf123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFfrom utils import *123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFsys.path.append("../../")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport affinity.geom123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport affinity.utils123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef inputs(data_dir, batch_size, side_pixels=20, num_threads=200):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Constructs the input for drug-shapematch from the av4 data.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    :param data_dir: Path to the MSHAPES data directory123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    :param batch_size: Number of images per batch123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    :param side_pixels: (Optional) The size of the bounding box for the receptor/ligand. Defaults to 20, although123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                        this parameter should be set nevertheless.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    :param num_threads: (Optional) The number of threads to be used. Defaults to 200, although this parameter should123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                        be set nevertheless.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    :return:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 6] size123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        labels: Labels. 1D tensor of [batch_size] size.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # Initialize lists for receptor files, matching ligand files, and non-matching ligand files123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    info("Initializing lists", source="dsminput")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    receptor_files = []123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ligand_files_good = []123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ligand_files_bad = []123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # All examples are in the form .../*.av4123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    num_examples = len(glob(os.path.join(data_dir + '/**/', "*[_]*.av4")))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    info("Loading files into queue", source="dsminput")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    affinity.utils.print_progress_bar(0, num_examples, prefix='Progress:', suffix='complete',123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                      length=50, fill='█')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    counter = 0123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    for ligand_file in glob(os.path.join(data_dir + '/**/', "*[_]*.av4")):  # Cycle through each example in the database123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        receptor_file = "/".join(ligand_file.split("/")[:-1]) + "/" + ligand_file.split("/")[-1][:4] + '.av4'123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        affinity.utils.print_progress_bar(counter + 1, num_examples,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                          prefix='Progress:', suffix='complete',123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                          length=50, fill='█')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # On odd times, append the receptor and the matching ligand.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # On even times, append a non-matching ligand.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        if counter % 2 == 0:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            receptor_files.append(receptor_file)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            ligand_files_good.append(ligand_file)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        else:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            ligand_files_bad.append(ligand_file)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        counter = counter + 1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    info("Finished loading files.", source="dsminput")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    info("Number of examples: " + str(counter), source="dsminput")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # print("Lock files: ")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # print(lock_files)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # print("Good key files: ")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # print(key_files_good)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # print("Bad key files: ")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # print(key_files_bad)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # Generate queues of matching and non-matching pairs123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    info("Generating queues of matching and non-matching data", source="dsminput")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    good_pairs_queue = tf.train.slice_input_producer([receptor_files, ligand_files_good],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                                     num_epochs=None, shuffle=False)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    bad_pairs_queue = tf.train.slice_input_producer([receptor_files, ligand_files_bad],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                                    num_epochs=None, shuffle=False)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    info("Finished queueing", source="dsminput")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # Get the correct and incorrect examples from files in the filename queue.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # receptor, ligand = read_av4_correct(good_pairs_queue)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # wrong_ligand = read_av4_wrong(bad_pairs_queue)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # Generate correct and incorrect examples from the image pair queues123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    info("Setting up correct and incorrect example generation", source="dsminput")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    correct_example = read_av4(good_pairs_queue)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    wrong_example = read_av4(bad_pairs_queue)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # print("c Example shape:--------------------------------------------------------->"),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # print(correct_example.get_shape())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # print("w Example shape:--------------------------------------------------------->"),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # print(wrong_example.get_shape())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    info("Finished setting up example generation", source="dsminput")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # Regroup the enqueues123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # grouped_enqueues = tf.group(enqueues[0], enqueues[1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # for i in xrange(2, len(enqueues) - 1):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #     grouped_enqueues = tf.group(grouped_enqueues, enqueues[i])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # Now, return a batch with randomly added correct and incorrect examples.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    info("Setting up correct/incorrect example chooser", source="dsminput")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    correct_or_incorrect = tf.random_uniform(shape=[], minval=0, maxval=1, dtype=tf.float32)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # The case code is basically tensorflow language for this:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # if (correct_or_incorrect < 0.5):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #     _generate_image_and_label_batch(correct_example, [1],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #                                     min_queue_examples, batch_size,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #                                     shuffle=False)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # else:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #     _generate_image_and_label_batch(wrong_example, [0],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #                                     min_queue_examples, batch_size,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #                                     shuffle=False)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    def f1():123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        return correct_example123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    def f2():123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        return wrong_example123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    def g1():123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        return tf.constant(0)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    def g2():123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        return tf.constant(1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    image = tf.case(123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        {tf.less(correct_or_incorrect, tf.constant(0.5)): f1, tf.greater(correct_or_incorrect, tf.constant(0.5)): f2},123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        default=f1, exclusive=True)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    label = tf.case(123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        {tf.less(correct_or_incorrect, tf.constant(0.5)): g1, tf.greater(correct_or_incorrect, tf.constant(0.5)): g2},123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        default=g1, exclusive=True)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # return (good_pairs_queue, (_generate_image_and_label_batch(image, label,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #                                                            min_queue_examples, batch_size,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #                                                            shuffle=True)))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    info("Returning queue and batches", source="dsminput")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return (good_pairs_queue, (tf.train.batch([image, label], batch_size,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                              num_threads=num_threads, capacity=batch_size * 3, dynamic_pad=True,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                              shapes=[[side_pixels, side_pixels, side_pixels], []])))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # def f1(): return (good_pairs_queue, (_generate_image_and_label_batch(correct_example, [1],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #                                     min_queue_examples, batch_size,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #                                     shuffle=False)))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # def f2(): return (good_pairs_queue, (_generate_image_and_label_batch(wrong_example, [0],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #                                     min_queue_examples, batch_size,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #                                     shuffle=False)))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # r = tf.case([(tf.less(correct_or_incorrect, tf.constant(0.5)), f1)], default=f2)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # return r123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef read_av4(filename_queue):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Reads a pair of av4 records from the filename queue.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    :param filename_queue: the filename queue of receptor/ligand av4 files.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    :return: a combined image of the receptor and ligand123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # Get all of the details of the receptor and ligand123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    receptor_labels, receptor_elements, multiframe_receptor_coords = decode_av4(filename_queue[0])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ligand_labels, ligand_elements, multiframe_ligand_coords = decode_av4(filename_queue[1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # There's a lot of different frames saved, and only the first one is the actual correct binding position123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ligand_coords = multiframe_ligand_coords[:, :, 0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    receptor_coords = multiframe_receptor_coords[:, :, 0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # Convert the acquired elements into an actual image123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    image, _, _ = complex_coords_to_image(ligand_elements, ligand_coords, receptor_elements, receptor_coords,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                          side_pixels=20, pixel_size=1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # Return the combined image123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return image123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef _generate_image_and_label_batch(image, label, min_queue_examples,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                    batch_size, shuffle):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """Construct a queued batch of images and labels.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Args:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      image: 3-D Tensor of [height, width, 6] of type.float32.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      label: 1-D Tensor of type.int32123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      min_queue_examples: int32, minimum number of samples to retain123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        in the queue that provides of batches of examples.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      batch_size: Number of images per batch.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      shuffle: boolean indicating whether to use a shuffling queue.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Returns:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      images: Images. 4D tensor of [batch_size, height, width, 6] size.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      labels: Labels. 1D tensor of [batch_size] size.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print("Image dimensions: "),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print(image.get_shape())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # image = tf.reshape(image, [2 * IMAGE_SIZE, IMAGE_SIZE, 3])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # Create a queue that shuffles the examples, and then123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # read 'batch_size' images + labels from the example queue.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    num_preprocess_threads = 16123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    if shuffle:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        images, label_batch = tf.train.shuffle_batch(123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            [image, label],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            batch_size=batch_size,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            num_threads=num_preprocess_threads,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            capacity=min_queue_examples + 6 * batch_size,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            min_after_dequeue=min_queue_examples)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    else:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        images, label_batch = tf.train.batch(123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            [image, label],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            batch_size=batch_size,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            num_threads=num_preprocess_threads,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            capacity=min_queue_examples + 6 * batch_size)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # Display the training images in the visualizer.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    tf.summary.image('images', images)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print("Images dimensions: "),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print(images.get_shape())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return images, tf.reshape(label_batch, [batch_size])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef decode_av4(file_path):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # read the whole file123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    serialized_record = tf.read_file(file_path)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # decode everything into int32123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    tmp_decoded_record = tf.decode_raw(serialized_record, tf.int32)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # first four bytes describe the number of frames in a record123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    number_of_frames = tf.slice(tmp_decoded_record, [0], [1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # labels are saved as int32 * number of frames in the record123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    labels = tf.slice(tmp_decoded_record, [1], number_of_frames)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # elements are saved as int32 and their number is == to the number of atoms123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    number_of_atoms = tf.to_int32((tf.shape(tmp_decoded_record) - number_of_frames - 1) / (3 * number_of_frames + 1))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    elements = tf.slice(tmp_decoded_record, number_of_frames + 1, number_of_atoms)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # coordinates are saved as a stack of X,Y,Z where the first(vertical) dimension123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # corresponds to the number of atoms123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # second (horizontal dimension) is x,y,z coordinate of every atom and is always 3123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # third (depth) dimension corresponds to the number of frames123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    coords_shape = tf.concat([number_of_atoms, [3], number_of_frames], 0)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    tmp_coords = tf.slice(tmp_decoded_record, number_of_frames + number_of_atoms + 1,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                          tf.shape(tmp_decoded_record) - number_of_frames - number_of_atoms - 1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    multiframe_coords = tf.bitcast(tf.reshape(tmp_coords, coords_shape), type=tf.float32)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return labels, elements, multiframe_coords123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef read_rec_and_lig(filename_q, epoch_counter, lig_frame):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """Reads ligand and protein raw bytes based on the names in the filename queue. Returns tensors with coordinates123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    and atoms of ligand and protein for future processing.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Important: by default it does oversampling of the positive examples based on training epoch."""123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # read raw bytes of the ligand and receptor123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    idx = filename_q[0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ligand_file = filename_q[1]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # decode bytes into meaningful tensors123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ligand_labels, ligand_elements, multiframe_ligand_coords = decode_av4(ligand_file)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    receptor_labels, receptor_elements, multiframe_receptor_coords = decode_av4(filename_q[2])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #    Some simple arithmetics is used to sample all of the available frames123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #    if the index of the examle is even, positive label is taken every even epoch123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #    if the index of the example is odd, positive label is taken every odd epoch123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #    current negative example increments once every two epochs, and slides along all of the negative examples123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    if lig_frame == "ZERO":123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # always select oth frame (initial conf) of the ligand123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        current_frame = tf.constant(0)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    elif lig_frame == "SEQUENTIAL":123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        current_frame = tf.mod(epoch_counter, tf.shape(ligand_labels)[0])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    elif lig_frame == "OVERSAMPLING":123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        num_lig_frames = tf.shape(ligand_labels)[0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        current_frame = tf.cond(tf.equal(tf.mod(epoch_counter + idx + 1, 2), 1),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                lambda: tf.constant(0),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                lambda: tf.mod(tf.div(1 + epoch_counter, 2), num_lig_frames - 1) + 1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    else:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        raise NotImplementedError('ligand frame sampling method unknown')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # ligand_coords = tf.gather(tf.transpose(multiframe_ligand_coords, perm=[2, 0, 1]),current_frame)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ligand_coords = multiframe_ligand_coords[:, :, current_frame]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    receptor_coords = multiframe_receptor_coords[:, :, 0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print("Receptor shape:")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print(receptor_coords.get_shape())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print("Ligand shape:")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print(ligand_coords.get_shape())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    label = tf.gather(ligand_labels, current_frame)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return ligand_file, tf.squeeze(epoch_counter), tf.squeeze(label), ligand_elements, ligand_coords,\123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF           receptor_elements, receptor_coords123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef complex_coords_to_image(ligand_elements, ligand_coords, receptor_elements, receptor_coords, side_pixels, pixel_size,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                            cameraview=None):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """Take coordinates and elements of protein and ligand and convert them into an image.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Return image with one dimension so far."""123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # FIXME abandon ligand when it does not fit into the box (it's kept now)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # max_num_attempts - maximum number of affine transforms for the ligand to be tried123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    max_num_attemts = 1000  # TODO this should happen on the level of data preparation123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # affine_transform_pool_size is the first(batch) dimension of tensor of transition matrices to be returned123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # affine tranform pool is only generated once in the beginning of training and randomly sampled afterwards123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    affine_transform_pool_size = 10000123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # transform center ligand around zero123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ligand_center_of_mass = tf.reduce_mean(ligand_coords, reduction_indices=0)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    centered_ligand_coords = ligand_coords - ligand_center_of_mass123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    centered_receptor_coords = receptor_coords - ligand_center_of_mass123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # use TF while loop to find such an affine transform matrix that can fit the ligand so that no atoms are outside123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    box_size = (tf.cast(side_pixels, tf.float32) * pixel_size)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    def generate_transition_matrix(attempt, cameraview, random_cameraviews):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        """Takes initial coordinates of the ligand, generates a random affine transform matrix and transforms coordinates."""123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        cameraview = tf.gather(random_cameraviews,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                               tf.random_uniform([], minval=0, maxval=affine_transform_pool_size - 1,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                                 dtype=tf.int32))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        attempt += 1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        return attempt, cameraview, random_cameraviews123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    def not_all_in_the_box(attempt, cameraview, random_cameraviews, ligand_coords=centered_ligand_coords,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                           box_size=box_size,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                           max_num_attempts=max_num_attemts):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        """Takes affine transform matrix and box dimensions, performs the transformation, and checks if all atoms123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        are in the box."""123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        transformed_coords, cameraview = affinity.geom.affine_tform(ligand_coords, cameraview)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        not_all = tf.cast(123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            tf.reduce_max(tf.cast(tf.square(box_size * 0.5) - tf.square(transformed_coords) < 0, tf.int32)),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            tf.bool)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        within_iteration_limit = tf.cast(tf.reduce_sum(tf.cast(attempt < max_num_attemts, tf.float32)), tf.bool)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        return tf.logical_and(within_iteration_limit, not_all)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    attempt = tf.Variable(tf.constant(0, shape=[1]))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    random_cameraviews = tf.Variable(gen_affine_tform(affine_transform_pool_size,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                                      max_angle_degrees=10))  # FIXME: Use with_labels generation instead to have different rotations in x/y/z dimensions123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    if cameraview is None:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        cameraview = tf.gather(random_cameraviews, tf.random_uniform([], minval=0,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                                                     maxval=affine_transform_pool_size, dtype=tf.int64))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    else:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        cameraview = cameraview123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    last_attempt, final_cameraview, _ = tf.while_loop(not_all_in_the_box, generate_transition_matrix,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                                      [attempt, cameraview, random_cameraviews], parallel_iterations=1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # rotate receptor and ligand using an affine transform matrix found123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    rotatated_ligand_coords, _ = affinity.geom.affine_tform(centered_ligand_coords, final_cameraview)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    rotated_receptor_coords, _ = affinity.geom.affine_tform(centered_receptor_coords, final_cameraview)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # TODO: this should be an error: move this function to the level of data preparation123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # check if all of the atoms are in the box, if not set the ligand to 0, but do not raise an error123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    def set_elements_coords_zero():123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        return tf.constant([0], dtype=tf.int32), tf.constant([[0, 0, 0]], dtype=tf.float32)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    def keep_elements_coords():123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        return ligand_elements, rotatated_ligand_coords123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    not_all = tf.cast(123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        tf.reduce_max(tf.cast(tf.square(box_size * 0.5) - tf.square(rotatated_ligand_coords) < 0, tf.int32)),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        tf.bool)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ligand_elements, rotatated_ligand_coords = tf.case({tf.equal(not_all, tf.constant(True)):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                                            set_elements_coords_zero}, keep_elements_coords,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                                       exclusive=True)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # TODO: maybe throw an error when things don't fit ??123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # move coordinates of a complex to an integer number so as to put every atom on a grid123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # ceiled coords is an integer number out of real coordinates that corresponds to the index on the cell123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # epsilon - potentially, there might be very small rounding errors leading to additional indexes123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    epsilon = tf.constant(0.999, dtype=tf.float32)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ceiled_ligand_coords = tf.cast(tf.round((-0.5 + (tf.cast(side_pixels, tf.float32) * 0.5) +123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                             (rotatated_ligand_coords / pixel_size)) * epsilon), tf.int64)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ceiled_receptor_coords = tf.cast(tf.round((-0.5 + (tf.cast(side_pixels, tf.float32) * 0.5) +123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                               (rotated_receptor_coords / pixel_size)) * epsilon), tf.int64)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # crop atoms of the protein that do not fit inside the box123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    top_filter = tf.reduce_max(ceiled_receptor_coords, reduction_indices=1) < side_pixels123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    bottom_filter = tf.reduce_min(ceiled_receptor_coords, reduction_indices=1) > 0123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    retain_atoms = tf.logical_and(top_filter, bottom_filter)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    cropped_receptor_coords = tf.boolean_mask(ceiled_receptor_coords, retain_atoms)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    cropped_receptor_elements = tf.boolean_mask(receptor_elements, retain_atoms)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # FIXME: remove hydrogens123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # FIXME: put ligand and protein each into a separate layers of depth123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # FIXME: cropping and matmul123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # matmul is to escape bug within tensorflow when a boolean mask of undefined shape can not be used123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ligand_hydrogen_mask = tf.cast(tf.matmul(tf.transpose([ligand_elements],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                                          perm=[1, 0]), tf.ones([1, 1], tf.int32))[:, 0] > 1, tf.bool)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ligand_elements_noh = tf.boolean_mask(ligand_elements, ligand_hydrogen_mask)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ligand_coords_noh = tf.boolean_mask(ceiled_ligand_coords, ligand_hydrogen_mask)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    receptor_hydrogen_mask = tf.cast(tf.matmul(tf.transpose([cropped_receptor_elements],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                                            perm=[1, 0]), tf.ones([1, 1], tf.int32))[:, 0] > 1, tf.bool)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    receptor_elements_noh = tf.boolean_mask(cropped_receptor_elements, receptor_hydrogen_mask)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    receptor_coords_noh = tf.boolean_mask(cropped_receptor_coords, receptor_hydrogen_mask)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    complex_coords = tf.concat([ligand_coords_noh, receptor_coords_noh], 0)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    complex_elements = tf.concat([ligand_elements_noh + 7, receptor_elements_noh], 0)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # FIXME: validate indices = True123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    sparse_complex = tf.SparseTensor(indices=complex_coords, values=tf.to_float(complex_elements),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                     dense_shape=[side_pixels, side_pixels, side_pixels])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ordered_sparse_complex = tf.sparse_reorder(sparse_complex)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    complex_image = tf.sparse_tensor_to_dense(ordered_sparse_complex, validate_indices=False)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return complex_image, ligand_center_of_mass, final_cameraview123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef gen_affine_tform(num_frames, max_angle_degrees=360):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """Generates a very big batch of affine transform matrices in 3D. The first dimension is batch, the other two123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    describe typical affine transform matrices. Deep affine transform can be generated once in the beginning123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    of training, and later slices can be taken from it randomly to speed up the computation."""123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # shift range is hard coded to 10A because that's how the proteins look like123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # rotation range is hardcoded to 360 degrees123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    shift_range = tf.constant(10, dtype=tf.float32)  # FIXME123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    rotation_range = tf.cast(tf.convert_to_tensor(np.pi * max_angle_degrees / 180.0), dtype=tf.float32)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # randomly shift along X,Y,Z123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    x_shift = tf.random_uniform([num_frames], minval=-1, maxval=1, dtype=tf.float32) * shift_range123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    y_shift = tf.random_uniform([num_frames], minval=-1, maxval=1, dtype=tf.float32) * shift_range123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    z_shift = tf.random_uniform([num_frames], minval=-1, maxval=1, dtype=tf.float32) * shift_range123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # [1, 0, 0, random_x_shift],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # [0, 1, 0, random_y_shift],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # [0, 0, 1, random_z_shift],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # [0, 0, 0, 1]])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # try to do the following:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # generate nine tensors for each of them123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # concatenate and reshape sixteen tensors123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn0_0 = tf.ones([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn0_1 = tf.zeros([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn0_2 = tf.zeros([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn0_3 = x_shift123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn1_0 = tf.zeros([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn1_1 = tf.ones([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn1_2 = tf.zeros([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn1_3 = y_shift123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn2_0 = tf.zeros([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn2_1 = tf.zeros([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn2_2 = tf.ones([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn2_3 = z_shift123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn3_0 = tf.zeros([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn3_1 = tf.zeros([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn3_2 = tf.zeros([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn3_3 = tf.ones([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    xyz_shift_stick = tf.stack(123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        [afn0_0, afn0_1, afn0_2, afn0_3, afn1_0, afn1_1, afn1_2, afn1_3, afn2_0, afn2_1, afn2_2, afn2_3, afn3_0,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF         afn3_1, afn3_2, afn3_3])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    xyz_shift_matrix = tf.transpose(tf.reshape(xyz_shift_stick, [4, 4, num_frames]), perm=[2, 0, 1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # randomly rotate along X123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    x_rot = tf.random_uniform([num_frames], minval=-1, maxval=1, dtype=tf.float32) * rotation_range123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # [[1, 0, 0, 0],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # [0, cos(x_rot),-sin(x_rot),0],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # [0, sin(x_rot),cos(x_rot),0],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # [0, 0, 0, 1]],dtype=tf.float32)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn0_0 = tf.ones([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn0_1 = tf.zeros([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn0_2 = tf.zeros([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn0_3 = tf.zeros([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn1_0 = tf.zeros([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn1_1 = tf.cos(x_rot)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn1_2 = -tf.sin(x_rot)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn1_3 = tf.zeros([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn2_0 = tf.zeros([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn2_1 = tf.sin(x_rot)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn2_2 = tf.cos(x_rot)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn2_3 = tf.zeros([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn3_0 = tf.zeros([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn3_1 = tf.zeros([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn3_2 = tf.zeros([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn3_3 = tf.ones([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    x_rot_stick = tf.stack(123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        [afn0_0, afn0_1, afn0_2, afn0_3, afn1_0, afn1_1, afn1_2, afn1_3, afn2_0, afn2_1, afn2_2, afn2_3, afn3_0,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF         afn3_1, afn3_2, afn3_3])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    x_rot_matrix = tf.transpose(tf.reshape(x_rot_stick, [4, 4, num_frames]), perm=[2, 0, 1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # randomly rotate along Y123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    y_rot = tf.random_uniform([num_frames], minval=-1, maxval=1, dtype=tf.float32, seed=None,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                              name=None) * rotation_range123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # [cos(y_rot), 0,sin(y_rot), 0],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # [0, 1, 0, 0],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # [-sin(y_rot), 0,cos(y_rot), 0],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # [0, 0 ,0 ,1]])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn0_0 = tf.cos(y_rot)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn0_1 = tf.zeros([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn0_2 = tf.sin(y_rot)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn0_3 = tf.zeros([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn1_0 = tf.zeros([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn1_1 = tf.ones([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn1_2 = tf.zeros([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn1_3 = tf.zeros([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn2_0 = -tf.sin(y_rot)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn2_1 = tf.zeros([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn2_2 = tf.cos(y_rot)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn2_3 = tf.zeros([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn3_0 = tf.zeros([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn3_1 = tf.zeros([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn3_2 = tf.zeros([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn3_3 = tf.ones([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    y_rot_stick = tf.stack(123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        [afn0_0, afn0_1, afn0_2, afn0_3, afn1_0, afn1_1, afn1_2, afn1_3, afn2_0, afn2_1, afn2_2, afn2_3, afn3_0,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF         afn3_1, afn3_2, afn3_3])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    y_rot_matrix = tf.transpose(tf.reshape(y_rot_stick, [4, 4, num_frames]), perm=[2, 0, 1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # randomly rotate along Z123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    z_rot = tf.random_uniform([num_frames], minval=-1, maxval=1, dtype=tf.float32) * rotation_range123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # [[cos(z_rot), -sin(z_rot), 0, 0],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # [sin(z_rot), cos(z_rot), 0, 0],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # [0, 0, 1, 0],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # [0, 0, 0, 1]])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn0_0 = tf.cos(z_rot)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn0_1 = -tf.sin(z_rot)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn0_2 = tf.zeros([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn0_3 = tf.zeros([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn1_0 = tf.sin(z_rot)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn1_1 = tf.cos(z_rot)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn1_2 = tf.zeros([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn1_3 = tf.zeros([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn2_0 = tf.zeros([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn2_1 = tf.zeros([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn2_2 = tf.ones([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn2_3 = tf.zeros([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn3_0 = tf.zeros([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn3_1 = tf.zeros([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn3_2 = tf.zeros([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    afn3_3 = tf.ones([num_frames])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    z_rot_stick = tf.stack(123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        [afn0_0, afn0_1, afn0_2, afn0_3, afn1_0, afn1_1, afn1_2, afn1_3, afn2_0, afn2_1, afn2_2, afn2_3, afn3_0,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF         afn3_1, afn3_2, afn3_3])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    z_rot_matrix = tf.transpose(tf.reshape(z_rot_stick, [4, 4, num_frames]), perm=[2, 0, 1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    xyz_shift_xyz_rot = tf.matmul(tf.matmul(tf.matmul(xyz_shift_matrix, x_rot_matrix), y_rot_matrix), z_rot_matrix)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return xyz_shift_xyz_rot123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF