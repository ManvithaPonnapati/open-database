import tensorflow as tf123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport numpy as np123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef stnet(x):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    x_tensor = tf.reshape(x, [-1, 40, 40, 1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # %% We'll setup the two-layer localisation network to figure out the123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # %% parameters for an affine transformation of the input123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # %% Create variables for fully connected layer123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    W_fc_loc1 = weight_variable([1600, 20])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    b_fc_loc1 = bias_variable([20])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    W_fc_loc2 = weight_variable([20, 6])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # Use identity transformation as starting point123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    initial = np.array([[1., 0, 0], [0, 1., 0]])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    initial = initial.astype('float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    initial = initial.flatten()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    b_fc_loc2 = tf.Variable(initial_value=initial, name='b_fc_loc2')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # %% Define the two layer localisation network123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    h_fc_loc1 = tf.nn.tanh(tf.matmul(x, W_fc_loc1) + b_fc_loc1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # %% We can add dropout for regularizing and to reduce overfitting like so:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    keep_prob = tf.placeholder(tf.float32)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    h_fc_loc1_drop = tf.nn.dropout(h_fc_loc1, keep_prob)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # %% Second layer123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    h_fc_loc2 = tf.nn.tanh(tf.matmul(h_fc_loc1_drop, W_fc_loc2) + b_fc_loc2)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # %% We'll create a spatial transformer module to identify discriminative123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # %% patches123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    out_size = (40, 40)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    h_trans = transformer(x_tensor, h_fc_loc2, out_size)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # %% We'll setup the first convolutional layer123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # Weight matrix is [height x width x input_channels x output_channels]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    filter_size = 3123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    n_filters_1 = 16123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    W_conv1 = weight_variable([filter_size, filter_size, 1, n_filters_1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # %% Bias is [output_channels]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    b_conv1 = bias_variable([n_filters_1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # %% Now we can build a graph which does the first layer of convolution:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # we define our stride as batch x height x width x channels123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # instead of pooling, we use strides of 2 and more layers123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # with smaller filters.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    h_conv1 = tf.nn.relu(123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        tf.nn.conv2d(input=h_trans,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                     filter=W_conv1,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                     strides=[1, 2, 2, 1],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                     padding='SAME') +123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        b_conv1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # %% And just like the first layer, add additional layers to create123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # a deep net123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    n_filters_2 = 16123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    W_conv2 = weight_variable([filter_size, filter_size, n_filters_1, n_filters_2])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    b_conv2 = bias_variable([n_filters_2])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    h_conv2 = tf.nn.relu(123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        tf.nn.conv2d(input=h_conv1,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                     filter=W_conv2,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                     strides=[1, 2, 2, 1],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                     padding='SAME') +123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        b_conv2)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # %% We'll now reshape so we can connect to a fully-connected layer:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    h_conv2_flat = tf.reshape(h_conv2, [-1, 10 * 10 * n_filters_2])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # %% Create a fully-connected layer:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    n_fc = 1024123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    W_fc1 = weight_variable([10 * 10 * n_filters_2, n_fc])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    b_fc1 = bias_variable([n_fc])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    h_fc1 = tf.nn.relu(tf.matmul(h_conv2_flat, W_fc1) + b_fc1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # %% And finally our softmax layer:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    W_fc2 = weight_variable([n_fc, 10])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    b_fc2 = bias_variable([10])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    y_logits = tf.matmul(h_fc1_drop, W_fc2) + b_fc2123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return y_logits123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef conv2d(x, n_filters,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF           k_h=5, k_w=5,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF           stride_h=2, stride_w=2,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF           stddev=0.02,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF           activation=lambda x: x,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF           bias=True,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF           padding='SAME',123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF           name="Conv2D"):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """2D Convolution with options for kernel size, stride, and init deviation.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Parameters123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ----------123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    x : Tensor123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Input tensor to convolve.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    n_filters : int123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Number of filters to apply.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    k_h : int, optional123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Kernel height.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    k_w : int, optional123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Kernel width.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    stride_h : int, optional123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Stride in rows.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    stride_w : int, optional123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Stride in cols.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    stddev : float, optional123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Initialization's standard deviation.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    activation : arguments, optional123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Function which applies a nonlinearity123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    padding : str, optional123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        'SAME' or 'VALID'123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    name : str, optional123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Variable scope to use.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Returns123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    -------123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    x : Tensor123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Convolved input.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.variable_scope(name):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        w = tf.get_variable(123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            'w', [k_h, k_w, x.get_shape()[-1], n_filters],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            initializer=tf.truncated_normal_initializer(stddev=stddev))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        conv = tf.nn.conv2d(123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x, w, strides=[1, stride_h, stride_w, 1], padding=padding)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        if bias:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            b = tf.get_variable(123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                'b', [n_filters],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                initializer=tf.truncated_normal_initializer(stddev=stddev))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            conv = conv + b123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        return conv123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef linear(x, n_units, scope=None, stddev=0.02,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF           activation=lambda x: x):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """Fully-connected network.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Parameters123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ----------123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    x : Tensor123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Input tensor to the network.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    n_units : int123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Number of units to connect to.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    scope : str, optional123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Variable scope to use.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    stddev : float, optional123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Initialization's standard deviation.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    activation : arguments, optional123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Function which applies a nonlinearity123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Returns123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    -------123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    x : Tensor123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Fully-connected output.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    shape = x.get_shape().as_list()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.variable_scope(scope or "Linear"):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        matrix = tf.get_variable("Matrix", [shape[1], n_units], tf.float32,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                 tf.random_normal_initializer(stddev=stddev))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        return activation(tf.matmul(x, matrix))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# %%123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef weight_variable(shape):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    '''Helper function to create a weight variable initialized with123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    a normal distribution123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Parameters123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ----------123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    shape : list123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Size of weight variable123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    '''123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # initial = tf.random_normal(shape, mean=0.0, stddev=0.01)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    initial = tf.zeros(shape)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return tf.Variable(initial)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# %%123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef bias_variable(shape):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    '''Helper function to create a bias variable initialized with123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    a constant value.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Parameters123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ----------123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    shape : list123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Size of weight variable123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    '''123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    initial = tf.random_normal(shape, mean=0.0, stddev=0.01)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return tf.Variable(initial)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# %%123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef dense_to_one_hot(labels, n_classes=2):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """Convert class labels from scalars to one-hot vectors."""123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    labels = np.array(labels)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    n_labels = labels.shape[0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    index_offset = np.arange(n_labels) * n_classes123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    labels_one_hot = np.zeros((n_labels, n_classes), dtype=np.float32)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    labels_one_hot.flat[index_offset + labels.ravel()] = 1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return labels_one_hot123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef transformer(U, theta, out_size, name='SpatialTransformer', **kwargs):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """Spatial Transformer Layer123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Implements a spatial transformer layer as described in [1]_.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Based on [2]_ and edited by David Dao for Tensorflow.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Parameters123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ----------123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    U : float123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        The output of a convolutional net should have the123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        shape [num_batch, height, width, num_channels].123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    theta: float123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        The output of the123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        localisation network should be [num_batch, 6].123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    out_size: tuple of two ints123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        The size of the output of the network (height, width)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    References123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ----------123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    .. [1]  Spatial Transformer Networks123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            Max Jaderberg, Karen Simonyan, Andrew Zisserman, Koray Kavukcuoglu123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            Submitted on 5 Jun 2015123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    .. [2]  https://github.com/skaae/transformer_network/blob/master/transformerlayer.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Notes123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    -----123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    To initialize the network to the identity transform init123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ``theta`` to :123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        identity = np.array([[1., 0., 0.],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                             [0., 1., 0.]])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        identity = identity.flatten()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        theta = tf.Variable(initial_value=identity)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    def _repeat(x, n_repeats):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        with tf.variable_scope('_repeat'):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            rep = tf.transpose(123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                tf.expand_dims(tf.ones(shape=tf.stack([n_repeats, ])), 1), [1, 0])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            rep = tf.cast(rep, 'int32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x = tf.matmul(tf.reshape(x, (-1, 1)), rep)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            return tf.reshape(x, [-1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    def _interpolate(im, x, y, out_size):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        with tf.variable_scope('_interpolate'):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            # constants123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            num_batch = tf.shape(im)[0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            height = tf.shape(im)[1]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            width = tf.shape(im)[2]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            channels = tf.shape(im)[3]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x = tf.cast(x, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y = tf.cast(y, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            height_f = tf.cast(height, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            width_f = tf.cast(width, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            out_height = out_size[0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            out_width = out_size[1]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            zero = tf.zeros([], dtype='int32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            max_y = tf.cast(tf.shape(im)[1] - 1, 'int32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            max_x = tf.cast(tf.shape(im)[2] - 1, 'int32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            # scale indices from [-1, 1] to [0, width/height]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x = (x + 1.0)*(width_f) / 2.0123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y = (y + 1.0)*(height_f) / 2.0123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            # do sampling123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x0 = tf.cast(tf.floor(x), 'int32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x1 = x0 + 1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y0 = tf.cast(tf.floor(y), 'int32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y1 = y0 + 1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x0 = tf.clip_by_value(x0, zero, max_x)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x1 = tf.clip_by_value(x1, zero, max_x)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y0 = tf.clip_by_value(y0, zero, max_y)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y1 = tf.clip_by_value(y1, zero, max_y)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            dim2 = width123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            dim1 = width*height123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            base = _repeat(tf.range(num_batch)*dim1, out_height*out_width)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            base_y0 = base + y0*dim2123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            base_y1 = base + y1*dim2123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            idx_a = base_y0 + x0123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            idx_b = base_y1 + x0123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            idx_c = base_y0 + x1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            idx_d = base_y1 + x1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            # use indices to lookup pixels in the flat image and restore123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            # channels dim123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            im_flat = tf.reshape(im, tf.stack([-1, channels]))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            im_flat = tf.cast(im_flat, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            Ia = tf.gather(im_flat, idx_a)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            Ib = tf.gather(im_flat, idx_b)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            Ic = tf.gather(im_flat, idx_c)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            Id = tf.gather(im_flat, idx_d)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            # and finally calculate interpolated values123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x0_f = tf.cast(x0, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x1_f = tf.cast(x1, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y0_f = tf.cast(y0, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y1_f = tf.cast(y1, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            wa = tf.expand_dims(((x1_f-x) * (y1_f-y)), 1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            wb = tf.expand_dims(((x1_f-x) * (y-y0_f)), 1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            wc = tf.expand_dims(((x-x0_f) * (y1_f-y)), 1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            wd = tf.expand_dims(((x-x0_f) * (y-y0_f)), 1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            output = tf.add_n([wa*Ia, wb*Ib, wc*Ic, wd*Id])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            return output123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    def _meshgrid(height, width):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        with tf.variable_scope('_meshgrid'):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            # This should be equivalent to:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            #  x_t, y_t = np.meshgrid(np.linspace(-1, 1, width),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            #                         np.linspace(-1, 1, height))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            #  ones = np.ones(np.prod(x_t.shape))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            #  grid = np.vstack([x_t.flatten(), y_t.flatten(), ones])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x_t = tf.matmul(tf.ones(shape=tf.stack([height, 1])),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                            tf.transpose(tf.expand_dims(tf.linspace(-1.0, 1.0, width), 1), [1, 0]))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y_t = tf.matmul(tf.expand_dims(tf.linspace(-1.0, 1.0, height), 1),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                            tf.ones(shape=tf.stack([1, width])))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x_t_flat = tf.reshape(x_t, (1, -1))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y_t_flat = tf.reshape(y_t, (1, -1))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            ones = tf.ones_like(x_t_flat)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            grid = tf.concat(axis=0, values=[x_t_flat, y_t_flat, ones])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            return grid123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    def _transform(theta, input_dim, out_size):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        with tf.variable_scope('_transform'):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            num_batch = tf.shape(input_dim)[0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            height = tf.shape(input_dim)[1]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            width = tf.shape(input_dim)[2]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            num_channels = tf.shape(input_dim)[3]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            theta = tf.reshape(theta, (-1, 2, 3))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            theta = tf.cast(theta, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            # grid of (x_t, y_t, 1), eq (1) in ref [1]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            height_f = tf.cast(height, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            width_f = tf.cast(width, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            out_height = out_size[0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            out_width = out_size[1]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            grid = _meshgrid(out_height, out_width)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            grid = tf.expand_dims(grid, 0)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            grid = tf.reshape(grid, [-1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            grid = tf.tile(grid, tf.stack([num_batch]))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            grid = tf.reshape(grid, tf.stack([num_batch, 3, -1]))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            # Transform A x (x_t, y_t, 1)^T -> (x_s, y_s)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            T_g = tf.matmul(theta, grid)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x_s = tf.slice(T_g, [0, 0, 0], [-1, 1, -1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y_s = tf.slice(T_g, [0, 1, 0], [-1, 1, -1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x_s_flat = tf.reshape(x_s, [-1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y_s_flat = tf.reshape(y_s, [-1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            input_transformed = _interpolate(123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                input_dim, x_s_flat, y_s_flat,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                out_size)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            output = tf.reshape(123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                input_transformed, tf.stack([num_batch, out_height, out_width, num_channels]))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            return output123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.variable_scope(name):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        output = _transform(theta, U, out_size)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        return output123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef batch_transformer(U, thetas, out_size, name='BatchSpatialTransformer'):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """Batch Spatial Transformer Layer123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Parameters123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ----------123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    U : float123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        tensor of inputs [num_batch,height,width,num_channels]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    thetas : float123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        a set of transformations for each input [num_batch,num_transforms,6]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    out_size : int123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        the size of the output [out_height,out_width]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Returns: float123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Tensor of size [num_batch*num_transforms,out_height,out_width,num_channels]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.variable_scope(name):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        num_batch, num_transforms = map(int, thetas.get_shape().as_list()[:2])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        indices = [[i]*num_transforms for i in xrange(num_batch)]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        input_repeated = tf.gather(U, tf.reshape(indices, [-1]))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return transformer(input_repeated, thetas, out_size)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF