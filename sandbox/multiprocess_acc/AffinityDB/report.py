"""123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFgenerate report for the database123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF"""123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport os123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport sys123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFfrom copy import copy123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFfrom collections import Counter123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport numpy as np 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport pandas as pd 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport config123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFfrom db import database123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdb = database()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdataframe_dict = {}123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef load_dataframe():123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #db.export()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    for table in db.tables.keys():123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        try:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            csv_path = os.path.join(config.table_dir, table+'.csv')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        except IOError as e:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            print e123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            continue123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        dataframe_dict[table] = pd.read_csv(csv_path)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef gather_state():123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    gather report for state123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    state_tables = [tab for tab in dataframe_dict.keys() if tab.endswith('state')]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    state_tables = sorted(state_tables)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    records = []123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    for table in state_tables:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        csv_path = os.path.join(config.table_dir,table+'.csv')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        df = pd.read_csv(csv_path)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        success_entrys = df[df['state'] == 1]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        success_num = len(success_entrys)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        failed_entrys = df[df['state'] == 0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        failed_group = failed_entrys.groupby('comment')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        failed_count = []123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        for name, group in failed_group:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            failed_count.append(name, len(group))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        print table123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        print 'success : ', success_num123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        if len(failed_count):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            print 'failed : ' 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            for reason, num in failed_count:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                print "\t%d\t%s" % (num, reason)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        print '\n\n'123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef report_for_state_by_id(dataframe, identifier, total_num):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    df_success = dataframe[dataframe['state']==1]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    df_failed = dataframe[dataframe['state']==0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print "\ttotal : %d\n" % total_num123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    success = len(df_success)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print "\tfinished : %d\tpercent: %.2f" % (success, 100.0 * success/total_num)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    rest = total_num - success123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print "\trest     : %d\tpercent: %.2f " % ( rest, 100.0 * rest/ total_num)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    failed_group = df_failed.groupby('comment')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    failed_count = []123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    for name, group in failed_group:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        failed_count.append([name, len(group)])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    if len(failed_count):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        print 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        for reason, failed_num in failed_count:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            print "\t%d failed for : %s" % (failed_num, reason)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef report_for_state(dataframe, name, total_num, key='identifier',cont='For %s\n'):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print '\n\n==========\n%s\n==========\n' % name123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    data_groups = dataframe.groupby(key)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    for identifier, group in data_groups:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        print cont % identifier123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        report_for_state_by_id(group, identifier, total_num)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef reporter_test():123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ligands_num = len(dataframe_dict['ligand_atom_num'])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    report_for_state(dataframe_dict['dock_state'], 'dock', ligands_num,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                    'identifier','result for %s\n')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    receptor_info = dataframe_dict['receptor_info']123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    pair_cumsum = lambda x: (x-1)*x/2 if x>1 else 0123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    similarity_pair_num = sum(receptor_info['residue_num'].apply(pair_cumsum))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    report_for_state(dataframe_dict['similarity_state'], 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                    'similarity', 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                    similarity_pair_num, 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                    'finger_print',123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                    'use finger print %s\n')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    overlap_ligands_pairs = sum(receptor_info['residue_num'].apply(lambda x:x*x))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    report_for_state(dataframe_dict['overlap_state'],'overlap',overlap_ligands_pairs,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                    'identifier',123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                    'for docking result of %s\n')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ligand_atom_num = copy(dataframe_dict['ligand_atom_num'])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ligand_atom_num['rlpair'] = ligand_atom_num['name'].apply(lambda x:'_'.join(x.split('_')[:2]))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ligand_count = Counter(ligand_atom_num['rlpair'])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    pair_cumsum = lambda x: x*x 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    rmsd_count_num = sum(map(pair_cumsum, ligand_count.values()))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    report_for_state(dataframe_dict['rmsd_state'], 'rmsd', rmsd_count_num,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                    'identifier',123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                    'for docking result of %s\n')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    report_for_state(dataframe_dict['native_contact_state'], 'native_contact', ligands_num,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                    'identifier',123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                    'for docking result of %s\n' )123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef reporter_gen():123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ligands_atom = len(dataframe_dict['ligand_atom_num'])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    dock_df = dataframe_dict['dock_state']123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    dock_success = dock_df[dock_df['state']==1]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    dock_failed = dock_df[dock_df['state']==0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    failed_group = dock_failed.groupby('comment')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    failed_count = []123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    for name, group in failed_group:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        failed_count.append([name, len(group)])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print "\n\n=========\ndocking\n=========\n"123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ligands_num = ligands_atom123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print "total ligands : %d" % ligands_num123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    success = len(dock_success)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print "finished: %d\tpercents: %f" % (success, 100.0 * success/ligands_num)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    rest = ligands_num - success123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print "rest: %d\tpercent: %f " % ( rest, 100.0 * rest/ ligands_num)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print '\n'123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    for reason, failed_num in failed_count:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        print "%d ligands failed docking due to %s" % (failed_num, reason)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    receptor_info = dataframe_dict['receptor_info']123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    pair_cumsum = lambda x: (x-1)*x/2 if x>1 else 0123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ligands_pair_num = sum(receptor_info['residue_num'].apply(pair_cumsum))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    similarity123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    similar_df = dataframe_dict['similarity']123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    similar_group = similar_df.groupby(['finger_print'])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    similar_count = []123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    for name, group in similar_group:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        similar_count.append([name, len(group)])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print "\n\n=========\nsimilarity\n============\n"123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    for finger_print, finish in similar_count:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        print "calculate similarity use finger print %s" % finger_print123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        print "finished: %d\tpercent: %f" % (finish, 100.0 * finish / ligands_pair_num)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        rest = ligands_pair_num - finish123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        print "rest: %d\tpercent: %f" % (rest, 100.0 * rest / ligands_pair_num)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    overlap123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    overlap_ligands_pairs = sum(receptor_info['residue_num'].apply(lambda x:x*x))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    overlap_state = dataframe_dict['overlap_state']123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print "\n\n=========\noverlap\n=========\n"123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    overlap_groups = overlap_state.groupby('identifier')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    for identifier, overlap_group in overlap_groups :123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        overlap_success = overlap_group[overlap_group['state']==1]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        overlap_failed = overlap_group[overlap_group['state']==1]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        overlap_count = []123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        for identifier, group in overlap_group:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            overlap_count.append([identifier, len(group)])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        print "total ligands pairs : %d" % overlap_ligands_pairs123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        for identifer , finish in overlap_count:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            print "overlap result for %s" % identifier123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            print "finished: %d\tpercent: %f " % (finish, 100.0 * finish / overlap_ligands_pairs)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            rest = overlap_ligands_pairs - finish123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            print "rest: %d\tpercent: %f" % (rest, 100.0 * rest / overlap_ligands_pairs )123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    rmsd123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print "\n\n=========\nrmsd\n=========\n"123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ligand_atom_num = copy(dataframe_dict['ligand_atom_num'])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ligand_atom_num['rlpair'] = ligand_atom_num['name'].apply(lambda x:'_'.join(x.split('_')[:2]))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ligand_count = Counter(ligand_atom_num['rlpair'])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    pair_cumsum = lambda x: x*x 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    rmsd_count_num = sum(map(pair_cumsum, ligand_count.values()))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print rmsd_count_num123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    rmsd_state = dataframe_dict['rmsd_state']123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    rmsd_success = rmsd_state[rmsd_state['state']== 1][['docked_ligand','crystal_ligand']]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    rmsd_success =rmsd_success.drop_duplicates()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    rmsd_failed = rmsd_state[rmsd_state['state'] == 0][['docked_ligand','crystal_ligand','comment']]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    rmsd_failed = rmsd_failed.drop_duplicates()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    failed_group = rmsd_failed.groupby('comment')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    failed_count = []123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    for name, group in failed_group:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        failed_count.append([name, len(group)])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    success = len(rmsd_success)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print "rmsd"123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print "finished: %d\t percent: %f" % (success, 100.0 * success/rmsd_count_num)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    rest = rmsd_count_num - success123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print "rest: %d\t percent: %f" % (rest, 100.0 * rest/rmsd_count_num)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    for reason, failed_num in failed_count:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        print "%d pairs failed due to %s" % (failed_num, reason)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    overlap123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef _reporter_gen():123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    total_ligands_num = len(dataframe_dict['ligand_atom_num'])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    dock_group = dataframe_dict['dock_state'].groupby('identifier')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef rmsd_report():123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    pass123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFload_dataframe()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFreporter_test()