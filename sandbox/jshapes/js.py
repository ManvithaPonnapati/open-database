"""123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFst5.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFThis file contains the graph structure for simpletrain5.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF"""123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport os123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport re123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport tensorflow as tf123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport numpy as np123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport js_input123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFfrom constants import FLAGS123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# Global constants describing the MSHAPES data set.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFIMAGE_SIZE = FLAGS.IMAGE_SIZE123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFNUM_CLASSES = FLAGS.NUM_CLASSES123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFNUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = FLAGS.NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFNUM_EXAMPLES_PER_EPOCH_FOR_EVAL = FLAGS.NUM_EXAMPLES_PER_EPOCH_FOR_EVAL123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFTOWER_NAME = FLAGS.TOWER_NAME123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef inputs(eval_data):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """Construct input for MSHAPES evaluation using the Reader ops.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Args:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      eval_data: bool, indicating if one should use the train or eval data set.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Returns:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      labels: Labels. 1D tensor of [batch_size] size.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Raises:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      ValueError: If no data_dir123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    if not FLAGS.DATA_DIR:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        raise ValueError('Please supply a data_dir')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    data_dir = os.path.join(FLAGS.DATA_DIR, '')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    (filequeue, (images, labels)) = js_input.inputs(eval_data=eval_data,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                                    data_dir=data_dir,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                                    batch_size=FLAGS.BATCH_SIZE)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # print("Reenqueues: ")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # print(reenqueues)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    if FLAGS.USE_FP16:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        images = tf.cast(images, tf.float16)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        labels = tf.cast(labels, tf.float16)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return filequeue, images, labels123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef train(total_loss):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """Train CIFAR-10 model.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Create an optimizer and apply to all trainable variables. Add moving123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    average for all trainable variables.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Args:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      total_loss: Total loss from loss().123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Returns:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      train_op: op for training.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    train_op = tf.train.AdamOptimizer().minimize(total_loss)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return train_op123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# def inference_pretrained(images):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#     this could also be the output a different Keras model or layer123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#     input_tensor = Input(shape=(150, 150, 3))  # this assumes K.image_data_format() == 'channels_last'123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#     model = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=True)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#     return model123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef inference(images):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """Build the CIFAR-10 model.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Args:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      images: Images returned from distorted_inputs() or inputs().123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Returns:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      Logits.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # We instantiate all variables using tf.get_variable() instead of123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # tf.Variable() in order to share variables across multiple GPU training runs.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # If we only ran this model on a single GPU, we could simplify this function123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # by replacing all instances of tf.get_variable() with tf.Variable().123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # conv1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.variable_scope('conv1') as scope:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        kernel = _variable_with_weight_decay('weights',123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                             shape=[5, 5, 2, 64],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                             stddev=5e-3,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                             wd=0.0)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        conv = tf.nn.conv2d(images, kernel, [1, 1, 1, 1], padding='SAME')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        biases = _variable_on_cpu('biases', [64], tf.constant_initializer(1e-2))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        pre_activation = tf.nn.bias_add(conv, biases)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        conv1 = tf.nn.relu(pre_activation, name=scope.name)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        _activation_summary(conv1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # pool1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    pool1 = tf.nn.max_pool(conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                           padding='SAME', name='pool1')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # norm1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    norm1 = tf.nn.lrn(pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                      name='norm1')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # conv2123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.variable_scope('conv2') as scope:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        kernel = _variable_with_weight_decay('weights',123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                             shape=[5, 5, 64, 64],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                             stddev=5e-2,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                             wd=0.0)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        conv = tf.nn.conv2d(norm1, kernel, [1, 1, 1, 1], padding='SAME')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.1))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        pre_activation = tf.nn.bias_add(conv, biases)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        conv2 = tf.nn.relu(pre_activation, name=scope.name)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        _activation_summary(conv2)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # norm2123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    norm2 = tf.nn.lrn(conv2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                      name='norm2')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # pool2123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    pool2 = tf.nn.max_pool(norm2, ksize=[1, 3, 3, 1],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                           strides=[1, 2, 2, 1], padding='SAME', name='pool2')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # local3123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.variable_scope('local3') as scope:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # Move everything into depth so we can perform a single matrix multiply.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        reshape = tf.reshape(pool2, [FLAGS.BATCH_SIZE, -1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        dim = reshape.get_shape()[1].value123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        weights = _variable_with_weight_decay('weights', shape=[dim, 384],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                              stddev=0.04, wd=0.004)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        biases = _variable_on_cpu('biases', [384], tf.constant_initializer(0.1))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        local3 = tf.nn.relu(tf.matmul(reshape, weights) + biases, name=scope.name)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        _activation_summary(local3)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # local4123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.variable_scope('local4') as scope:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        weights = _variable_with_weight_decay('weights', shape=[384, 192],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                              stddev=0.04, wd=0.004)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        biases = _variable_on_cpu('biases', [192], tf.constant_initializer(0.1))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        local4 = tf.nn.relu(tf.matmul(local3, weights) + biases, name=scope.name)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        _activation_summary(local4)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # linear layer(WX + b),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # We don't apply softmax here because123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # tf.nn.sparse_softmax_cross_entropy_with_logits accepts the unscaled logits123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # and performs the softmax internally for efficiency.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.variable_scope('softmax_linear') as scope:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        weights = _variable_with_weight_decay('weights', [192, NUM_CLASSES],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                              stddev=1 / 192.0, wd=0.0)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        biases = _variable_on_cpu('biases', [NUM_CLASSES],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                  tf.constant_initializer(0.0))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        softmax_linear = tf.add(tf.matmul(local4, weights), biases, name=scope.name)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        _activation_summary(softmax_linear)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return softmax_linear123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef spatial_transformer_network(input_fmap, theta, out_dims=None, **kwargs):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Spatial Transformer Network layer implementation as described in [1].123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    The layer is composed of 3 elements:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    - localisation_net: takes the original image as input and outputs123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      the parameters of the affine transformation that should be applied123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      to the input image.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    - affine_grid_generator: generates a grid of (x,y) coordinates that123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      correspond to a set of points where the input should be sampled123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      to produce the transformed output.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    - bilinear_sampler: takes as input the original image and the grid123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      and produces the output image using bilinear interpolation.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Input123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    -----123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    - input_fmap: output of the previous layer. Can be input if spatial123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      transformer layer is at the beginning of architecture. Should be123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      a tensor of shape (B, H, W, C).123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    - theta: affine transform tensor of shape (B, 6). Permits cropping,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      translation and isotropic scaling. Initialize to identity matrix.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      It is the output of the localization network.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Returns123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    -------123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    - out_fmap: transformed input feature map. Tensor of size (B, H, W, C).123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Notes123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    -----123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    [1]: 'Spatial Transformer Networks', Jaderberg et. al,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF         (https://arxiv.org/abs/1506.02025)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # grab input dimensions123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    B = tf.shape(input_fmap)[0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    H = tf.shape(input_fmap)[1]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    W = tf.shape(input_fmap)[2]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    C = tf.shape(input_fmap)[3]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # reshape theta to (B, 2, 3)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    theta = tf.reshape(theta, [B, 2, 3])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # generate grids of same size123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    batch_grids = affine_grid_generator(H, W, theta)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # or upsample/downsample if specified123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    if out_dims:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        out_H = out_dims[0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        out_W = out_dims[1]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        batch_grids = affine_grid_generator(out_H, out_W, theta)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # extract x and y coordinates123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    x_s = tf.squeeze(batch_grids[:, 0:1, :, :])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    y_s = tf.squeeze(batch_grids[:, 1:2, :, :])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # sample input with grid to get output123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    out_fmap = bilinear_sampler(input_fmap, x_s, y_s)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return out_fmap123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef stn(images):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print("Input shape")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print(images.get_shape())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    conv1_loc = Conv2D(images, 2, 5, 32, name='conv1_loc')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print(conv1_loc.get_shape())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    pool1_loc = MaxPooling2D(conv1_loc, use_relu=True, name='pool1_loc')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print(pool1_loc.get_shape())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    conv2_loc = Conv2D(pool1_loc, 32, 5, 64, name='conv2_loc')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print(conv2_loc.get_shape())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    pool2_loc = MaxPooling2D(conv2_loc, use_relu=True, name='pool2_loc')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print(pool2_loc.get_shape())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    pool2_loc_flat, pool2_loc_size = Flatten(pool2_loc)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    fc1_loc = Dense(pool2_loc_flat, pool2_loc_size, 2048, use_relu=False, name='fc1_loc')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    fc2_loc = Dense(fc1_loc, 2048, 512, use_relu=True, name='fc2_loc')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    fc3_loc = Dense(fc2_loc, 512, 6, use_relu=False, trans=True, name='fc3_loc')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print("fc3_loc shape:")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print(fc3_loc.get_shape())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # spatial transformer123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    h_trans = spatial_transformer_network(images, fc3_loc)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print("h_trans shape:")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print(h_trans.get_shape())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # convnet123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    conv1 = Conv2D(images, 2, 5, 32, name='conv1')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    bn1 = BatchNormalization(conv1, phase=False, name='bn1')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    pool1 = MaxPooling2D(bn1, use_relu=True, name='pool1')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    conv2 = Conv2D(pool1, 32, 5, 64, name='conv2')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    bn2 = BatchNormalization(conv2, phase=False, name='bn2')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    pool2 = MaxPooling2D(bn2, use_relu=True, name='pool2')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    conv3 = Conv2D(pool2, 64, 3, 128, name='conv3')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    bn3 = BatchNormalization(conv3, phase=False, name='bn3')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    pool3 = MaxPooling2D(bn3, use_relu=True, name='pool3')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    pool3_flat, pool3_size = Flatten(pool3)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    fc1 = Dense(pool3_flat, pool3_size, 2048, use_relu=False, name='fc1')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    bn4 = BatchNormalization(fc1, phase=False, use_relu=True, name='bn4')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    fc2 = Dense(bn4, 2048, 512, use_relu=False, name='fc2')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    bn5 = BatchNormalization(fc2, phase=False, use_relu=True, name='bn5')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    logits = Dense(bn5, 512, FLAGS.NUM_CLASSES, name='fc3', use_relu=False)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return logits123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef get_pixel_value(img, x, y):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Utility function to get pixel value for coordinate123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    vectors x and y from a  4D tensor image.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Input123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    -----123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    - img: tensor of shape (B, H, W, C)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    - x: flattened tensor of shape (B*H*W, )123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    - y: flattened tensor of shape (B*H*W, )123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Returns123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    -------123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    - output: tensor of shape (B, H, W, C)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    shape = tf.shape(x)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    batch_size = shape[0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    height = shape[1]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    width = shape[2]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    batch_idx = tf.range(0, batch_size)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    batch_idx = tf.reshape(batch_idx, (batch_size, 1, 1))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    b = tf.tile(batch_idx, (1, height, width))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    indices = tf.stack([b, y, x], 3)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return tf.gather_nd(img, indices)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef affine_grid_generator(height, width, theta):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    This function returns a sampling grid, which when123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    used with the bilinear sampler on the input feature123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    map, will create an output feature map that is an123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    affine transformation [1] of the input feature map.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Input123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    -----123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    - height: desired height of grid/output. Used123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      to downsample or upsample.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    - width: desired width of grid/output. Used123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      to downsample or upsample.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    - theta: affine transform matrices of shape (num_batch, 2, 3).123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      For each image in the batch, we have 6 theta parameters of123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      the form (2x3) that define the affine transformation T.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Returns123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    -------123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    - normalized gird (-1, 1) of shape (num_batch, 2, H, W).123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      The 2nd dimension has 2 components: (x, y) which are the123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      sampling points of the original image for each point in the123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      target image.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Note123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ----123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    [1]: the affine transformation allows cropping, translation,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF         and isotropic scaling.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # grab batch size123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    num_batch = tf.shape(theta)[0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # create normalized 2D grid123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    x = tf.linspace(-1.0, 1.0, width)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    y = tf.linspace(-1.0, 1.0, height)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    x_t, y_t = tf.meshgrid(x, y)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # flatten123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    x_t_flat = tf.reshape(x_t, [-1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    y_t_flat = tf.reshape(y_t, [-1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # reshape to (x_t, y_t , 1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ones = tf.ones_like(x_t_flat)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    sampling_grid = tf.stack([x_t_flat, y_t_flat, ones])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # repeat grid num_batch times123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    sampling_grid = tf.expand_dims(sampling_grid, axis=0)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    sampling_grid = tf.tile(sampling_grid, tf.stack([num_batch, 1, 1]))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # cast to float32 (required for matmul)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    theta = tf.cast(theta, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    sampling_grid = tf.cast(sampling_grid, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # transform the sampling grid - batch multiply123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    batch_grids = tf.matmul(theta, sampling_grid)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # batch grid has shape (num_batch, 2, H*W)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # reshape to (num_batch, H, W, 2)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    batch_grids = tf.reshape(batch_grids, [num_batch, 2, height, width])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # batch_grids = tf.transpose(batch_grids, [0, 2, 1, 3])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return batch_grids123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef bilinear_sampler(img, x, y):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Performs bilinear sampling of the input images according to the123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    normalized coordinates provided by the sampling grid. Note that123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    the sampling is done identically for each channel of the input.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    To test if the function works properly, output image should be123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    identical to input image when theta is initialized to identity123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    transform.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Input123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    -----123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    - img: batch of images in (B, H, W, C) layout.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    - grid: x, y which is the output of affine_grid_generator.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Returns123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    -------123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    - interpolated images according to grids. Same size as grid.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # prepare useful params123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    B = tf.shape(img)[0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    H = tf.shape(img)[1]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    W = tf.shape(img)[2]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    C = tf.shape(img)[3]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    max_y = tf.cast(H - 1, 'int32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    max_x = tf.cast(W - 1, 'int32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    zero = tf.zeros([], dtype='int32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # cast indices as float32 (for rescaling)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    x = tf.cast(x, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    y = tf.cast(y, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # rescale x and y to [0, W/H]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    x = 0.5 * ((x + 1.0) * tf.cast(W, 'float32'))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    y = 0.5 * ((y + 1.0) * tf.cast(H, 'float32'))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # grab 4 nearest corner points for each (x_i, y_i)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # i.e. we need a rectangle around the point of interest123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    x0 = tf.cast(tf.floor(x), 'int32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    x1 = x0 + 1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    y0 = tf.cast(tf.floor(y), 'int32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    y1 = y0 + 1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # clip to range [0, H/W] to not violate img boundaries123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    x0 = tf.clip_by_value(x0, zero, max_x)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    x1 = tf.clip_by_value(x1, zero, max_x)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    y0 = tf.clip_by_value(y0, zero, max_y)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    y1 = tf.clip_by_value(y1, zero, max_y)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # get pixel value at corner coords123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Ia = get_pixel_value(img, x0, y0)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Ib = get_pixel_value(img, x0, y1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Ic = get_pixel_value(img, x1, y0)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Id = get_pixel_value(img, x1, y1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # recast as float for delta calculation123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    x0 = tf.cast(x0, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    x1 = tf.cast(x1, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    y0 = tf.cast(y0, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    y1 = tf.cast(y1, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # calculate deltas123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    wa = (x1 - x) * (y1 - y)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    wb = (x1 - x) * (y - y0)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    wc = (x - x0) * (y1 - y)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    wd = (x - x0) * (y - y0)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # add dimension for addition123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    wa = tf.expand_dims(wa, axis=3)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    wb = tf.expand_dims(wb, axis=3)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    wc = tf.expand_dims(wc, axis=3)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    wd = tf.expand_dims(wd, axis=3)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # compute output123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    out = tf.add_n([wa * Ia, wb * Ib, wc * Ic, wd * Id])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return out123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef init_weights(name, shape):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Handy helper function for initializing the weights of a layer.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Performs He. et al. initilization as described in [1].123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    References123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ----------123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    [1] - https://arxiv.org/abs/1502.01852123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    init = tf.contrib.layers.variance_scaling_initializer()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    W = tf.get_variable(name, shape, tf.float32, init)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return W123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef init_bias(name, shape, trans=False):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Handy helper function for initializing the biases of a layer.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Performs zero bias initialization.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    init = tf.zeros_initializer123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    b = tf.get_variable(name, shape, tf.float32, init)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    if trans:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        x = np.array([[1., 0, 0], [0, 1., 0]])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        x = x.astype('float32').flatten()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        b = tf.Variable(initial_value=x)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return b123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef Conv2D(input_tensor, input_shape, filter_size, num_filters, strides=1, name=None):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Handy helper function for convnets.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Performs 2D convolution with a default stride of 1. The kernel has shape123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    filter_size x filter_size with num_filters output filters.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    shape = [filter_size, filter_size, input_shape, num_filters]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # initialize weights and biases of the convolution123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    W = init_weights(name=name + '_W', shape=shape)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    b = init_bias(name=name + '_b', shape=shape[-1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    conv = tf.nn.conv2d(input_tensor, W, strides=[1, strides, strides, 1], padding='SAME', name=name)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    conv = tf.nn.bias_add(conv, b)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return conv123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef MaxPooling2D(input_tensor, k=2, use_relu=False, name=None):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Handy wrapper function for convolutional networks.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Performs 2D max pool with a default stride of 2.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    pool = tf.nn.max_pool(input_tensor, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME', name=name)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    if use_relu:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        pool = tf.nn.relu(pool)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return pool123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef BatchNormalization(input_tensor, phase, use_relu=False, name=None):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Handy wrapper function for convolutional networks.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Performs batch normalization on the input tensor.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    normed = tf.contrib.layers.batch_norm(input_tensor, center=True, scale=True, is_training=phase, scope=name)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    if use_relu:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        normed = tf.nn.relu(normed)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return normed123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef Flatten(layer):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Handy function for flattening the result of a conv2D or123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    maxpool2D to be used for a fully-connected (affine) layer.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    layer_shape = layer.get_shape()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # num_features = tf.reduce_prod(tf.shape(layer)[1:])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    num_features = layer_shape[1:].num_elements()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    layer_flat = tf.reshape(layer, [-1, num_features])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return layer_flat, num_features123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef Dense(input_tensor, num_inputs, num_outputs, use_relu=True, trans=False, name=None):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Handy wrapper function for convolutional networks.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Performs an affine layer (fully-connected) on the input tensor.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    shape = [num_inputs, num_outputs]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # initialize weights and biases of the affine layer123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    W = init_weights(name=name + '_W', shape=shape)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    b = init_bias(name=name + '_b', shape=shape[-1], trans=trans)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    fc = tf.matmul(input_tensor, W, name=name) + b123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    if use_relu:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        fc = tf.nn.relu(fc)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return fc123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef theta_bias(name):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.variable_scope(name):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        x = np.array([[1., 0, 0], [0, 1., 0]])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        x = x.astype('float32').flatten()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return tf.Variable(initial_value=x)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef loss(logits, labels):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """Calculates the cross-entropy loss.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Args:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      logits: Logits from inference().123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      labels: Labels from inputs(). 1-D tensor123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF              of shape [batch_size]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Returns:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      Loss tensor of type float.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # Calculate the average cross entropy loss across the batch.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    labels = tf.cast(labels, tf.int64)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        labels=labels, logits=logits, name='cross_entropy_per_example')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    cross_entropy_mean = tf.reduce_mean(cross_entropy, name='cross_entropy')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    tf.add_to_collection('losses', cross_entropy_mean)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # The total loss is defined as the cross entropy loss plus all of the weight123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # decay terms (L2 loss).123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # return tf.add_n(tf.get_collection('losses'), name='total_loss')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return cross_entropy_mean + 6 - 6123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef _add_loss_summaries(total_loss):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """Add summaries for losses in CIFAR-10 model.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Generates moving average for all losses and associated summaries for123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    visualizing the performance of the network.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Args:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      total_loss: Total loss from loss().123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Returns:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      loss_averages_op: op for generating moving averages of losses.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # Compute the moving average of all individual losses and the total loss.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    loss_averages = tf.train.ExponentialMovingAverage(0.9, name='avg')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    losses = tf.get_collection('losses')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    loss_averages_op = loss_averages.apply(losses + [total_loss])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # Attach a scalar summary to all individual losses and the total loss; do the123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # same for the averaged version of the losses.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    for l in losses + [total_loss]:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # Name each loss as '(raw)' and name the moving average version of the loss123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # as the original loss name.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        tf.summary.scalar(l.op.name + ' (raw)', l)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        tf.summary.scalar(l.op.name, loss_averages.average(l))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return loss_averages_op123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef _activation_summary(x):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """Helper to create summaries for activations.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Creates a summary that provides a histogram of activations.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Creates a summary that measures the sparsity of activations.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Args:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      x: Tensor123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Returns:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      nothing123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    author: The TensorFlow Authors123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # Remove 'tower_[0-9]/' from the name in case this is a multi-GPU training123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # session. This helps the clarity of presentation on tensorboard.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    tensor_name = re.sub('%s_[0-9]*/' % TOWER_NAME, '', x.op.name)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    tf.summary.histogram(tensor_name + '/activations', x)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    tf.summary.scalar(tensor_name + '/sparsity',123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                      tf.nn.zero_fraction(x))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef _variable_on_cpu(name, shape, initializer):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """Helper to create a Variable stored on CPU memory.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Args:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      name: name of the variable123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      shape: list of ints123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      initializer: initializer for Variable123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Returns:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      Variable Tensor123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.device('/cpu:0'):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        dtype = tf.float16 if FLAGS.USE_FP16 else tf.float32123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        var = tf.get_variable(name, shape, initializer=initializer, dtype=dtype)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return var123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef _variable_with_weight_decay(name, shape, stddev, wd):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """Helper to create an initialized Variable with weight decay.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Note that the Variable is initialized with a truncated normal distribution.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    A weight decay is added only if one is specified.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Args:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      name: name of the variable123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      shape: list of ints123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      stddev: standard deviation of a truncated Gaussian123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      wd: add L2Loss weight decay multiplied by this float. If None, weight123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF          decay is not added for this Variable.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Returns:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      Variable Tensor123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    dtype = tf.float16 if FLAGS.USE_FP16 else tf.float32123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    var = _variable_on_cpu(123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        name,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        shape,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        tf.truncated_normal_initializer(stddev=stddev, dtype=dtype))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    if wd is not None:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        weight_decay = tf.multiply(tf.nn.l2_loss(var), wd, name='weight_loss')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        tf.add_to_collection('losses', weight_decay)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return var123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef conv2d(x, n_filters,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF           k_h=5, k_w=5,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF           stride_h=2, stride_w=2,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF           stddev=0.02,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF           activation=lambda x: x,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF           bias=True,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF           padding='SAME',123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF           name="Conv2D"):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """2D Convolution with options for kernel size, stride, and init deviation.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Parameters123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ----------123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    x : Tensor123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Input tensor to convolve.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    n_filters : int123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Number of filters to apply.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    k_h : int, optional123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Kernel height.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    k_w : int, optional123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Kernel width.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    stride_h : int, optional123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Stride in rows.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    stride_w : int, optional123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Stride in cols.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    stddev : float, optional123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Initialization's standard deviation.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    activation : arguments, optional123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Function which applies a nonlinearity123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    padding : str, optional123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        'SAME' or 'VALID'123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    name : str, optional123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Variable scope to use.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Returns123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    -------123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    x : Tensor123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Convolved input.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.variable_scope(name):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        w = tf.get_variable(123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            'w', [k_h, k_w, x.get_shape()[-1], n_filters],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            initializer=tf.truncated_normal_initializer(stddev=stddev))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        conv = tf.nn.conv2d(123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x, w, strides=[1, stride_h, stride_w, 1], padding=padding)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        if bias:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            b = tf.get_variable(123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                'b', [n_filters],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                initializer=tf.truncated_normal_initializer(stddev=stddev))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            conv = conv + b123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        return conv123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef linear(x, n_units, scope=None, stddev=0.02,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF           activation=lambda x: x):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """Fully-connected network.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Parameters123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ----------123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    x : Tensor123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Input tensor to the network.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    n_units : int123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Number of units to connect to.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    scope : str, optional123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Variable scope to use.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    stddev : float, optional123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Initialization's standard deviation.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    activation : arguments, optional123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Function which applies a nonlinearity123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Returns123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    -------123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    x : Tensor123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Fully-connected output.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    shape = x.get_shape().as_list()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.variable_scope(scope or "Linear"):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        matrix = tf.get_variable("Matrix", [shape[1], n_units], tf.float32,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                 tf.random_normal_initializer(stddev=stddev))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        return activation(tf.matmul(x, matrix))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# %%123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef weight_variable(shape):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    '''Helper function to create a weight variable initialized with123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    a normal distribution123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Parameters123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ----------123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    shape : list123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Size of weight variable123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    '''123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # initial = tf.random_normal(shape, mean=0.0, stddev=0.01)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    initial = tf.zeros(shape)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return tf.Variable(initial)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# %%123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef bias_variable(shape):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    '''Helper function to create a bias variable initialized with123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    a constant value.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Parameters123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ----------123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    shape : list123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Size of weight variable123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    '''123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    initial = tf.random_normal(shape, mean=0.0, stddev=0.01)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return tf.Variable(initial)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# %%123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef dense_to_one_hot(labels, n_classes=2):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """Convert class labels from scalars to one-hot vectors."""123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    labels = np.array(labels)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    n_labels = labels.shape[0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    index_offset = np.arange(n_labels) * n_classes123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    labels_one_hot = np.zeros((n_labels, n_classes), dtype=np.float32)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    labels_one_hot.flat[index_offset + labels.ravel()] = 1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return labels_one_hot123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef transformer(U, theta, out_size, name='SpatialTransformer', **kwargs):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """Spatial Transformer Layer123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Implements a spatial transformer layer as described in [1]_.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Based on [2]_ and edited by David Dao for Tensorflow.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Parameters123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ----------123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    U : float123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        The output of a convolutional net should have the123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        shape [num_batch, height, width, num_channels].123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    theta: float123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        The output of the123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        localisation network should be [num_batch, 6].123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    out_size: tuple of two ints123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        The size of the output of the network (height, width)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    References123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ----------123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    .. [1]  Spatial Transformer Networks123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            Max Jaderberg, Karen Simonyan, Andrew Zisserman, Koray Kavukcuoglu123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            Submitted on 5 Jun 2015123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    .. [2]  https://github.com/skaae/transformer_network/blob/master/transformerlayer.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Notes123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    -----123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    To initialize the network to the identity transform init123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ``theta`` to :123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        identity = np.array([[1., 0., 0.],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                             [0., 1., 0.]])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        identity = identity.flatten()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        theta = tf.Variable(initial_value=identity)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    def _repeat(x, n_repeats):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        with tf.variable_scope('_repeat'):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            rep = tf.transpose(123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                tf.expand_dims(tf.ones(shape=tf.stack([n_repeats, ])), 1), [1, 0])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            rep = tf.cast(rep, 'int32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x = tf.matmul(tf.reshape(x, (-1, 1)), rep)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            return tf.reshape(x, [-1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    def _interpolate(im, x, y, out_size):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        with tf.variable_scope('_interpolate'):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            # constants123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            num_batch = tf.shape(im)[0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            height = tf.shape(im)[1]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            width = tf.shape(im)[2]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            channels = tf.shape(im)[3]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x = tf.cast(x, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y = tf.cast(y, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            height_f = tf.cast(height, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            width_f = tf.cast(width, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            out_height = out_size[0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            out_width = out_size[1]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            zero = tf.zeros([], dtype='int32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            max_y = tf.cast(tf.shape(im)[1] - 1, 'int32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            max_x = tf.cast(tf.shape(im)[2] - 1, 'int32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            # scale indices from [-1, 1] to [0, width/height]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x = (x + 1.0) * (width_f) / 2.0123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y = (y + 1.0) * (height_f) / 2.0123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            # do sampling123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x0 = tf.cast(tf.floor(x), 'int32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x1 = x0 + 1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y0 = tf.cast(tf.floor(y), 'int32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y1 = y0 + 1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x0 = tf.clip_by_value(x0, zero, max_x)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x1 = tf.clip_by_value(x1, zero, max_x)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y0 = tf.clip_by_value(y0, zero, max_y)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y1 = tf.clip_by_value(y1, zero, max_y)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            dim2 = width123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            dim1 = width * height123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            base = _repeat(tf.range(num_batch) * dim1, out_height * out_width)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            base_y0 = base + y0 * dim2123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            base_y1 = base + y1 * dim2123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            idx_a = base_y0 + x0123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            idx_b = base_y1 + x0123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            idx_c = base_y0 + x1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            idx_d = base_y1 + x1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            # use indices to lookup pixels in the flat image and restore123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            # channels dim123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            im_flat = tf.reshape(im, tf.stack([-1, channels]))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            im_flat = tf.cast(im_flat, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            Ia = tf.gather(im_flat, idx_a)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            Ib = tf.gather(im_flat, idx_b)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            Ic = tf.gather(im_flat, idx_c)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            Id = tf.gather(im_flat, idx_d)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            # and finally calculate interpolated values123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x0_f = tf.cast(x0, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x1_f = tf.cast(x1, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y0_f = tf.cast(y0, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y1_f = tf.cast(y1, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            wa = tf.expand_dims(((x1_f - x) * (y1_f - y)), 1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            wb = tf.expand_dims(((x1_f - x) * (y - y0_f)), 1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            wc = tf.expand_dims(((x - x0_f) * (y1_f - y)), 1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            wd = tf.expand_dims(((x - x0_f) * (y - y0_f)), 1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            output = tf.add_n([wa * Ia, wb * Ib, wc * Ic, wd * Id])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            return output123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    def _meshgrid(height, width):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        with tf.variable_scope('_meshgrid'):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            # This should be equivalent to:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            #  x_t, y_t = np.meshgrid(np.linspace(-1, 1, width),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            #                         np.linspace(-1, 1, height))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            #  ones = np.ones(np.prod(x_t.shape))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            #  grid = np.vstack([x_t.flatten(), y_t.flatten(), ones])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x_t = tf.matmul(tf.ones(shape=tf.stack([height, 1])),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                            tf.transpose(tf.expand_dims(tf.linspace(-1.0, 1.0, width), 1), [1, 0]))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y_t = tf.matmul(tf.expand_dims(tf.linspace(-1.0, 1.0, height), 1),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                            tf.ones(shape=tf.stack([1, width])))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x_t_flat = tf.reshape(x_t, (1, -1))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y_t_flat = tf.reshape(y_t, (1, -1))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            ones = tf.ones_like(x_t_flat)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            grid = tf.concat(axis=0, values=[x_t_flat, y_t_flat, ones])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            return grid123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    def _transform(theta, input_dim, out_size):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        with tf.variable_scope('_transform'):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            num_batch = tf.shape(input_dim)[0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            height = tf.shape(input_dim)[1]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            width = tf.shape(input_dim)[2]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            num_channels = tf.shape(input_dim)[3]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            theta = tf.reshape(theta, (-1, 2, 3))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            theta = tf.cast(theta, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            # grid of (x_t, y_t, 1), eq (1) in ref [1]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            height_f = tf.cast(height, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            width_f = tf.cast(width, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            out_height = out_size[0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            out_width = out_size[1]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            grid = _meshgrid(out_height, out_width)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            grid = tf.expand_dims(grid, 0)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            grid = tf.reshape(grid, [-1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            grid = tf.tile(grid, tf.stack([num_batch]))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            grid = tf.reshape(grid, tf.stack([num_batch, 3, -1]))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            # Transform A x (x_t, y_t, 1)^T -> (x_s, y_s)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            T_g = tf.matmul(theta, grid)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x_s = tf.slice(T_g, [0, 0, 0], [-1, 1, -1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y_s = tf.slice(T_g, [0, 1, 0], [-1, 1, -1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x_s_flat = tf.reshape(x_s, [-1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y_s_flat = tf.reshape(y_s, [-1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            input_transformed = _interpolate(123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                input_dim, x_s_flat, y_s_flat,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                out_size)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            output = tf.reshape(123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                input_transformed, tf.stack([num_batch, out_height, out_width, num_channels]))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            return output123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.variable_scope(name):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        output = _transform(theta, U, out_size)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        return output123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef batch_transformer(U, thetas, out_size, name='BatchSpatialTransformer'):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """Batch Spatial Transformer Layer123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Parameters123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ----------123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    U : float123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        tensor of inputs [num_batch,height,width,num_channels]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    thetas : float123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        a set of transformations for each input [num_batch,num_transforms,6]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    out_size : int123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        the size of the output [out_height,out_width]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Returns: float123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Tensor of size [num_batch*num_transforms,out_height,out_width,num_channels]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.variable_scope(name):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        num_batch, num_transforms = map(int, thetas.get_shape().as_list()[:2])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        indices = [[i] * num_transforms for i in xrange(num_batch)]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        input_repeated = tf.gather(U, tf.reshape(indices, [-1]))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return transformer(input_repeated, thetas, out_size)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF