"""123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFst5.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFThis file contains the graph structure for simpletrain5.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF"""123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport os123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport re123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport tensorflow as tf123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport numpy as np123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport js_input123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFfrom constants import FLAGS123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# Global constants describing the MSHAPES data set.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFIMAGE_SIZE = FLAGS.IMAGE_SIZE123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFDIM = IMAGE_SIZE123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFNUM_CLASSES = FLAGS.NUM_CLASSES123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFNUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = FLAGS.NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFNUM_EXAMPLES_PER_EPOCH_FOR_EVAL = FLAGS.NUM_EXAMPLES_PER_EPOCH_FOR_EVAL123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFTOWER_NAME = FLAGS.TOWER_NAME123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef inputs(eval_data):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """Construct input for MSHAPES evaluation using the Reader ops.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Args:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      eval_data: bool, indicating if one should use the train or eval data set.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Returns:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      labels: Labels. 1D tensor of [batch_size] size.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Raises:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      ValueError: If no data_dir123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    if not FLAGS.DATA_DIR:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        raise ValueError('Please supply a data_dir')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    data_dir = os.path.join(FLAGS.DATA_DIR, '')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    (filequeue, (images, labels)) = js_input.inputs(eval_data=eval_data,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                                    data_dir=data_dir,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                                    batch_size=FLAGS.BATCH_SIZE)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # print("Reenqueues: ")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # print(reenqueues)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    if FLAGS.USE_FP16:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        images = tf.cast(images, tf.float16)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        labels = tf.cast(labels, tf.float16)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return filequeue, images, labels123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef train(total_loss):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """Trains the JSPAMES model.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Uses an AdamOptimizer to minimize the loss.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Args:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      total_loss: Total loss from loss().123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Returns:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      train_op: op for training.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    train_op = tf.train.AdamOptimizer(FLAGS.LEARNING_RATE).minimize(total_loss)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return train_op123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# def inference_pretrained(images):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#     this could also be the output a different Keras model or layer123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#     input_tensor = Input(shape=(150, 150, 3))  # this assumes K.image_data_format() == 'channels_last'123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#     model = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=True)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#     return model123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef combined_stm_net(images):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print(images.get_shape())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # Set up an LTM after six fully-connected layers123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    out_size = tf.convert_to_tensor([IMAGE_SIZE, IMAGE_SIZE])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    n_fc = 6123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    W_fc1 = tf.Variable(tf.zeros([1200 * 1600 * 3, n_fc]), name='W_fc1')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    initial = np.array([[0.5, 0, 0], [0, 0.5, 0]])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    initial = initial.astype('float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    initial = initial.flatten()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    b_fc1 = tf.Variable(initial_value=initial, name='b_fc1')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    h_fc1 = tf.matmul(tf.zeros([FLAGS.BATCH_SIZE, 1200 * 1600 * 3]), W_fc1) + b_fc1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # Now, we train two specialized transformers on the data.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # What the specialized transformers do, is they see123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # the entire combined image (specifically, of size123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # [BATCH_SIZE, 100, 100, 2]). However, the transform123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # they learn is only applied to one of the two123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # size [BATCH_SIZE, 100, 100, 1] layers--that is,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # either just the lock images batch, or just the123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # key images batch.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # We have two specialized transformer to123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # accommodate both the lock images and the123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # key images.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    transformed_key_images = specialized_transformer(images, h_fc1, out_size, level_to_transform=1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    transformed_key_images = tf.reshape(transformed_key_images, [FLAGS.BATCH_SIZE, DIM, DIM, 1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    transformed_lock_images = specialized_transformer(images, h_fc1, out_size, level_to_transform=0)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    transformed_lock_images = tf.reshape(transformed_lock_images, [FLAGS.BATCH_SIZE, DIM, DIM, 1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print("Transformed key images shape:"),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print(transformed_key_images.get_shape())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print("Transformed lock images shape:"),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print(transformed_lock_images.get_shape())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # Now, we combine the transformed lock image batch123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # and the transformed key image batch to form123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # one combined image of shape123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # [BATCH_SIZE, 100, 100, 2] (the same shape123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # as the original input image batch).123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    combined_transformed_images = tf.stack([transformed_lock_images, transformed_key_images], axis=3)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    combined_transformed_images = tf.squeeze(combined_transformed_images)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print("Combined transformed images shape:"),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print(combined_transformed_images.get_shape())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # Now, we can run a normal convolutional neural123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # network on the images, since what we output123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # is the same exact shape as the input,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # except with two spatial transform modules123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # now inside of it.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return inference(combined_transformed_images)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef inference(images):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """Build the JSHAPES model.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Args:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      images: Images returned from distorted_inputs() or inputs().123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Returns:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      Logits.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # We instantiate all variables using tf.get_variable() instead of123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # tf.Variable() in order to share variables across multiple GPU training runs.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # If we only ran this model on a single GPU, we could simplify this function123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # by replacing all instances of tf.get_variable() with tf.Variable().123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # conv1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.variable_scope('conv1') as scope:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        kernel = _variable_with_weight_decay('weights',123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                             shape=[5, 5, 2, 64],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                             stddev=5e-3,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                             wd=0.0)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        conv = tf.nn.conv2d(images, kernel, [1, 1, 1, 1], padding='SAME')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        biases = _variable_on_cpu('biases', [64], tf.constant_initializer(1e-2))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        pre_activation = tf.nn.bias_add(conv, biases)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        conv1 = tf.nn.relu(pre_activation, name=scope.name)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        _activation_summary(conv1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # pool1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    pool1 = tf.nn.max_pool(conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                           padding='SAME', name='pool1')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # norm1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    norm1 = tf.nn.lrn(pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                      name='norm1')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # conv2123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.variable_scope('conv2') as scope:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        kernel = _variable_with_weight_decay('weights',123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                             shape=[5, 5, 64, 64],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                             stddev=5e-2,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                             wd=0.0)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        conv = tf.nn.conv2d(norm1, kernel, [1, 1, 1, 1], padding='SAME')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.1))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        pre_activation = tf.nn.bias_add(conv, biases)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        conv2 = tf.nn.relu(pre_activation, name=scope.name)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        _activation_summary(conv2)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # norm2123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    norm2 = tf.nn.lrn(conv2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                      name='norm2')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # pool2123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    pool2 = tf.nn.max_pool(norm2, ksize=[1, 3, 3, 1],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                           strides=[1, 2, 2, 1], padding='SAME', name='pool2')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # local3123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.variable_scope('local3') as scope:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # Move everything into depth so we can perform a single matrix multiply.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        reshape = tf.reshape(pool2, [FLAGS.BATCH_SIZE, -1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        dim = reshape.get_shape()[1].value123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        weights = _variable_with_weight_decay('weights', shape=[dim, 384],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                              stddev=0.04, wd=0.004)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        biases = _variable_on_cpu('biases', [384], tf.constant_initializer(0.1))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        local3 = tf.nn.relu(tf.matmul(reshape, weights) + biases, name=scope.name)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        _activation_summary(local3)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # local4123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.variable_scope('local4') as scope:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        weights = _variable_with_weight_decay('weights', shape=[384, 192],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                              stddev=0.04, wd=0.004)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        biases = _variable_on_cpu('biases', [192], tf.constant_initializer(0.1))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        local4 = tf.nn.relu(tf.matmul(local3, weights) + biases, name=scope.name)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        _activation_summary(local4)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # linear layer(WX + b),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # We don't apply softmax here because123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # tf.nn.sparse_softmax_cross_entropy_with_logits accepts the unscaled logits123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # and performs the softmax internally for efficiency.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.variable_scope('softmax_linear') as scope:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        weights = _variable_with_weight_decay('weights', [192, NUM_CLASSES],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                              stddev=1 / 192.0, wd=0.0)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        biases = _variable_on_cpu('biases', [NUM_CLASSES],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                  tf.constant_initializer(0.0))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        softmax_linear = tf.add(tf.matmul(local4, weights), biases, name=scope.name)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        _activation_summary(softmax_linear)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return softmax_linear123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef inference_with_stm(images):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    locks, keys = tf.split(images, 2, axis=3)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print(locks.get_shape()),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print("-->"),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print(keys.get_shape()),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print("-->"),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    lock_network = inference_with_stm_half(locks, which="locks")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    key_network = inference_with_stm_half(keys, which="keys")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print("-->"),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print(lock_network.get_shape()),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print("-->"),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print(key_network.get_shape()),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # combined_network = tf.scan(lambda a, (x, y): tf.matmul(tf.expand_dims(x, axis=1), tf.expand_dims(y, axis=1), transpose_a=True), (lock_network, key_network))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    locks = tf.reshape(lock_network, [FLAGS.BATCH_SIZE, 192, 1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print("-->"),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print(locks.get_shape()),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    keys = tf.reshape(key_network, [FLAGS.BATCH_SIZE, 1, 192])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print("-->"),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print(keys.get_shape()),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    h = tf.matmul(locks, keys)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print("-->"),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print(h.get_shape()),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    h = tf.reshape(h, [-1, 192 * 192])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print("-->"),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print(h.get_shape()),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print("-->"),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print(h.get_shape())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.variable_scope('softmax_linear') as scope:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        weights = _variable_with_weight_decay('weights', [192 * 192, NUM_CLASSES],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                              stddev=1 / (192.0 * 192.0), wd=0.0)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        biases = _variable_on_cpu('biases', [NUM_CLASSES],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                  tf.constant_initializer(0.0))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        softmax_linear = tf.add(tf.matmul(h, weights), biases, name=scope.name)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        _activation_summary(softmax_linear)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return softmax_linear123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef inference_with_stm_half(images, which="locks"):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    The JSHAPES model with an stn layer at the beginning.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    However, it is applied to both the locks and the keys at the same time,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    so it is not effective.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Args:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      images: Images returned from distorted_inputs() or inputs().123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Returns:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      Logits.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # We instantiate all variables using tf.get_variable() instead of123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # tf.Variable() in order to share variables across multiple GPU training runs.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # If we only ran this model on a single GPU, we could simplify this function123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # by replacing all instances of tf.get_variable() with tf.Variable().123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print(images.get_shape()),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # stm123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    out_size = tf.convert_to_tensor([IMAGE_SIZE, IMAGE_SIZE])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    n_fc = 6123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    W_fc1 = tf.Variable(tf.zeros([1200 * 1600 * 3, n_fc]), name='W_fc1' + which)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    initial = np.array([[0.5, 0, 0], [0, 0.5, 0]])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    initial = initial.astype('float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    initial = initial.flatten()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    b_fc1 = tf.Variable(initial_value=initial, name='b_fc1' + which)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    h_fc1 = tf.matmul(tf.zeros([FLAGS.BATCH_SIZE, 1200 * 1600 * 3]), W_fc1) + b_fc1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    images = transformer(images, h_fc1, out_size)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    images = tf.reshape(images, [FLAGS.BATCH_SIZE, 100, 100, 1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print("-->"),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print(images.get_shape()),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # conv1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.variable_scope('conv1' + which) as scope:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        kernel = _variable_with_weight_decay('weights' + which,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                             shape=[5, 5, 1, 64],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                             stddev=5e-3,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                             wd=0.0)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        conv = tf.nn.conv2d(images, kernel, [1, 1, 1, 1], padding='SAME')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        biases = _variable_on_cpu('biases' + which, [64], tf.constant_initializer(1e-2))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        pre_activation = tf.nn.bias_add(conv, biases)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        conv1 = tf.nn.relu(pre_activation, name=scope.name)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        _activation_summary(conv1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print("-->"),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print(conv1.get_shape()),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # pool1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    pool1 = tf.nn.max_pool(conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                           padding='SAME', name='pool1' + which)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print("-->"),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print(pool1.get_shape()),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # norm1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    norm1 = tf.nn.lrn(pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                      name='norm1' + which)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print("-->"),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print(norm1.get_shape()),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # conv2123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.variable_scope('conv2' + which) as scope:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        kernel = _variable_with_weight_decay('weights' + which,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                             shape=[5, 5, 64, 64],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                             stddev=5e-2,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                             wd=0.0)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        conv = tf.nn.conv2d(norm1, kernel, [1, 1, 1, 1], padding='SAME')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        biases = _variable_on_cpu('biases' + which, [64], tf.constant_initializer(0.1))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        pre_activation = tf.nn.bias_add(conv, biases)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        conv2 = tf.nn.relu(pre_activation, name=scope.name)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        _activation_summary(conv2)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print("-->"),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print(conv2.get_shape()),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # norm2123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    norm2 = tf.nn.lrn(conv2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                      name='norm2' + which)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print("-->"),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print(norm2.get_shape()),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # pool2123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    pool2 = tf.nn.max_pool(norm2, ksize=[1, 3, 3, 1],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                           strides=[1, 2, 2, 1], padding='SAME', name='pool2' + which)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print("-->"),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print(pool2.get_shape()),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # local3123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.variable_scope('local3' + which) as scope:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # Move everything into depth so we can perform a single matrix multiply.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        reshape = tf.reshape(pool2, [FLAGS.BATCH_SIZE, -1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        dim = reshape.get_shape()[1].value123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        weights = _variable_with_weight_decay('weights' + which, shape=[dim, 384],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                              stddev=0.04, wd=0.004)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        biases = _variable_on_cpu('biases' + which, [384], tf.constant_initializer(0.1))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        local3 = tf.nn.relu(tf.matmul(reshape, weights) + biases, name=scope.name)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        _activation_summary(local3)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print("-->"),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print(local3.get_shape()),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # local4123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.variable_scope('local4' + which) as scope:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        weights = _variable_with_weight_decay('weights' + which, shape=[384, 192],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                              stddev=0.04, wd=0.004)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        biases = _variable_on_cpu('biases' + which, [192], tf.constant_initializer(0.1))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        local4 = tf.nn.relu(tf.matmul(local3, weights) + biases, name=scope.name)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        _activation_summary(local4)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print("-->"),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print(local4.get_shape())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return local4123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # linear layer(WX + b),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # We don't apply softmax here because123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # tf.nn.sparse_softmax_cross_entropy_with_logits accepts the unscaled logits123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # and performs the softmax internally for efficiency.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # with tf.variable_scope('softmax_linear' + which) as scope:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #     weights = _variable_with_weight_decay('weights' + which, [192, NUM_CLASSES],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #                                           stddev=1 / 192.0, wd=0.0)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #     biases = _variable_on_cpu('biases' + which, [NUM_CLASSES],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #                               tf.constant_initializer(0.0))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #     softmax_linear = tf.add(tf.matmul(local4, weights), biases, name=scope.name)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #     _activation_summary(softmax_linear)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # print("linear shape:")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # print(softmax_linear.get_shape())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # return softmax_linear123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef inference_with_stm_old(images):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    The JSHAPES model with an stn layer at the beginning.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    However, it is applied to both the locks and the keys at the same time,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    so it is not effective.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Args:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      images: Images returned from distorted_inputs() or inputs().123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Returns:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      Logits.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # We instantiate all variables using tf.get_variable() instead of123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # tf.Variable() in order to share variables across multiple GPU training runs.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # If we only ran this model on a single GPU, we could simplify this function123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # by replacing all instances of tf.get_variable() with tf.Variable().123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print("Images shape:")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print(images.get_shape())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # stm123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    out_size = tf.convert_to_tensor([100, 100])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    n_fc = 6123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    W_fc1 = tf.Variable(tf.zeros([1200 * 1600 * 3, n_fc]), name='W_fc1')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    initial = np.array([[0.5, 0, 0], [0, 0.5, 0]])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    initial = initial.astype('float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    initial = initial.flatten()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    b_fc1 = tf.Variable(initial_value=initial, name='b_fc1')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    h_fc1 = tf.matmul(tf.zeros([FLAGS.BATCH_SIZE, 1200 * 1600 * 3]), W_fc1) + b_fc1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    images = transformer(images, h_fc1, out_size)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    images = tf.reshape(images, [FLAGS.BATCH_SIZE, 100, 100, 2])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print("STM'd images shape:")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print(images.get_shape())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # conv1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.variable_scope('conv1') as scope:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        kernel = _variable_with_weight_decay('weights',123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                             shape=[5, 5, 2, 64],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                             stddev=5e-3,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                             wd=0.0)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        conv = tf.nn.conv2d(images, kernel, [1, 1, 1, 1], padding='SAME')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        biases = _variable_on_cpu('biases', [64], tf.constant_initializer(1e-2))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        pre_activation = tf.nn.bias_add(conv, biases)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        conv1 = tf.nn.relu(pre_activation, name=scope.name)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        _activation_summary(conv1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print("conv1 shape:")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print(conv1.get_shape())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # pool1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    pool1 = tf.nn.max_pool(conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                           padding='SAME', name='pool1')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print("pool1 shape:")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print(pool1.get_shape())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # norm1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    norm1 = tf.nn.lrn(pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                      name='norm1')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print("norm1 shape:")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print(norm1.get_shape())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # conv2123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.variable_scope('conv2') as scope:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        kernel = _variable_with_weight_decay('weights',123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                             shape=[5, 5, 64, 64],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                             stddev=5e-2,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                             wd=0.0)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        conv = tf.nn.conv2d(norm1, kernel, [1, 1, 1, 1], padding='SAME')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.1))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        pre_activation = tf.nn.bias_add(conv, biases)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        conv2 = tf.nn.relu(pre_activation, name=scope.name)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        _activation_summary(conv2)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print("conv2 shape:")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print(conv2.get_shape())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # norm2123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    norm2 = tf.nn.lrn(conv2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                      name='norm2')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print("norm2 shape:")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print(norm2.get_shape())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # pool2123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    pool2 = tf.nn.max_pool(norm2, ksize=[1, 3, 3, 1],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                           strides=[1, 2, 2, 1], padding='SAME', name='pool2')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print("pool2 shape:")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print(pool2.get_shape())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # local3123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.variable_scope('local3') as scope:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # Move everything into depth so we can perform a single matrix multiply.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        reshape = tf.reshape(pool2, [FLAGS.BATCH_SIZE, -1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        dim = reshape.get_shape()[1].value123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        weights = _variable_with_weight_decay('weights', shape=[dim, 384],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                              stddev=0.04, wd=0.004)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        biases = _variable_on_cpu('biases', [384], tf.constant_initializer(0.1))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        local3 = tf.nn.relu(tf.matmul(reshape, weights) + biases, name=scope.name)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        _activation_summary(local3)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print("local3 shape:")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print(local3.get_shape())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # local4123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.variable_scope('local4') as scope:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        weights = _variable_with_weight_decay('weights', shape=[384, 192],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                              stddev=0.04, wd=0.004)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        biases = _variable_on_cpu('biases', [192], tf.constant_initializer(0.1))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        local4 = tf.nn.relu(tf.matmul(local3, weights) + biases, name=scope.name)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        _activation_summary(local4)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print("local4 shape:")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print(local4.get_shape())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # linear layer(WX + b),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # We don't apply softmax here because123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # tf.nn.sparse_softmax_cross_entropy_with_logits accepts the unscaled logits123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # and performs the softmax internally for efficiency.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.variable_scope('softmax_linear') as scope:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        weights = _variable_with_weight_decay('weights', [192, NUM_CLASSES],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                              stddev=1 / 192.0, wd=0.0)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        biases = _variable_on_cpu('biases', [NUM_CLASSES],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                  tf.constant_initializer(0.0))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        softmax_linear = tf.add(tf.matmul(local4, weights), biases, name=scope.name)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        _activation_summary(softmax_linear)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print("linear shape:")123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    print(softmax_linear.get_shape())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return softmax_linear123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef transformer(U, theta, out_size, name='SpatialTransformer', **kwargs):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """Spatial Transformer Layer123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Implements a spatial transformer layer as described in [1]_.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Based on [2]_ and edited by David Dao for Tensorflow.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Parameters123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ----------123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    U : float123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        The output of a convolutional net should have the123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        shape [num_batch, height, width, num_channels].123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    theta: float123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        The output of the123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        localisation network should be [num_batch, 6].123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    out_size: tuple of two ints123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        The size of the output of the network (height, width)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    References123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ----------123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    .. [1]  Spatial Transformer Networks123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            Max Jaderberg, Karen Simonyan, Andrew Zisserman, Koray Kavukcuoglu123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            Submitted on 5 Jun 2015123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    .. [2]  https://github.com/skaae/transformer_network/blob/master/transformerlayer.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Notes123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    -----123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    To initialize the network to the identity transform init123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ``theta`` to :123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        identity = np.array([[1., 0., 0.],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                             [0., 1., 0.]])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        identity = identity.flatten()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        theta = tf.Variable(initial_value=identity)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    def _repeat(x, n_repeats):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        with tf.variable_scope('_repeat'):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            rep = tf.transpose(123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                tf.expand_dims(tf.ones(shape=tf.stack([n_repeats, ])), 1), [1, 0])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            rep = tf.cast(rep, 'int32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x = tf.matmul(tf.reshape(x, (-1, 1)), rep)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            return tf.reshape(x, [-1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    def _interpolate(im, x, y, out_size):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        with tf.variable_scope('_interpolate'):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            # constants123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            num_batch = tf.shape(im)[0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            height = tf.shape(im)[1]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            width = tf.shape(im)[2]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            channels = tf.shape(im)[3]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x = tf.cast(x, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y = tf.cast(y, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            height_f = tf.cast(height, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            width_f = tf.cast(width, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            out_height = out_size[0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            out_width = out_size[1]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            zero = tf.zeros([], dtype='int32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            max_y = tf.cast(tf.shape(im)[1] - 1, 'int32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            max_x = tf.cast(tf.shape(im)[2] - 1, 'int32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            # scale indices from [-1, 1] to [0, width/height]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x = (x + 1.0)*(width_f) / 2.0123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y = (y + 1.0)*(height_f) / 2.0123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            # do sampling123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x0 = tf.cast(tf.floor(x), 'int32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x1 = x0 + 1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y0 = tf.cast(tf.floor(y), 'int32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y1 = y0 + 1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x0 = tf.clip_by_value(x0, zero, max_x)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x1 = tf.clip_by_value(x1, zero, max_x)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y0 = tf.clip_by_value(y0, zero, max_y)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y1 = tf.clip_by_value(y1, zero, max_y)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            dim2 = width123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            dim1 = width*height123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            base = _repeat(tf.range(num_batch)*dim1, out_height*out_width)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            base_y0 = base + y0*dim2123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            base_y1 = base + y1*dim2123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            idx_a = base_y0 + x0123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            idx_b = base_y1 + x0123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            idx_c = base_y0 + x1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            idx_d = base_y1 + x1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            # use indices to lookup pixels in the flat image and restore123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            # channels dim123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            im_flat = tf.reshape(im, tf.stack([-1, channels]))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            im_flat = tf.cast(im_flat, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            Ia = tf.gather(im_flat, idx_a)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            Ib = tf.gather(im_flat, idx_b)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            Ic = tf.gather(im_flat, idx_c)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            Id = tf.gather(im_flat, idx_d)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            # and finally calculate interpolated values123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x0_f = tf.cast(x0, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x1_f = tf.cast(x1, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y0_f = tf.cast(y0, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y1_f = tf.cast(y1, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            wa = tf.expand_dims(((x1_f-x) * (y1_f-y)), 1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            wb = tf.expand_dims(((x1_f-x) * (y-y0_f)), 1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            wc = tf.expand_dims(((x-x0_f) * (y1_f-y)), 1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            wd = tf.expand_dims(((x-x0_f) * (y-y0_f)), 1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            output = tf.add_n([wa*Ia, wb*Ib, wc*Ic, wd*Id])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            return output123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    def _meshgrid(height, width):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        with tf.variable_scope('_meshgrid'):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            # This should be equivalent to:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            #  x_t, y_t = np.meshgrid(np.linspace(-1, 1, width),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            #                         np.linspace(-1, 1, height))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            #  ones = np.ones(np.prod(x_t.shape))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            #  grid = np.vstack([x_t.flatten(), y_t.flatten(), ones])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x_t = tf.matmul(tf.ones(shape=tf.stack([height, 1])),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                            tf.transpose(tf.expand_dims(tf.linspace(-1.0, 1.0, width), 1), [1, 0]))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y_t = tf.matmul(tf.expand_dims(tf.linspace(-1.0, 1.0, height), 1),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                            tf.ones(shape=tf.stack([1, width])))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x_t_flat = tf.reshape(x_t, (1, -1))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y_t_flat = tf.reshape(y_t, (1, -1))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            ones = tf.ones_like(x_t_flat)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            grid = tf.concat(axis=0, values=[x_t_flat, y_t_flat, ones])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            return grid123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    def _transform(theta, input_dim, out_size):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        with tf.variable_scope('_transform'):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            num_batch = tf.shape(input_dim)[0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            height = tf.shape(input_dim)[1]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            width = tf.shape(input_dim)[2]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            num_channels = tf.shape(input_dim)[3]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            theta = tf.reshape(theta, (-1, 2, 3))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            theta = tf.cast(theta, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            # grid of (x_t, y_t, 1), eq (1) in ref [1]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            height_f = tf.cast(height, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            width_f = tf.cast(width, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            out_height = out_size[0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            out_width = out_size[1]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            grid = _meshgrid(out_height, out_width)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            grid = tf.expand_dims(grid, 0)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            grid = tf.reshape(grid, [-1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            grid = tf.tile(grid, tf.stack([num_batch]))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            grid = tf.reshape(grid, tf.stack([num_batch, 3, -1]))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            # Transform A x (x_t, y_t, 1)^T -> (x_s, y_s)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            T_g = tf.matmul(theta, grid)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x_s = tf.slice(T_g, [0, 0, 0], [-1, 1, -1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y_s = tf.slice(T_g, [0, 1, 0], [-1, 1, -1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x_s_flat = tf.reshape(x_s, [-1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y_s_flat = tf.reshape(y_s, [-1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            input_transformed = _interpolate(123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                input_dim, x_s_flat, y_s_flat,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                out_size)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            output = tf.reshape(123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                input_transformed, tf.stack([num_batch, out_height, out_width, num_channels]))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            return output123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.variable_scope(name):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        output = _transform(theta, U, out_size)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        return output123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef specialized_transformer(U, theta, out_size, level_to_transform, name='SpatialTransformer', **kwargs):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """Spatial Transformer Layer123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Learns on image pair, but transforms only second image123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Implements a spatial transformer layer as described in [1]_.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Based on [2]_ and edited by David Dao for Tensorflow.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Parameters123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ----------123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    U : float123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        The output of a convolutional net should have the123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        shape [num_batch, height, width, num_channels].123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    theta: float123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        The output of the123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        localisation network should be [num_batch, 6].123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    out_size: tuple of two ints123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        The size of the output of the network (height, width)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    References123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ----------123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    .. [1]  Spatial Transformer Networks123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            Max Jaderberg, Karen Simonyan, Andrew Zisserman, Koray Kavukcuoglu123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            Submitted on 5 Jun 2015123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    .. [2]  https://github.com/skaae/transformer_network/blob/master/transformerlayer.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Notes123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    -----123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    To initialize the network to the identity transform init123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ``theta`` to :123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        identity = np.array([[1., 0., 0.],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                             [0., 1., 0.]])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        identity = identity.flatten()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        theta = tf.Variable(initial_value=identity)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    def _repeat(x, n_repeats):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        with tf.variable_scope('_repeat'):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            rep = tf.transpose(123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                tf.expand_dims(tf.ones(shape=tf.stack([n_repeats, ])), 1), [1, 0])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            rep = tf.cast(rep, 'int32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x = tf.matmul(tf.reshape(x, (-1, 1)), rep)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            return tf.reshape(x, [-1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    def _interpolate(im, x, y, out_size):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        with tf.variable_scope('_interpolate'):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            # constants123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            num_batch = tf.shape(im)[0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            height = tf.shape(im)[1]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            width = tf.shape(im)[2]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            channels = tf.shape(im)[3]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x = tf.cast(x, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y = tf.cast(y, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            height_f = tf.cast(height, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            width_f = tf.cast(width, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            out_height = out_size[0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            out_width = out_size[1]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            zero = tf.zeros([], dtype='int32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            max_y = tf.cast(tf.shape(im)[1] - 1, 'int32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            max_x = tf.cast(tf.shape(im)[2] - 1, 'int32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            # scale indices from [-1, 1] to [0, width/height]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x = (x + 1.0)*(width_f) / 2.0123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y = (y + 1.0)*(height_f) / 2.0123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            # do sampling123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x0 = tf.cast(tf.floor(x), 'int32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x1 = x0 + 1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y0 = tf.cast(tf.floor(y), 'int32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y1 = y0 + 1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x0 = tf.clip_by_value(x0, zero, max_x)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x1 = tf.clip_by_value(x1, zero, max_x)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y0 = tf.clip_by_value(y0, zero, max_y)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y1 = tf.clip_by_value(y1, zero, max_y)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            dim2 = width123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            dim1 = width*height123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            base = _repeat(tf.range(num_batch)*dim1, out_height*out_width)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            base_y0 = base + y0*dim2123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            base_y1 = base + y1*dim2123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            idx_a = base_y0 + x0123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            idx_b = base_y1 + x0123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            idx_c = base_y0 + x1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            idx_d = base_y1 + x1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            # use indices to lookup pixels in the flat image and restore123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            # channels dim123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            im_flat = tf.reshape(im, tf.stack([-1, channels]))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            im_flat = tf.cast(im_flat, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            Ia = tf.gather(im_flat, idx_a)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            Ib = tf.gather(im_flat, idx_b)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            Ic = tf.gather(im_flat, idx_c)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            Id = tf.gather(im_flat, idx_d)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            # and finally calculate interpolated values123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x0_f = tf.cast(x0, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x1_f = tf.cast(x1, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y0_f = tf.cast(y0, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y1_f = tf.cast(y1, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            wa = tf.expand_dims(((x1_f-x) * (y1_f-y)), 1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            wb = tf.expand_dims(((x1_f-x) * (y-y0_f)), 1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            wc = tf.expand_dims(((x-x0_f) * (y1_f-y)), 1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            wd = tf.expand_dims(((x-x0_f) * (y-y0_f)), 1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            output = tf.add_n([wa*Ia, wb*Ib, wc*Ic, wd*Id])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            return output123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    def _meshgrid(height, width):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        with tf.variable_scope('_meshgrid'):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            # This should be equivalent to:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            #  x_t, y_t = np.meshgrid(np.linspace(-1, 1, width),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            #                         np.linspace(-1, 1, height))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            #  ones = np.ones(np.prod(x_t.shape))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            #  grid = np.vstack([x_t.flatten(), y_t.flatten(), ones])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x_t = tf.matmul(tf.ones(shape=tf.stack([height, 1])),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                            tf.transpose(tf.expand_dims(tf.linspace(-1.0, 1.0, width), 1), [1, 0]))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y_t = tf.matmul(tf.expand_dims(tf.linspace(-1.0, 1.0, height), 1),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                            tf.ones(shape=tf.stack([1, width])))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x_t_flat = tf.reshape(x_t, (1, -1))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y_t_flat = tf.reshape(y_t, (1, -1))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            ones = tf.ones_like(x_t_flat)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            grid = tf.concat(axis=0, values=[x_t_flat, y_t_flat, ones])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            return grid123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    def _transform(theta, input_dim, out_size, level):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        with tf.variable_scope('_transform'):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            if (level == 0):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                input_dim, _ = tf.split(input_dim, num_or_size_splits=2, axis=3)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            elif (level == 1):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                _, input_dim = tf.split(input_dim, num_or_size_splits=2, axis=3)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            num_batch = tf.shape(input_dim)[0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            height = tf.shape(input_dim)[1]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            width = tf.shape(input_dim)[2]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            num_channels = tf.shape(input_dim)[3]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            theta = tf.reshape(theta, (-1, 2, 3))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            theta = tf.cast(theta, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            # grid of (x_t, y_t, 1), eq (1) in ref [1]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            height_f = tf.cast(height, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            width_f = tf.cast(width, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            out_height = out_size[0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            out_width = out_size[1]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            grid = _meshgrid(out_height, out_width)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            grid = tf.expand_dims(grid, 0)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            grid = tf.reshape(grid, [-1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            grid = tf.tile(grid, tf.stack([num_batch]))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            grid = tf.reshape(grid, tf.stack([num_batch, 3, -1]))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            # Transform A x (x_t, y_t, 1)^T -> (x_s, y_s)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            T_g = tf.matmul(theta, grid)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x_s = tf.slice(T_g, [0, 0, 0], [-1, 1, -1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y_s = tf.slice(T_g, [0, 1, 0], [-1, 1, -1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x_s_flat = tf.reshape(x_s, [-1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y_s_flat = tf.reshape(y_s, [-1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            input_transformed = _interpolate(123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                input_dim, x_s_flat, y_s_flat,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                out_size)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            output = tf.reshape(123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                input_transformed, tf.stack([num_batch, out_height, out_width, num_channels]))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            return output123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.variable_scope(name):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        output = _transform(theta, U, out_size, level_to_transform)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        return output123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef batch_transformer(U, thetas, out_size, name='BatchSpatialTransformer'):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """Batch Spatial Transformer Layer123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Parameters123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ----------123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    U : float123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        tensor of inputs [num_batch,height,width,num_channels]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    thetas : float123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        a set of transformations for each input [num_batch,num_transforms,6]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    out_size : int123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        the size of the output [out_height,out_width]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Returns: float123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Tensor of size [num_batch*num_transforms,out_height,out_width,num_channels]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.variable_scope(name):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        num_batch, num_transforms = map(int, thetas.get_shape().as_list()[:2])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        indices = [[i]*num_transforms for i in xrange(num_batch)]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        input_repeated = tf.gather(U, tf.reshape(indices, [-1]))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return transformer(input_repeated, thetas, out_size)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef loss(logits, labels):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """Calculates the cross-entropy loss.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Args:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      logits: Logits from inference().123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      labels: Labels from inputs(). 1-D tensor123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF              of shape [batch_size]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Returns:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      Loss tensor of type float.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # Calculate the average cross entropy loss across the batch.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    labels = tf.cast(labels, tf.int64)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        labels=labels, logits=logits, name='cross_entropy_per_example')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    cross_entropy_mean = tf.reduce_mean(cross_entropy, name='cross_entropy')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    tf.add_to_collection('losses', cross_entropy_mean)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # The total loss is defined as the cross entropy loss plus all of the weight123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # decay terms (L2 loss).123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # return tf.add_n(tf.get_collection('losses'), name='total_loss')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return cross_entropy_mean + 6 - 6123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef _add_loss_summaries(total_loss):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """Add summaries for losses in CIFAR-10 model.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Generates moving average for all losses and associated summaries for123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    visualizing the performance of the network.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Args:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      total_loss: Total loss from loss().123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Returns:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      loss_averages_op: op for generating moving averages of losses.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # Compute the moving average of all individual losses and the total loss.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    loss_averages = tf.train.ExponentialMovingAverage(0.9, name='avg')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    losses = tf.get_collection('losses')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    loss_averages_op = loss_averages.apply(losses + [total_loss])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # Attach a scalar summary to all individual losses and the total loss; do the123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # same for the averaged version of the losses.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    for l in losses + [total_loss]:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # Name each loss as '(raw)' and name the moving average version of the loss123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # as the original loss name.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        tf.summary.scalar(l.op.name + ' (raw)', l)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        tf.summary.scalar(l.op.name, loss_averages.average(l))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return loss_averages_op123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef _activation_summary(x):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """Helper to create summaries for activations.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Creates a summary that provides a histogram of activations.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Creates a summary that measures the sparsity of activations.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Args:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      x: Tensor123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Returns:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      nothing123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    author: The TensorFlow Authors123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # Remove 'tower_[0-9]/' from the name in case this is a multi-GPU training123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # session. This helps the clarity of presentation on tensorboard.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    tensor_name = re.sub('%s_[0-9]*/' % TOWER_NAME, '', x.op.name)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    tf.summary.histogram(tensor_name + '/activations', x)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    tf.summary.scalar(tensor_name + '/sparsity',123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                      tf.nn.zero_fraction(x))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef _variable_on_cpu(name, shape, initializer):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """Helper to create a Variable stored on CPU memory.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Args:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      name: name of the variable123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      shape: list of ints123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      initializer: initializer for Variable123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Returns:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      Variable Tensor123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.device('/cpu:0'):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        dtype = tf.float16 if FLAGS.USE_FP16 else tf.float32123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        var = tf.get_variable(name, shape, initializer=initializer, dtype=dtype)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return var123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef _variable_with_weight_decay(name, shape, stddev, wd):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """Helper to create an initialized Variable with weight decay.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Note that the Variable is initialized with a truncated normal distribution.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    A weight decay is added only if one is specified.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Args:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      name: name of the variable123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      shape: list of ints123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      stddev: standard deviation of a truncated Gaussian123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      wd: add L2Loss weight decay multiplied by this float. If None, weight123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF          decay is not added for this Variable.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Returns:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF      Variable Tensor123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    dtype = tf.float16 if FLAGS.USE_FP16 else tf.float32123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    var = _variable_on_cpu(123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        name,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        shape,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        tf.truncated_normal_initializer(stddev=stddev, dtype=dtype))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    if wd is not None:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        weight_decay = tf.multiply(tf.nn.l2_loss(var), wd, name='weight_loss')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        tf.add_to_collection('losses', weight_decay)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return var123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef conv2d(x, n_filters,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF           k_h=5, k_w=5,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF           stride_h=2, stride_w=2,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF           stddev=0.02,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF           activation=lambda x: x,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF           bias=True,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF           padding='SAME',123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF           name="Conv2D"):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Based on https://github.com/kevinzakka/spatial_transformer_network123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    2D Convolution with options for kernel size, stride, and init deviation.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Parameters123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ----------123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    x : Tensor123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Input tensor to convolve.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    n_filters : int123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Number of filters to apply.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    k_h : int, optional123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Kernel height.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    k_w : int, optional123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Kernel width.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    stride_h : int, optional123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Stride in rows.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    stride_w : int, optional123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Stride in cols.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    stddev : float, optional123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Initialization's standard deviation.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    activation : arguments, optional123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Function which applies a nonlinearity123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    padding : str, optional123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        'SAME' or 'VALID'123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    name : str, optional123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Variable scope to use.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Returns123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    -------123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    x : Tensor123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Convolved input.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.variable_scope(name):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        w = tf.get_variable(123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            'w', [k_h, k_w, x.get_shape()[-1], n_filters],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            initializer=tf.truncated_normal_initializer(stddev=stddev))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        conv = tf.nn.conv2d(123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x, w, strides=[1, stride_h, stride_w, 1], padding=padding)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        if bias:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            b = tf.get_variable(123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                'b', [n_filters],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                initializer=tf.truncated_normal_initializer(stddev=stddev))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            conv = conv + b123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        return conv123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef linear(x, n_units, scope=None, stddev=0.02,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF           activation=lambda x: x):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Based on https://github.com/kevinzakka/spatial_transformer_network123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Fully-connected network.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Parameters123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ----------123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    x : Tensor123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Input tensor to the network.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    n_units : int123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Number of units to connect to.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    scope : str, optional123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Variable scope to use.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    stddev : float, optional123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Initialization's standard deviation.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    activation : arguments, optional123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Function which applies a nonlinearity123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Returns123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    -------123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    x : Tensor123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Fully-connected output.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    shape = x.get_shape().as_list()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.variable_scope(scope or "Linear"):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        matrix = tf.get_variable("Matrix", [shape[1], n_units], tf.float32,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                 tf.random_normal_initializer(stddev=stddev))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        return activation(tf.matmul(x, matrix))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef dense_to_one_hot(labels, n_classes=2):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """Convert class labels from scalars to one-hot vectors."""123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    labels = np.array(labels)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    n_labels = labels.shape[0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    index_offset = np.arange(n_labels) * n_classes123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    labels_one_hot = np.zeros((n_labels, n_classes), dtype=np.float32)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    labels_one_hot.flat[index_offset + labels.ravel()] = 1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return labels_one_hot123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef transformer(U, theta, out_size, name='SpatialTransformer', **kwargs):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Based on https://github.com/kevinzakka/spatial_transformer_network123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Spatial Transformer Layer123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Implements a spatial transformer layer as described in [1]_.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Based on [2]_ and edited by David Dao for Tensorflow.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Parameters123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ----------123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    U : float123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        The output of a convolutional net should have the123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        shape [num_batch, height, width, num_channels].123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    theta: float123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        The output of the123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        localisation network should be [num_batch, 6].123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    out_size: tuple of two ints123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        The size of the output of the network (height, width)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    References123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ----------123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    .. [1]  Spatial Transformer Networks123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            Max Jaderberg, Karen Simonyan, Andrew Zisserman, Koray Kavukcuoglu123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            Submitted on 5 Jun 2015123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    .. [2]  https://github.com/skaae/transformer_network/blob/master/transformerlayer.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Notes123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    -----123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    To initialize the network to the identity transform init123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ``theta`` to :123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        identity = np.array([[1., 0., 0.],123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                             [0., 1., 0.]])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        identity = identity.flatten()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        theta = tf.Variable(initial_value=identity)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    def _repeat(x, n_repeats):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        with tf.variable_scope('_repeat'):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            rep = tf.transpose(123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                tf.expand_dims(tf.ones(shape=tf.stack([n_repeats, ])), 1), [1, 0])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            rep = tf.cast(rep, 'int32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x = tf.matmul(tf.reshape(x, (-1, 1)), rep)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            return tf.reshape(x, [-1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    def _interpolate(im, x, y, out_size):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        with tf.variable_scope('_interpolate'):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            # constants123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            num_batch = tf.shape(im)[0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            height = tf.shape(im)[1]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            width = tf.shape(im)[2]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            channels = tf.shape(im)[3]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x = tf.cast(x, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y = tf.cast(y, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            height_f = tf.cast(height, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            width_f = tf.cast(width, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            out_height = out_size[0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            out_width = out_size[1]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            zero = tf.zeros([], dtype='int32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            max_y = tf.cast(tf.shape(im)[1] - 1, 'int32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            max_x = tf.cast(tf.shape(im)[2] - 1, 'int32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            # scale indices from [-1, 1] to [0, width/height]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x = (x + 1.0) * (width_f) / 2.0123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y = (y + 1.0) * (height_f) / 2.0123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            # do sampling123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x0 = tf.cast(tf.floor(x), 'int32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x1 = x0 + 1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y0 = tf.cast(tf.floor(y), 'int32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y1 = y0 + 1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x0 = tf.clip_by_value(x0, zero, max_x)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x1 = tf.clip_by_value(x1, zero, max_x)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y0 = tf.clip_by_value(y0, zero, max_y)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y1 = tf.clip_by_value(y1, zero, max_y)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            dim2 = width123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            dim1 = width * height123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            base = _repeat(tf.range(num_batch) * dim1, out_height * out_width)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            base_y0 = base + y0 * dim2123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            base_y1 = base + y1 * dim2123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            idx_a = base_y0 + x0123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            idx_b = base_y1 + x0123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            idx_c = base_y0 + x1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            idx_d = base_y1 + x1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            # use indices to lookup pixels in the flat image and restore123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            # channels dim123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            im_flat = tf.reshape(im, tf.stack([-1, channels]))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            im_flat = tf.cast(im_flat, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            Ia = tf.gather(im_flat, idx_a)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            Ib = tf.gather(im_flat, idx_b)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            Ic = tf.gather(im_flat, idx_c)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            Id = tf.gather(im_flat, idx_d)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            # and finally calculate interpolated values123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x0_f = tf.cast(x0, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x1_f = tf.cast(x1, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y0_f = tf.cast(y0, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y1_f = tf.cast(y1, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            wa = tf.expand_dims(((x1_f - x) * (y1_f - y)), 1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            wb = tf.expand_dims(((x1_f - x) * (y - y0_f)), 1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            wc = tf.expand_dims(((x - x0_f) * (y1_f - y)), 1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            wd = tf.expand_dims(((x - x0_f) * (y - y0_f)), 1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            output = tf.add_n([wa * Ia, wb * Ib, wc * Ic, wd * Id])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            return output123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    def _meshgrid(height, width):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        with tf.variable_scope('_meshgrid'):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            # This should be equivalent to:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            #  x_t, y_t = np.meshgrid(np.linspace(-1, 1, width),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            #                         np.linspace(-1, 1, height))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            #  ones = np.ones(np.prod(x_t.shape))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            #  grid = np.vstack([x_t.flatten(), y_t.flatten(), ones])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x_t = tf.matmul(tf.ones(shape=tf.stack([height, 1])),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                            tf.transpose(tf.expand_dims(tf.linspace(-1.0, 1.0, width), 1), [1, 0]))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y_t = tf.matmul(tf.expand_dims(tf.linspace(-1.0, 1.0, height), 1),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                            tf.ones(shape=tf.stack([1, width])))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x_t_flat = tf.reshape(x_t, (1, -1))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y_t_flat = tf.reshape(y_t, (1, -1))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            ones = tf.ones_like(x_t_flat)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            grid = tf.concat(axis=0, values=[x_t_flat, y_t_flat, ones])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            return grid123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    def _transform(theta, input_dim, out_size):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        with tf.variable_scope('_transform'):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            num_batch = tf.shape(input_dim)[0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            height = tf.shape(input_dim)[1]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            width = tf.shape(input_dim)[2]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            num_channels = tf.shape(input_dim)[3]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            theta = tf.reshape(theta, (-1, 2, 3))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            theta = tf.cast(theta, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            # grid of (x_t, y_t, 1), eq (1) in ref [1]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            height_f = tf.cast(height, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            width_f = tf.cast(width, 'float32')123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            out_height = out_size[0]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            out_width = out_size[1]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            grid = _meshgrid(out_height, out_width)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            grid = tf.expand_dims(grid, 0)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            grid = tf.reshape(grid, [-1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            grid = tf.tile(grid, tf.stack([num_batch]))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            grid = tf.reshape(grid, tf.stack([num_batch, 3, -1]))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            # Transform A x (x_t, y_t, 1)^T -> (x_s, y_s)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            T_g = tf.matmul(theta, grid)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x_s = tf.slice(T_g, [0, 0, 0], [-1, 1, -1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y_s = tf.slice(T_g, [0, 1, 0], [-1, 1, -1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            x_s_flat = tf.reshape(x_s, [-1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            y_s_flat = tf.reshape(y_s, [-1])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            input_transformed = _interpolate(123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                input_dim, x_s_flat, y_s_flat,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                out_size)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            output = tf.reshape(123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                input_transformed, tf.stack([num_batch, out_height, out_width, num_channels]))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            return output123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.variable_scope(name):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        output = _transform(theta, U, out_size)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        return output123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef batch_transformer(U, thetas, out_size, name='BatchSpatialTransformer'):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """Batch Spatial Transformer Layer123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Parameters123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ----------123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    U : float123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        tensor of inputs [num_batch,height,width,num_channels]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    thetas : float123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        a set of transformations for each input [num_batch,num_transforms,6]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    out_size : int123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        the size of the output [out_height,out_width]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    Returns: float123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        Tensor of size [num_batch*num_transforms,out_height,out_width,num_channels]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    """123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.variable_scope(name):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        num_batch, num_transforms = map(int, thetas.get_shape().as_list()[:2])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        indices = [[i] * num_transforms for i in xrange(num_batch)]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        input_repeated = tf.gather(U, tf.reshape(indices, [-1]))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    return transformer(input_repeated, thetas, out_size)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF