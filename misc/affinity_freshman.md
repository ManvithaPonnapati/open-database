###Quick Introduction to Affinity  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF_The aim of the resources on this page is to allow anyone, even without specific machine learning background, to quickly get up to speeed with Affinity Core virtual screening engine. The estimated time for completions is under two weeks._123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF####Background Readings123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF_If you are familiar with all of the concepts the list: weights, biases, activation function, ReLU, softmax, convolution, pooling, layers of depth, batch, gradient descent, backpropagation (and chain rule), AdamOptimizer, please feel free to skip to the next section._  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFCS231n "Convolutional Neural Networks for Visual Recognition"  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFhttp://cs231n.github.io/  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFPlease, read through  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFModule 1, Neural Networks      123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFModule 2, Convolutional Neural Networks   123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF####TensorFlow tutorials to complete123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF_If you are familiar with all of the concepts in this list: tensor graph, session, tf.global_variable_initializer, tf.train.coordinator, tf.train.start_queue_runners, tf.nn.sparse_softmax_cross_entropy_with_logits, tf.saver, tf.summary, tf.summary.FileWriter, tf.name_scope, please, feel free to skip to the next section._123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF[MNIST](https://www.tensorflow.org/tutorials/mnist/beginners/)  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF[Deep MNIST](https://www.tensorflow.org/tutorials/mnist/pros/)  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF[Understandig TensorFlow's workflow](https://www.tensorflow.org/tutorials/mnist/tf/)  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF[CIFAR10](https://www.tensorflow.org/tutorials/deep_cnn/)  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF[Deep Generative Adversarial Models](https://github.com/carpedm20/DCGAN-tensorflow)  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF####Introduction to Affinity Core123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF_Structure based virtual screening is an approach that allows to retrieve a very small percent, usually few dozens of molecules, from the large database, of millioons of chemical structures. The process can be imagined as a google search for a flexible key (ligand) with a 3D image of a rigid lock (receptor,protein). Search can be broken into two parts. Since the most optimal relative position of the drug and protein is not known, it has to be estimated (docking). Afterwards, many static protein-ligand complexes have to be ranked by their predicted relative binding affinity (sorting). Usually, 25,000-200,000 pose evaluations are done during docking, and a single pose evaluation is done during ranking. Because Tesla K80 GPU can only evaluate 100-200 images/second, position search for a single ligand may take anywhere between 3 and 35 minutes, docking the average-size database of 1,000,000 of molecules may take 1.2 GPU years. In this example we only apply the network to the previously docked with AutoDock Smina positions, IE: ranking._123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF####Step 1: teaching the network123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFYou will need four scripts, and the database123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFav4_networks.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFav4_main.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFav4_input.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFav4_utils.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFlabeled_av4123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFwhere `labeled_av4` is an already prepared database of the ligands and proteins in av4 binary format.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFav4_networks.py 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# is a library of many different network architectures123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# each of the networks accepts batch of images, and outputs batch of unscaled probabilities (logits)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# crucial part 1: the network itself123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# convolutional layers IE: tf.nn.conv3d123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# pooling layers IE: tf.nn.max_pool3d or tf.nn.avg_pool3d123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# Rectifier Linear Regression Units, or ReLUs IE: tf.nn.relu123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# crucial part 2: rules for variable initialization123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# IE: bias_variable 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# tf.constant(0.01, shape=shape)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# or weight variable123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# tf.truncated_normal(shape, stddev=0.005)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# initial weights and biases for trainable variables are usually initialized with small random positive 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# values. Deep networks can easily run out of control and owerflow the floats in higher layers 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# if not initialized properly.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# That's why it's important to initialize variables very accurately123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# especially deep networks can be hierarchically constructed 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# when the new layer(s) is added to the top of existing trained network123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# crucial part 3: variable summaries123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# IE: tf.summary.histogram, tf.summary.scalar, 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# and tf.name_scope (groups variables together under a common name)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# variable summaries are written in a separate file and help to monitor the state and evolution 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# of the network during training or testing123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFav4_input.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# is script that reads and indexes the database in av4 format, and creates batches of images123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# in 3D that can be fed to the network123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# av4 database consists of thousands of folders - one for each protein123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# each protein can have many ligands123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# each ligand av4 file can have many positions (frames), and every frame has it's label123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# the name of each folder IE 1QGT, 4G93 each correspond to a particular PDB id  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# original PDB file with coordinates can be found at http://www.rcsb.org/123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# crucial part 1: index_the_database_into_queue123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# crawls of all the folders in the database and creates tensor of filenames123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# crucial part 2: read_receptor_and_ligand123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# reads a single example of receptor and ligand from the database123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# returns coordinates and name (label) of every atom (only one frame depending on epoch counter)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# crucial part 3: convert_protein_and_ligand_to_image123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# creates an image (sparse or dense) from input atom coordinates123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# dense image is cubic, has only some atoms of the protein, and describes pixels (not atoms)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# empty spaces in dense image are filled with zeros123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# crucial part 4: tf.train.batch (for three reasons)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# reason 1:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# it runs multiple independent threads of image creation123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# reason 2:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# it batches images together123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# single images are small and tensor operations in them (such as convolution or pooling)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# are not efficient. 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# reason 3:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# gradient descent optimizer gets much better gradient from multiple images. 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# Ideally, every single gradient descent step would be applied to a representative sample 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# of a whole database; this is better achievable with larger batches123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# av4_main.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# is a main script that assembles all of the parts together 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# crucial part 1: FLAGS123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# class that stores many global parameters of the script123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# such as FLAGS.pixels_size - determines the size of the pixel generated by av4_input123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# crucial part 2: train123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# assembles all of the parts together:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 1. input image creation pipeline              IE: ....something = image_and_label_queue 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 2. network that makes predictions             IE: intuit_net or nilai_net123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 3. cost function to minimize                  IE: tf.nn.sparse_softmax_cross_entropy_with_logits123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 4. optimizer(applies gradient descent steps)  IE: tf.train.AdamOptimizer123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 5. run while loop pipe the tensor graph       IE: sess.run(train_step_run)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# graph initialization commands:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 6. initializer of variables from placeholders IE: tf.global_variable_initializer 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 7. fill the graph skeleton with data inputs   IE: tf.train.start_queue_runners123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 8. also has saver of variable states          IE: tf.train.saver123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 9. variable summaries to visualize            IE: tf.summaries.writer123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 10. an epoch counter that counts every read through all proteins in database as one epoch123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFav4_utils.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# stores various utilities to support functions that are not natively present in TensorFlow123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF``` 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFhere is how a typical session on our Amazon graphical instance with K80 GPU would look like:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# log into our remote machine 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# email maksym to get the key123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFssh -i P2_key.pem ubuntu@awsinstance.com123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# every member of the group should have his or her folder123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFcd maksym123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# clone affinity core into your working directory 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFubuntu@ip-172-31-4-5:~/maksym$ git clone https://github.com/mitaffinity/core.git  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFcd core 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFpython av4_main.py  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# point the script to the location of the database123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFvi (or any other command line text file editor; some people like nano) 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# the database has already been donloaded to the instance123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# change the database path under flags to   123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# /home/ubuntu/common/data/labeled_av4  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# does not work; needs latest tensorflow  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# tensorflow12 is hidden in an envoronmental variable 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# source $TF12  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# if you are interested what $TF12 it is:  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFecho $TF12 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF/home/ubuntu/common/venv/tf12/bin/activate  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# start training123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFpython av4_main.py 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# seems to work, now it's time to launch this process for a while123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# the key is to launch it on the background, so it does not die when you log off123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# from your remote host. Use the '&' sign123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFpython av4_main.py &  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# now background process will persist when you exit the session  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# now the nasty problem: TensorFlow tends not to die and hog on the GPU even after it's been terminated123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# also, there are many of us using GPU instance at the same time, but with TF's default settings123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# only one process will capture all VRAM on the GPU 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# see if anything is running on the GPU  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFnvidia-smi  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# should show the running processes, and how much VRAM each of them takes123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# you can also use top to monitor RAM and CPU123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFtop123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# since it's a development instance, it is ok to kill all python processes with123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# be carefull as it kills all the python processes that other people are running 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# it's ok to do it on our instance since it's consired to be only development zone for debugging123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFpkill -9 python123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFThe network training may take hours, or days depending on your dataset and architecture of the network. It's important to note that in our code the epoch is counted by protein-ligand pairs, not by images. Every protein-ligand pair may have multiple incorrect positions of the ligand 50-400, and a single correct, crystal position. In this case, it takes 100 epochs to only show all of the negatives to the network once. That is different from classical understanding of epochs in image recognition when images can't have multiple frames.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFRunning the code should have resulted in four folders with outputs:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF1_logs   123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF1_netstate   123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF1_test   123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF1_train  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF`1_logs` might be empty, and will be used to write outputs during evaluation.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF`1_netstate` will store the saved weights and biases for every trainable variable of the network 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF(and also all other variables, such as epoch counter)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF`1_train` and `1_test` should store summaries for variable states during training and testing that can123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFbe visualized. Let's expect the outputs of in the foders123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# log into our instance123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFssh -i P2_key.pem ubuntu@awsinstance.com123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# now I am123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# ubuntu@ip-172-31-4-5:~$123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# cd maksym123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFcd /core/summaries123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFcd 1_netstate123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFls -l123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# should show all of the files together with their size123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# IE: 96789276 Jan 29 16:55 saved_state-60999.data-00000-of-00001123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFcd ../1_train123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFls123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# should show 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# events.out.tfevents.1485708632.ip-172-31-4-5123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# which is a tensorflow summaries file123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# let's try to visualize it:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# load tensorflow 0.12 (default version in the environment is 0.10)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFsource $TF12123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# it's important to launch the tensorboard on port 80. By default internet browsers, such as chrome,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# will connect to port 80. You can read more here: https://en.wikipedia.org/wiki/Port_(computer_networking)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# by default port 80 is not available to the user (the error is port is busy) that's why we use sudo123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# now you can navigate your browser to awsinstance.com123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF you should be able to see the following:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF![alt_tag](https://github.com/mitaffinity/core/blob/master/misc/cross_entropy.png)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF####Step 2: evaluating the network123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFand in addition you will need these three sripts123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFav4_eval.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFav4_input.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFav4_utils.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFthe only new script is `av4_eval`  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFav4_eval.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# av4_eval script is very similar to av4_main123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# crucial part 1:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# assembles all of the parts together:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 1. input image creation pipeline              IE: ....something = image_and_label_queue 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 2. network that makes predictions             IE: intuit_net or nilai_net123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 3. softmax instead of cost function in main   IE: tf.nn.softmax123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 4. no optimizer, variables are loaded         IE: saver.restore123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 5. run while loop pipe the tensor graph       IE: sess.run(train_step_run)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# crucial part 2: class store_predictions123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# stores, sorts, and saves predictions123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# estimates different evaluation parameters for straightforward binary classification such as 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# Area Under Curve https://en.wikipedia.org/wiki/Receiver_operating_characteristic123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# Confusion Matrix https://en.wikipedia.org/wiki/Confusion_matrix123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# crucial part 3: av4_eval can be used for two different tasks123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 1. distinguishing the correct position within many positions as in docking123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 2. sorting ligands each of which has many positions as in sorting123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 1 is very straightforward since our training consits of correct and incorrect positions, 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# we only need to score all of the available positions123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# our performance on task 1 is very high (AUC > 0.94)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 2 is not straighforward. Since many of the docked positions given to the network are not correct123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# (sometimes all of them)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFthe simplest way would be to rescore all of the docked positions, and retain one123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFwith highest prediction for each ligand for sorting as in AutoDock (and classical biophysics algorithms)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFthe network is noisy, and does not work well that way at the moment.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFour best predictions so far incorporate averaging of predictions for many conformations.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#####Step 3: database preparation (optional)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdata and .av4 format123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFav4_database_master123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFav4_atom_dictionary123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFVisualizing the network  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFsudo python -m tensorflow.tensorboard --logdir=. --port=80  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF`123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFOpen  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFhttp://awsinstance.com/  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFIn your browser to visualize the network. This thing can crawl all the directories  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFHeavy lifting  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFClusters  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF