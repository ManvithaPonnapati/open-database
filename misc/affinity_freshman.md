###Quick Introduction to Affinity  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF_The aim of the resources on this page is to allow anyone, even without specific machine learning background, to quickly get up to speeed with Affinity Core virtual screening engine. The estimated time for completions is under two weeks._123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF####Background Readings123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF_If you are familiar with all of the concepts the list: weights, biases, activation function, ReLU, softmax, convolution, pooling, layers of depth, batch, gradient descent, backpropagation (and chain rule), AdamOptimizer, please feel free to skip to the next section._  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFCS231n "Convolutional Neural Networks for Visual Recognition"  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFhttp://cs231n.github.io/  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFPlease, read through  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFModule 1, Neural Networks      123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFModule 2, Convolutional Neural Networks   123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF####TensorFlow tutorials to complete123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF_If you are familiar with all of the concepts in this list: tensor graph, session, tf.global_variable_initializer, tf.train.coordinator, tf.train.start_queue_runners, tf.nn.sparse_softmax_cross_entropy_with_logits, tf.saver, tf.summary, tf.summary.FileWriter, tf.name_scope, please, feel free to skip to the next section._123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF[MNIST](https://www.tensorflow.org/tutorials/mnist/beginners/)  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF[Deep MNIST](https://www.tensorflow.org/tutorials/mnist/pros/)  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF[Understandig TensorFlow's workflow](https://www.tensorflow.org/tutorials/mnist/tf/)  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF[CIFAR10](https://www.tensorflow.org/tutorials/deep_cnn/)  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF[Deep Generative Adversarial Models](https://github.com/carpedm20/DCGAN-tensorflow)  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF####Introduction to Affinity Core123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF_Structure based virtual screening is an approach that allows to retrieve a very small percent, usually few dozens of molecules, from the large database, of millioons of chemical structures. The process can be imagined as a google search for a flexible key (ligand) with a 3D image of a rigid lock (receptor,protein). Search can be broken into two parts. Since the most optimal relative position of the drug and protein is not known, it has to be estimated (docking). Afterwards, many static protein-ligand complexes have to be ranked by their predicted relative binding affinity (sorting). Usually, 25,000-200,000 pose evaluations are done during docking, and a single pose evaluation is done during ranking. Because Tesla K80 GPU can only evaluate 100-200 images/second, position search for a single ligand may take anywhere between 3 and 35 minutes, docking the average-size database of 1,000,000 of molecules may take 1.2 GPU years. In this example we only apply the network to the previously docked with AutoDock Smina positions, IE: ranking._123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF####Step 1: teaching the network123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFYou will need four scripts, and the database123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFav4_networks.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFav4_main.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFav4_input.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFav4_utils.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFlabeled_av4123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFwhere `labeled_av4` is an already prepared database of the ligands and proteins in av4 binary format.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFav4_networks.py 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# is a library of many different network architectures123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# each of the networks accepts batch of images, and outputs batch of unscaled probabilities (logits)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# crucial part 1: the network itself123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# convolutional layers IE: tf.nn.conv3d123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# pooling layers IE: tf.nn.max_pool3d or tf.nn.avg_pool3d123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# Rectifier Linear Regression Units, or ReLUs IE: tf.nn.relu123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# crucial part 2: rules for variable initialization123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# IE: bias_variable 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# tf.constant(0.01, shape=shape)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# or weight variable123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# tf.truncated_normal(shape, stddev=0.005)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# initial weights and biases for trainable variables are usually initialized with small random positive 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# values. Deep networks can easily run out of control and owerflow the floats in higher layers 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# if not initialized properly.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# That's why it's important to initialize variables very accurately123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# especially deep networks can be hierarchically constructed 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# when the new layer(s) is added to the top of existing trained network123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# crucial part 3: variable summaries123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# IE: tf.summary.histogram, tf.summary.scalar, 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# and tf.name_scope (groups variables together under a common name)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# variable summaries are written in a separate file and help to monitor the state and evolution 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# of the network during training or testing123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFav4_input.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# is script that reads and indexes the database in av4 format, and creates batches of images123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# in 3D that can be fed to the network123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# av4 database consists of thousands of folders - one for each protein123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# each protein can have many ligands123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# each ligand av4 file can have many positions (frames), and every frame has it's label123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# the name of each folder IE 1QGT, 4G93 each correspond to a particular PDB id  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# original PDB file with coordinates can be found at http://www.rcsb.org/123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# crucial part 1: index_the_database_into_queue123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# crawls of all the folders in the database and creates tensor of filenames123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# crucial part 2: read_receptor_and_ligand123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# reads a single example of receptor and ligand from the database123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# returns coordinates and name (label) of every atom (only one frame depending on epoch counter)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# crucial part 3: convert_protein_and_ligand_to_image ***(A bit unclear, maybe more to differentiate dense image from sparse image. Also describe "pixels" in a bit more detail)***123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# creates an image (sparse or dense) from input atom coordinates123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# dense image is cubic, has only some atoms of the protein, and describes pixels (not atoms)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# empty spaces in dense image are filled with zeros123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# crucial part 4: tf.train.batch (for three reasons)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# reason 1:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# it runs multiple independent threads of image creation123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# reason 2:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# it batches images together123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# single images are small and tensor operations in them (such as convolution or pooling)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# are not efficient. 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# reason 3:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# gradient descent optimizer gets much better gradient from multiple images. 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# Ideally, every single gradient descent step would be applied to a representative sample 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# of a whole database; this is better achievable with larger batches123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# av4_main.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# is a main script that assembles all of the parts together 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# crucial part 1: FLAGS123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# class that stores many global parameters of the script123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# such as FLAGS.pixels_size - determines the size of the pixel generated by av4_input123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# crucial part 2: train123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# assembles all of the parts together:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 1. input image creation pipeline              IE: ....something = image_and_label_queue 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 2. network that makes predictions             IE: intuit_net or nilai_net123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 3. cost function to minimize                  IE: tf.nn.sparse_softmax_cross_entropy_with_logits123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 4. optimizer(applies gradient descent steps)  IE: tf.train.AdamOptimizer123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 5. run while loop pipe the tensor graph       IE: sess.run(train_step_run)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# graph initialization commands:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 6. initializer of variables from placeholders IE: tf.global_variable_initializer 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 7. fill the graph skeleton with data inputs   IE: tf.train.start_queue_runners123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 8. also has saver of variable states          IE: tf.train.saver123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 9. variable summaries to visualize            IE: tf.summaries.writer123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 10. an epoch counter that counts every read through all proteins in database as one epoch123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFav4_utils.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# stores various utilities to support functions that are not natively present in TensorFlow123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF``` 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFhere is how a typical session on our Amazon graphical instance with K80 GPU would look like:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# log into our remote machine 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# email maksym to get the key123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFssh -i P2_key.pem ubuntu@awsinstance.com123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# every member of the group should have his or her folder123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFcd maksym123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# clone affinity core into your working directory 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFubuntu@ip-172-31-4-5:~/maksym$ git clone https://github.com/mitaffinity/core.git  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFcd core 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFpython av4_main.py **(Shouldn't run this until the location pointer has been changed) **  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# point the script to the location of the database123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFvi (or any other command line text file editor; some people like nano) 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# the database has already been donloaded to the instance123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# change the database path under flags to   123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# /home/ubuntu/common/data/labeled_av4  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# does not work; needs latest tensorflow  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# tensorflow12 is hidden in an envoronmental variable 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# source $TF12  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# if you are interested what $TF12 it is:  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFecho $TF12 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF/home/ubuntu/common/venv/tf12/bin/activate  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# start training123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFpython av4_main.py 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# seems to work, now it's time to launch this process for a while123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# the key is to launch it on the background, so it does not die when you log off123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# from your remote host. Use the '&' sign123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFpython av4_main.py &  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# now background process will persist when you exit the session  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# now the nasty problem: TensorFlow tends not to die and hog on the GPU even after it's been terminated123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# also, there are many of us using GPU instance at the same time, but with TF's default settings123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# only one process will capture all VRAM on the GPU 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# see if anything is running on the GPU  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFnvidia-smi  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# should show the running processes, and how much VRAM each of them takes123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# you can also use top to monitor RAM and CPU123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFtop123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# since it's a development instance, it is ok to kill all python processes with123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# be carefull as it kills all the python processes that other people are running 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# it's ok to do it on our instance since it's consired to be only development zone for debugging123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFpkill -9 python123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFThe network training may take hours, or days depending on your dataset and architecture of the network. It's important to note that in our code the epoch is counted by protein-ligand pairs, not by images. Every protein-ligand pair may have multiple incorrect positions of the ligand 50-400, and a single correct, crystal position. In this case, it takes 100 epochs to only show all of the negatives to the network once. That is different from classical understanding of epochs in image recognition when images can't have multiple frames.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFRunning the code should have resulted in four folders with outputs:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF1_logs   123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF1_netstate   123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF1_test   123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF1_train  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF`1_logs` might be empty, and will be used to write outputs during evaluation.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF`1_netstate` will store the saved weights and biases for every trainable variable of the network 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF(and also all other variables, such as epoch counter)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF`1_train` and `1_test` should store summaries for variable states during training and testing that can123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFbe visualized. Let's expect the outputs of in the foders123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# log into our instance123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFssh -i P2_key.pem ubuntu@awsinstance.com123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# now I am123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# ubuntu@ip-172-31-4-5:~$123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# cd maksym123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFcd /core/summaries123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFcd 1_netstate123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFls -l123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# should show all of the files together with their size123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# IE: 96789276 Jan 29 16:55 saved_state-60999.data-00000-of-00001123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFcd ../1_train123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFls123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# should show 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# events.out.tfevents.1485708632.ip-172-31-4-5123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# which is a tensorflow summaries file123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# let's try to visualize it:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# load tensorflow 0.12 (default version in the environment is 0.10)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFsource $TF12123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# it's important to launch the tensorboard on port 80. By default internet browsers, such as chrome,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# will connect to port 80. You can read more here: 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# https://en.wikipedia.org/wiki/Port_(computer_networking)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# by default port 80 is not available to the user (the error is port is busy) that's why we use sudo123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFsudo python -m tensorflow.tensorboard --logdir=. --port=80123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# now you can navigate your browser to awsinstance.com123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF you should be able to see the following:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF![alt_tag](https://github.com/mitaffinity/core/blob/master/misc/cross_entropy.png)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFCross entropy (our cost function) goes down as we are training the network. 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF![alt_tag](https://github.com/mitaffinity/core/blob/master/misc/sparsity.png)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFSparsity of Rectifier Linear Unit is a percentage of zero-valued outputs of the layer. 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFIn chain rule for backpropagation, the derivative on sparse neuron is 0, and the derivative on downstream 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFneurons is also 0. If the sparsity for the layer is exactly 1, backpropagation does not work, and weights 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFcan't be updated. That is what frequently happens when the network "explodes" because of the incorrect weight initialization.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF![alt_tag](https://github.com/mitaffinity/core/blob/master/misc/histogram.png)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFBiases that all vere all initialized at 0.001 diverge as we are training our network. 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF####Step 2: evaluating the network123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFIn addition to four folders resulting from our previous step, you will need these three scripts:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF1_logs   123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF1_netstate   123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF1_test   123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF1_train  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFav4_eval.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFav4_input.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFav4_utils.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFthe only new script is `av4_eval`  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFav4_eval.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# av4_eval script is very similar to av4_main123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# crucial part 1:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# assembles all of the parts together:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 1. input image creation pipeline              IE: ....something = image_and_label_queue 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 2. network that makes predictions             IE: intuit_net or nilai_net123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 3. softmax instead of cost function in main   IE: tf.nn.softmax123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 4. no optimizer, variables are loaded         IE: saver.restore123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 5. run while loop pipe the tensor graph       IE: sess.run(train_step_run)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# crucial part 2: class store_predictions123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# stores, sorts, and saves predictions123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# estimates different evaluation parameters for straightforward binary classification such as 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# Area Under Curve https://en.wikipedia.org/wiki/Receiver_operating_characteristic123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# Confusion Matrix https://en.wikipedia.org/wiki/Confusion_matrix123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# crucial part 3: av4_eval can be used for two different tasks123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 1. distinguishing the correct position within many positions as in docking123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 2. sorting ligands each of which has many positions as in sorting123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 1 is very straightforward since our training consits of correct and incorrect positions, 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# we only need to score all of the available positions123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# our performance on task 1 is very high (AUC > 0.94)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 2 is not straighforward. Since many of the docked positions given to the network are not correct123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# (sometimes all of them)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFNow let's evaluate our script on distinguishing a single correct position from a single incorrect position, the same task it has been trained on. In this case testing set would be the part of the same dataset that was not used for training.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# Let's download the dataset from Kaggle to our local machine123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# navigate your browser to: https://inclass.kaggle.com/c/affinity4/data123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# and download holdout_av4.zip123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFscp -i P2_key.pem holdout_av4.zip ubuntu@awsinstance.com:/home/ubuntu/common/data123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFssh -i P2_key.pem ubuntu@awsinstance.com123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFcd common123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# unzip the database 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFunzip holdout_av4.zip123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# get the path to current directory123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFpwd 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# /home/ubuntu/common/data/labeled_av4123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFcd ~/maksym/core/summaries/1_netstate123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFls123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# note the latest step of the saved network123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# it's saved_state-60999.data-00000-of-00001 in my case123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFcd ../..123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# edit 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# FLAGS.saved_session = ./summaries/1_netstate/saved_state-60999123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# FLAGS.database_path = /home/ubuntu/common/data/labeled_av4123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFvi av4_eval.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# now source tensorflow 0.12 and launch the evaluation script123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFsource $TF12123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFpython av4_eval.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# ....123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# current_epoch: 6 batch_num: [82] 	prediction averages: 0.538309 	examples per second: 273.89123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# ......123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# all_done123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# the evaluation script should have written five files into the corresponding logs folder123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# in our case it's 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# saved_state-60999_average_submission.csv123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# saved_state-60999_max_submission.csv123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# saved_state-60999_multiframe_submission.csv123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# saved_state-60999_predictions.txt123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# saved_state-60999_scores.txt123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# for this kind of evaluation only two files are meaningful:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFvi saved_state-60999_predictions.txt123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# saved_state-60999_predictions.txt123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# has four columns:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# average_prediction   label   filename   predictions123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 1.0       1.0       1swd_465_ligand.av4_frame19                       1.0              123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 1.0       1.0       2pno_1757_ligand.av4_frame11                      1.0                     123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 1.0       1.0       4d1j_4337_ligand.av4_frame13                      1.0  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 1.0       1.0       4nul_138_ligand.av4_frame11                       1.0           123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 1.0       1.0       2pno_1757_ligand.av4_frame3                       1.0                                               123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 1.0       1.0       4nul_138_ligand.av4_frame15                       1.0,1.0            123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 1.0       1.0       4nul_138_ligand.av4_frame17                       1.0,1.0  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# .....123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# ...123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 0.953     1.0       3n66_819_ligand.av4_frame9                        0.953           123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 0.953     1.0       3elz_401_ligand.av4_frame5                        0.953                 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 0.953     1.0       4rrw_2217_ligand.av4_frame8                       0.953 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 0.953     1.0       1gt6_538_ligand.av4_frame6                        0.953  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 0.953     1.0       1an5_533_ligand.av4_frame18                       0.953 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 0.953     1.0       4ki0_1898_ligand.av4_frame2                       0.953 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 0.953     1.0       1ivf_807_ligand.av4_frame18                       0.953  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# ....123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 0.002     0.0       3ekw_199_ligand.av4_frame3                        0.002   123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 0.002     0.0       2b0m_362_ligand.av4_frame0                        0.003,0.001   123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 0.002     0.0       1oya_399_ligand.av4_frame14                       0.002 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 0.002     0.0       2nxi_3110_ligand.av4_frame3                       0.002   123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 0.002     0.0       1yrh_1605_ligand.av4_frame5                       0.002   123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 0.001     0.0       3thq_430_ligand.av4_frame18                       0.001 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 0.001     0.0       1jvu_248_ligand.av4_frame2                        0.001    123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# 0.001     0.0       1yrh_1605_ligand.av4_frame17                      0.001  123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# the reson that the last column has multiple entries is because same protein-ligand complex can be123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# evaluated several times. Because random affine transform (in av4_input) rotates and shifts the box 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# around protein-ligand complex randomly, every time an image in different orientation is evaluated123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# ideally, the network should be rotationally and translationally invariant. In that case all of the123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# values in the last column should be same. That is almost the case.123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF####Step 3: database preparation (optional)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdata and .av4 format123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFav4_database_master123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFav4_atom_dictionary123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF####Step 4: running affinity on Bridges, XSEDE national supercomputer123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF- login to Bridge through XSEDE Single Sign-On (SSO) Hub. 123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ ssh [xsede_username]@login.xsede.org123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ gsissh bridges123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF- get groupname123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ id -gn123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFyour work directory will be `/pylon1/[groupname]/[username]`123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF- clone affinity source code to work directory123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ cd /pylon1/[groupname]/[username]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF$ clone git https://github.com/mitaffinity/core.git123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF- prepare data123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFtodo123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF- create batch script (you can create this script at anywhere, recommand save it under `$HOME`)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```bash123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#!/bin/bash123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#SBATCH -N 1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#SBATCH -p GPU123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#SBATCH --ntasks-per-node 28123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#SBATCH -t 48:00:00123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#SBATCH --gres=gpu:4123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#echo commands to stdout123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFset -x123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#load module123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFmodule load cuda/8.0123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFmodule load tensorflow/0.12.1123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#set python environment123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFsource $TENSORFLOW_ENV/bin/activate123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#move to working directory123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFcd /pylon1/[groupname]/[username]/core123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#run GPU program123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFpython av4_main.py123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF- submit job123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFsbatch job.sh123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF```123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF