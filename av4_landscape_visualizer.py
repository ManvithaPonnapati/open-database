import time,re123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport tensorflow as tf123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFimport numpy as np123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFfrom av4_input import image_and_label_queue,index_the_database_into_queue,read_receptor_and_ligand,convert_protein_and_ligand_to_image123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFfrom av4_main import FLAGS123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFfrom av4_networks import max_net123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFfrom av4_utils import generate_exhaustive_affine_transform,deep_affine_transform,affine_transform123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFFLAGS.saved_session = './summaries/2_netstate/saved_state-999'123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFFLAGS.predictions_file_path = re.sub("netstate","logs",FLAGS.saved_session)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFFLAGS.database_path = '../datasets/unlabeled_av4'123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFFLAGS.num_epochs = 10123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFFLAGS.top_k = FLAGS.num_epochs123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# av4 lanscape visualizer makes visualizaition of the predicted energy landscape in VMD123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# take a single ligand;123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# generate affine transform123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# enqueue all of the ligands into a queue without shuffling (I don't think I need a queue)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF# take the ligands ; collect the energy terms123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFclass minimizer_object:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    def __init__(self,side_pixels=FLAGS.side_pixels,pixel_size=FLAGS.pixel_size,batch_size=FLAGS.batch_size,num_threads=FLAGS.num_threads):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.affine_transform_queue = tf.FIFOQueue(capacity=10000,dtypes=tf.float32,shapes=[4,4])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.exhaustive_affine_transform = generate_exhaustive_affine_transform()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.ligand_elements = tf.Variable([0,0],trainable=False)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.ligand_coords = tf.Variable([[0.0,0.0,0.0],[0.0,0.0,0.0]],trainable=False)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.receptor_elements = tf.Variable([0,0,0],trainable=False)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.receptor_coords = tf.Variable([[0.0,0.0,0.0],[0.0,0.0,0.0],[0.0,0.0,0.0]],trainable=False)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.transformed_ligand_coords,_ = affine_transform(self.ligand_coords,self.affine_transform_queue.dequeue())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.complex_image,_,_ = convert_protein_and_ligand_to_image(self.ligand_elements,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                                                     self.transformed_ligand_coords,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                                                     self.receptor_elements, self.receptor_coords,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                                                     side_pixels, pixel_size)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.image_batch = tf.train.batch([self.complex_image], batch_size=batch_size,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                           num_threads=num_threads, capacity=batch_size * 5,123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                                           shapes=[[side_pixels, side_pixels, side_pixels]])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.keep_prob = tf.placeholder(tf.float32)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        y_conv = max_net(self.image_batch, self.keep_prob, batch_size)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        # compute softmax over raw predictions123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        self.predictions_batch = tf.nn.softmax(y_conv)[:,1]123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    def evaluate_all_positions(self,sess,my_ligand_elements,my_ligand_coords,my_receptor_elements,my_receptor_coords):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        sess.run(tf.global_variables_initializer())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        sess.run(self.affine_transform_queue.enqueue_many(self.exhaustive_affine_transform))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        tf.assign(self.ligand_elements,my_ligand_elements,validate_shape=False)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        tf.assign(self.ligand_coords,my_ligand_coords,validate_shape=False)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        tf.assign(self.receptor_elements,my_receptor_elements,validate_shape=False)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        tf.assign(self.receptor_coords,my_receptor_coords,validate_shape=False)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        try:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            while True:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                start = time.time()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                my_predictions = sess.run(self.predictions_batch,feed_dict={self.keep_prob :1},options=tf.RunOptions(timeout_in_ms=1000))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                print "\tprediction averages:", np.mean(my_predictions),123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                print "\texamples per second:", "%.2f" % (FLAGS.batch_size / (time.time() - start))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        except tf.errors.DeadlineExceededError:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            print "evaluation finished"123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#print "right before minimizer"123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#time.sleep(1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFminimizer1 = minimizer_object()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#print "right after minimizer "123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF#time.sleep(1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFdef evaluate_on_train_set():123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    "train a network"123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    with tf.name_scope("epoch_counter"):123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        batch_counter = tf.Variable(0)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        batch_counter_increment = tf.assign(batch_counter,tf.Variable(0).count_up_to(np.round((100000*FLAGS.num_epochs)/FLAGS.batch_size)))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        epoch_counter = tf.div(batch_counter*FLAGS.batch_size,1000000)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # create session to compute evaluation123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    sess = tf.Session()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # create a filename queue first123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    filename_queue,examples_in_database = index_the_database_into_queue(FLAGS.database_path, shuffle=True)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # create an epoch counter123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # there is an additional step with variable initialization in order to get the name of "count up to" in the graph123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    batch_counter = tf.Variable(0,trainable=False)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # sess.run(tf.global_variables_initializer())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # read one receptor and stack of ligands; choose one of the ligands from the stack according to epoch123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    ligand_file,current_epoch,label,ligand_elements,ligand_coords,receptor_elements,receptor_coords = read_receptor_and_ligand(filename_queue,epoch_counter=tf.constant(0))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    # create saver to save and load the network state123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #print "right before saver"123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #time.sleep(1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    sess.run(tf.global_variables_initializer())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    saver= tf.train.Saver(var_list=(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope="Adam_optimizer") +123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                             tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope="network") +123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF                             tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope="epoch_counter")))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #print "right after saver"123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #time.sleep(1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    if FLAGS.saved_session is None:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        sess.run(tf.global_variables_initializer())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    else:123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        sess.run(tf.global_variables_initializer())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        print "Restoring variables from sleep. This may take a while..."123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        saver.restore(sess,FLAGS.saved_session)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        print "unitialized vars:", sess.run(tf.report_uninitialized_variables())123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        #time.sleep(1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    coord = tf.train.Coordinator()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    threads = tf.train.start_queue_runners(sess = sess,coord=coord)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    batch_num = 0123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #print "before the while loop"123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    #time.sleep(1)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF    while True or not coord.should_stop():123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        start = time.time()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        print sess.run(ligand_file)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        my_ligand_file,my_current_epoch,my_label,my_ligand_elements,my_ligand_coords,my_receptor_elements,my_receptor_coords = \123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF            sess.run([ligand_file,current_epoch,label,ligand_elements,ligand_coords,receptor_elements,receptor_coords])123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        minimizer1.evaluate_all_positions(sess,my_ligand_elements,my_ligand_coords,my_receptor_elements,my_receptor_coords)123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        print "batch_num:",batch_num123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF        print "\texamples per second:", "%.2f" % (FLAGS.batch_size / (time.time() - start))123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNF123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFevaluate_on_train_set()123343DJNBFHJBJNKFJNBHDRFBNJKDJUNFprint "All Done"